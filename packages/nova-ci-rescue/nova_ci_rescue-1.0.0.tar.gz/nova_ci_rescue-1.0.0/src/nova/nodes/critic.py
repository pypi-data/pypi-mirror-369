"""
Critic node for Nova CI-Rescue agent workflow.
Reviews and approves/rejects patches generated by the Actor.
"""

from pathlib import Path
from typing import Dict, Any, Tuple, List
from datetime import datetime
from rich.console import Console

from nova.agent.state import AgentState
from nova.telemetry.logger import JSONLLogger

console = Console()


class CriticNode:
    """Node responsible for reviewing patches before application."""
    
    def __init__(self, verbose: bool = False):
        self.verbose = verbose
        
    def execute(
        self,
        state: AgentState,
        patch_diff: str,
        llm_agent: Any,
        logger: JSONLLogger
    ) -> Tuple[bool, str]:
        """
        Review a patch and decide whether to approve or reject it.
        
        Args:
            state: Current agent state
            patch_diff: The patch diff to review
            llm_agent: LLM agent for patch review
            logger: Telemetry logger
            
        Returns:
            Tuple of (approved: bool, reason: str)
        """
        iteration = state.current_iteration
        
        # Analyze patch before review
        patch_lines = patch_diff.split('\n')
        patch_size = len(patch_lines)
        
        # Check for dangerous patterns
        dangerous_patterns = {
            'config_changes': any('config' in line.lower() or 'settings' in line.lower() for line in patch_lines),
            'deletion_heavy': sum(1 for line in patch_lines if line.startswith('-')) > sum(1 for line in patch_lines if line.startswith('+')),
            'large_patch': patch_size > 500,
            'affects_tests': any('test_' in line or '_test.' in line for line in patch_lines),
            'affects_setup': any('setup.py' in line or 'pyproject.toml' in line or 'requirements' in line for line in patch_lines)
        }
        
        # Log critic start event
        logger.log_event("critic_start", {
            "iteration": iteration,
            "patch_size": patch_size,
            "dangerous_patterns": dangerous_patterns,
            "failing_tests_count": len(state.failing_tests),
            "previous_rejections": state.critic_feedback is not None,
            "timestamp": datetime.utcnow().isoformat()
        })
        
        if self.verbose:
            console.print(f"[cyan]🔍 Reviewing patch with critic...[/cyan]")
            if dangerous_patterns['large_patch']:
                console.print(f"[yellow]⚠ Large patch detected: {patch_size} lines[/yellow]")
            if dangerous_patterns['config_changes']:
                console.print(f"[yellow]⚠ Patch modifies configuration files[/yellow]")
        
        start_time = datetime.utcnow()
        
        try:
            # Use LLM to review the patch
            approved, reason = llm_agent.review_patch(patch_diff, state.failing_tests)
            
            # Override if patch has critical issues
            if not patch_diff or patch_diff.strip() == "":
                approved = False
                reason = "Empty patch"
            elif patch_size > 1000:
                approved = False
                reason = f"Patch too large ({patch_size} lines) - should be more focused"
            elif dangerous_patterns['affects_setup'] and not any('requirements' in str(test.get('file', '')) for test in state.failing_tests):
                approved = False
                reason = "Patch modifies setup/dependency files without related test failures"
            
            execution_time = (datetime.utcnow() - start_time).total_seconds()
            
            # Log critic decision
            event_type = "critic_approved" if approved else "critic_rejected"
            logger.log_event(event_type, {
                "iteration": iteration,
                "approved": approved,
                "reason": reason,
                "review_details": {
                    "patch_size": patch_size,
                    "dangerous_patterns_found": [k for k, v in dangerous_patterns.items() if v],
                    "execution_time_seconds": execution_time
                },
                "timestamp": datetime.utcnow().isoformat()
            })
            
            if self.verbose:
                if approved:
                    console.print(f"[green]✓ Patch approved: {reason}[/green]")
                else:
                    console.print(f"[red]❌ Patch rejected: {reason}[/red]")
                    
            # Store feedback in state if rejected
            if not approved:
                state.critic_feedback = reason
            else:
                # Clear feedback if approved
                state.critic_feedback = None
                
            return approved, reason
            
        except Exception as e:
            # Log critic error
            logger.log_event("critic_error", {
                "iteration": iteration,
                "error": str(e),
                "error_type": type(e).__name__,
                "timestamp": datetime.utcnow().isoformat()
            })
            
            if self.verbose:
                console.print(f"[yellow]⚠ Critic error: {e}, auto-approving[/yellow]")
            
            # Default to approving on error to avoid blocking
            return True, f"Auto-approved due to review error: {e}"


def review_patch(
    state: AgentState,
    patch_diff: str,
    llm_agent: Any,
    logger: JSONLLogger,
    verbose: bool = False
) -> Tuple[bool, str]:
    """
    Convenience function to review a patch using the CriticNode.
    
    Args:
        state: Current agent state
        patch_diff: The patch diff to review
        llm_agent: LLM agent for patch review
        logger: Telemetry logger
        verbose: Enable verbose output
        
    Returns:
        Tuple of (approved: bool, reason: str)
    """
    node = CriticNode(verbose=verbose)
    return node.execute(state, patch_diff, llm_agent, logger)