FP_SIM_THRESHOLD_L1 = 0.998

# Model name abbreviation replacements for generating short names
MODEL_NAME_REPLACEMENTS = {
    "Instruct": "Inst",
    "Instruction": "Inst",
    "Tuned": "",
    "Base": "B",
    "Gemma": "G",
    "Llama": "L",
    "CodeLlama": "CL",  # More specific, should be applied before "Llama"
    "Qwen": "Q",
    "Mistral": "M",
    "Phi": "P",
    "DeepSeek": "DS",
    "SmolLM": "SL",
    "-": "",
    "_": "",
    " ": "",
    "3-": "3",
    "2-": "2",
    "1-": "1",
}

# Order matters - more specific replacements should come first
MODEL_NAME_REPLACEMENT_ORDER = [
    "CodeLlama",  # Must come before "Llama"
    "SmolLM",  # Must come before generic patterns
    "DeepSeek",
    "Instruct",
    "Instruction",
    "Mistral",
    "Gemma",
    "Llama",
    "Qwen",
    "Tuned",
    "Base",
    "Phi",
    "3-",
    "2-",
    "1-",
    " ",
    "_",
    "-",
]


VALID_QUANTIZATION = {
    "awq",
    "bf16",
    "fp8",
    "fp16",
    "fp32",
    "int4",
    "int8",
    # GGUF quantizations
    "Q3_K_XL",
    "Q3_K_L",
    "Q3_K_M",
    "Q3_K_S",
    "Q4_0",
    "Q4_0_4_4",
    "Q4_0_4_8",
    "Q4_0_8_8",
    "Q4_K_L",
    "Q4_K_M",
    "Q4_K_S",
    "Q5_K_L",
    "Q5_K_M",
    "Q5_K_S",
    "Q6_K",
    "Q6_K_L",
    "Q8_0",
    # IMatrix quantizations
    "IQ3_M",
    "IQ4_XS",
    # Float formats
    "f16",
    "f32",
}


# HuggingFace loader classes
VALID_LOADER_CLASSES = {
    "AutoModelForCausalLM",
    "BartForConditionalGeneration",
    "DeepseekV3ForCausalLM",
    "GraniteMoeHybridForCausalLM",
    "Llama4ForConditionalGeneration",
    "Mistral3ForConditionalGeneration",
    "T5ForConditionalGeneration",
}

VALID_SOURCE_TYPES = {"huggingface_api", "onnx_file", "gguf_file"}

VALID_MODEL_MAKERS = {
    "01-ai",
    "AI-MO",
    "bartowski",
    "CohereForAI",
    "DeepSeek AI",
    "EleutherAI",
    "Google",
    "HuggingFaceTB",
    "IntervitensInc",
    "LightOn",
    "LiquidAI",
    "LGAI-EXAONE",
    "Microsoft",
    "Mistral AI",
    "myselfsaurabh",
    "Nexusflow",
    "Nous Research",
    "NousResearch",
    "OpenAI",
    "Perplexity AI",
    "Qwen",
    "RedHatAI",
    "RekaAI",
    "SakanaAI",
    "ServiceNow-AI",
    "TencentARC",
    "ai21labs",
    "allenai",
    "baidu",
    "bartowski",
    "berkeley-nest",
    "bigcode",
    "codellama",
    "databricks",
    "deepcogito",
    "deepseek-ai",
    "eurecom-ds",
    "facebook",
    "google",
    "ibm-granite",
    "ibm-ai-platform",
    "jondurbin",
    "katanemo",
    "lmstudio-community",
    "meta",
    "meta-llama",
    "microsoft",
    "mistralai",
    "mlx-community",
    "moonshotai",
    "netease-youdao",
    "numind",
    "nvidia",
    "openai",
    "ruliad",
    "stabilityai",
    "stanford-crfm",
    "teknium",
    "tencent",
    "tiiuae",
    "togethercomputer",
    "unsloth",
    "upstage",
}

VALID_LICENSES = {
    "bigcode-openrail-m",
    "bigscience-bloom-rail-1.0",
    "cc-by-nc-4.0",
    "deepseek",
    "gemma",
    "gpl",
    "llama2",
    "llama3",
    "llama3.1",
    "llama3.2",
    "llama3.3",
    "mit",
    "mnpl",
    "nexusflow_research",
    "apache-2.0",
    "qwen",
    "qwen-research",
    "microsof_research",
    "nvidia-open-model-license",
    "stability_ai",
    "tencent-hunyuan-a13b",
}
