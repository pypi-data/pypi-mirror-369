from datetime import datetime
from enum import Enum
from typing import Literal, TypedDict

import numpy as np
from numpy.typing import NDArray
from pydantic import BaseModel
from typing_extensions import deprecated

from ..utils.pydantic import UNSET, UUID7, InputType, InputTypeList, Metadata, Vector


# we use typed dicts for this because they can distinguish between unset and None
class MemoryMetrics(TypedDict, total=False):
    ##### DUPLICATE ANALYSIS
    is_duplicate: bool
    """
    Whether the memory is an exact duplicate of another memory

    Note:
        All but the last memories of a set of duplicates will be marked as duplicate. This does not
        indicate if the memory has potential duplicates, check if `potential_duplicate_memory_ids` is
        not `None` for that.
    """

    duplicate_memory_ids: list[UUID7]
    """The IDs of the duplicate memories."""

    has_potential_duplicates: bool
    """Whether the memory has potential duplicates."""

    potential_duplicate_memory_ids: list[UUID7] | None
    """
    IDs of potentially duplicate memories.

    Note:
        This will be `None` if the memory has no potential duplicates. Exact duplicates
        will not be included in this list. Unlike exact duplicates, this will be set on all
        memories that have potential duplicates not just the first memory of a set of duplicates.
    """

    ##### CLUSTER ANALYSIS
    cluster: int
    """The cluster ID of the memory. `-1` indicates that the memory is an outlier."""

    ##### PROJECTION ANALYSIS
    embedding_2d: tuple[float, float]
    """The projection of the memory embedding into a 2D space."""

    ##### NEIGHBOR ANALYSIS
    anomaly_score: float
    """The distance to the closest neighbor."""

    ##### LABEL ANALYSIS METRICS
    neighbor_label_logits: Vector
    """
    Logits that indicate likelihood for all label classes based on the memory's neighbors.

    Note:
        These logits are guaranteed to be non-negative and sum to a value less than or equal to 1.
        They are not normalized to sum to 1, and indicate the likelihood of each label class.
    """

    neighbor_predicted_label: int
    """The label with the highest neighbor label logit score."""

    neighbor_predicted_label_ambiguity: float
    """The difference between the highest and second highest neighbor label logit score."""

    neighbor_predicted_label_confidence: float
    """The logit score of the neighbor predicted label."""

    current_label_neighbor_confidence: float
    """The logit score of the current label."""

    normalized_neighbor_label_entropy: float
    """The normalized entropy of the neighbor label logits."""

    neighbor_predicted_label_matches_current_label: bool | None
    """Whether the neighbor predicted label matches the current label."""

    ##### CLASS PATTERNS ANALYSIS METRICS
    spread: float
    """Average distance to neighbors of the same class."""

    uniformity: float
    """Fraction of neighbors that are of the same class."""

    ##### SUBCONCEPT ANALYSIS METRICS
    subconcept_cluster_id: int | None
    """The ID of the subconcept cluster this memory belongs to, or -1 if it is an outlier."""

    subconcept_name: str | None
    """The name of the subconcept this memory belongs to, or Noise if it is an outlier."""


class Memory(BaseModel):
    """A memory is a single item that can be stored in the database."""

    value: InputType
    """The value used to generate the embedding for looking up this memory."""

    embedding: Vector
    """The embedding of the memory value, automatically generated by the Memoryset model."""

    source_id: str | None
    """Optional unique ID of the memory in a system of reference."""

    metadata: Metadata
    """Metadata associated with the memory that is not used in the model."""

    memory_id: UUID7
    """The UUID of the memory in the table, automatically generated by the Memoryset."""

    memory_version: int
    """The version of the memory, automatically maintained by the Memoryset."""

    created_at: datetime
    """The timestamp when the memory was created."""

    updated_at: datetime
    """The timestamp when the memory was last updated."""

    edited_at: datetime
    """The timestamp when the memory version was last incremented."""

    metrics: MemoryMetrics
    """Analysis metrics about this memory."""

    def __eq__(self, other: object) -> bool:
        if not isinstance(other, Memory):
            return False
        return self.memory_id == other.memory_id


class MemoryLookup(Memory):
    """A lookup result for a memory."""

    lookup_score: float
    """The similarity score between the query and the memory."""


class MemoryInsert(BaseModel):
    """Model of fields required for inserting a memory"""

    memory_id: UUID7 | None = None
    value: InputType
    metadata: Metadata = {}
    source_id: str | None = None

    class Config:
        extra = "forbid"


class MemoryUpdate(BaseModel):
    """Model for updating a memory (unset fields are kept as is)"""

    memory_id: UUID7
    value: InputType = UNSET
    metadata: Metadata | None = UNSET
    source_id: str | None = UNSET
    metrics: MemoryMetrics | None = UNSET

    class Config:
        extra = "forbid"


FilterableMemoryMetricFields = Literal[
    # Cluster analysis
    "cluster",
    # Projection analysis
    "embedding_2d",
    # Duplicate analysis
    "is_duplicate",
    "duplicate_memory_ids",
    "has_potential_duplicates",
    "potential_duplicate_memory_ids",
    # Neighbor analysis
    "anomaly_score",
    # Label analysis
    "neighbor_label_logits",
    "neighbor_predicted_label",
    "neighbor_predicted_label_ambiguity",
    "neighbor_predicted_label_confidence",
    "current_label_neighbor_confidence",
    "normalized_neighbor_label_entropy",
    "neighbor_predicted_label_matches_current_label",
    # Class patterns analysis
    "spread",
    "uniformity",
    # Subconcept analysis
    "subconcept_name",
]


class LabeledMemoryInsert(MemoryInsert):
    """Model of fields required for inserting a labeled memory"""

    label: int


class LabeledMemoryUpdate(MemoryUpdate):
    """Model for updating a labeled memory (unset fields are kept as is)"""

    label: int = UNSET


class LabeledMemory(Memory):
    """
    A labeled memory is a single item that can be stored in the database and has a label.
    """

    label: int
    """The label of the memory."""

    label_name: str | None
    """The human-readable name of the label."""

    metrics: MemoryMetrics  # type: ignore
    """Analysis metrics about this memory."""

    def __repr__(self) -> str:
        return "".join(
            [
                "LabeledMemory(\n",
                f"    value={(chr(39) + self.value + chr(39)) if isinstance(self.value, str) else '<Image>'},\n",
                f"    label={('<' + self.label_name + ': ' + str(self.label) + '>') if self.label_name else str(self.label)},\n",
                f"    metadata={self.metadata},\n" if self.metadata else "",
                f"    embedding=<array.{self.embedding.dtype}{self.embedding.shape}>,\n",
                f"    memory_id={self.memory_id},\n",
                f"    memory_version={self.memory_version},\n",
                f"    source_id={self.source_id},\n" if self.source_id else "",
                f"    metadata={self.metadata},\n" if self.metadata else "",
                f"    metrics={self.metrics},\n" if self.metrics else "",
                ")",
            ]
        )

    class Config:
        arbitrary_types_allowed = True


FilterableMemoryField = Literal[
    "memory_id", "value", "label", "metadata", "source_id", "created_at", "updated_at", "edited_at", "metrics", "score"
]


class LabeledMemoryLookup(MemoryLookup, LabeledMemory):
    """Single labeled memory lookup result."""

    def __repr__(self) -> str:
        return "".join(
            [
                "LabeledMemoryLookup(\n",
                f"    value={(chr(39) + self.value + chr(39)) if isinstance(self.value, str) else '<Image>'},\n",
                f"    label={('<' + self.label_name + ': ' + str(self.label) + '>') if self.label_name else str(self.label)},\n",
                f"    metadata={self.metadata},\n" if self.metadata else "",
                f"    embedding=<array.{self.embedding.dtype}{self.embedding.shape}>,\n",
                f"    memory_id={self.memory_id},\n",
                f"    memory_version={self.memory_version},\n",
                f"    lookup_score={self.lookup_score},\n",
                ")",
            ]
        )


class LookupReturnType(str, Enum):
    COLUMNS = "columns"
    ROWS = "rows"


class MemoryLookupColumnResult(TypedDict):
    input_embeddings: NDArray[np.float32]  # batch_size x embedding_dim
    memories_embeddings: NDArray[np.float32]  # batch_size x memory_count x embedding_dim
    memories_lookup_scores: NDArray[np.float32]  # batch_size x memory_count
    # non-tensor fields
    memories_values: list[InputTypeList]  # batch_size x memory_count
    memories_ids: list[list[UUID7]]  # batch_size x memory_count
    memories_ids: list[list[UUID7]]  # batch_size x memory_count
    memories_versions: list[list[int]]  # batch_size x memory_count
    memories_metadata: list[list[Metadata]]  # batch_size x memory_count
    memories_source_ids: list[list[str | None]]  # batch_size x memory_count
    memories_created_ats: list[list[datetime]]  # batch_size x memory_count
    memories_updated_ats: list[list[datetime]]  # batch_size x memory_count
    memories_edited_ats: list[list[datetime]]  # batch_size x memory_count
    memories_metrics: list[list[MemoryMetrics]]  # batch_size x memory_count


class LabeledMemoryLookupColumnResult(MemoryLookupColumnResult):
    memories_labels: NDArray[np.int64]  # batch_size x memory_count
    memories_label_names: list[list[str | None]]  # batch_size x memory_count


class ScoredMemoryInsert(MemoryInsert):
    """Model of fields required for inserting a scored memory."""

    score: float


class ScoredMemoryUpdate(MemoryUpdate):
    """Model for updating a scored memory (unset fields are kept as is)."""

    score: float = UNSET


class ScoredMemory(Memory):
    """A scored memory is a single item stored in the database with a score."""

    score: float
    metrics: MemoryMetrics

    def __repr__(self) -> str:
        return "".join(
            [
                "ScoredMemory(\n",
                f"    value={(chr(39) + self.value + chr(39)) if isinstance(self.value, str) else '<Image>'},\n",
                f"    score={self.score},\n",
                f"    metadata={self.metadata},\n" if self.metadata else "",
                f"    embedding=<array.{self.embedding.dtype}{self.embedding.shape}>,\n",
                f"    memory_id={self.memory_id},\n",
                f"    memory_version={self.memory_version},\n",
                f"    source_id={self.source_id},\n" if self.source_id else "",
                f"    metrics={self.metrics},\n" if self.metrics else "",
                ")",
            ]
        )


class ScoredMemoryLookup(ScoredMemory, MemoryLookup):
    """Single scored memory lookup result."""

    def __repr__(self) -> str:
        return "".join(
            [
                "ScoredMemoryLookup(\n",
                f"    value={(chr(39) + self.value + chr(39)) if isinstance(self.value, str) else '<Image>'},\n",
                f"    score={self.score},\n",
                f"    metadata={self.metadata},\n" if self.metadata else "",
                f"    embedding=<array.{self.embedding.dtype}{self.embedding.shape}>,\n",
                f"    memory_id={self.memory_id},\n",
                f"    memory_version={self.memory_version},\n",
                f"    lookup_score={self.lookup_score},\n",
                ")",
            ]
        )


class ScoredMemoryLookupColumnResult(MemoryLookupColumnResult):
    memories_scores: NDArray[np.float32]  # batch_size x memory_count
