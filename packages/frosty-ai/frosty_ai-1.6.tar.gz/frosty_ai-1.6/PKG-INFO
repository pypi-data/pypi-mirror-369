Metadata-Version: 2.4
Name: frosty_ai
Version: 1.6
Summary: A Python package for seamless multi-LLM routing, observability, and LLM-agnostic integration.
Home-page: https://docs.gofrosty.ai/frosty-ai-docs/frosty-ai-documentation
Author: FrostyAI
Author-email: brittany@gofrosty.ai
Classifier: Programming Language :: Python :: 3
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Requires-Python: >=3.7
Description-Content-Type: text/markdown
Requires-Dist: requests
Requires-Dist: openai>=0.28.0
Requires-Dist: mistralai>=1.5.0
Requires-Dist: anthropic>=0.49.0
Requires-Dist: urllib3<1.27,>=1.25.4
Dynamic: author
Dynamic: author-email
Dynamic: classifier
Dynamic: description
Dynamic: description-content-type
Dynamic: home-page
Dynamic: requires-dist
Dynamic: requires-python
Dynamic: summary


        Frosty AI is a Python package for seamless multi-LLM (Large Language Model) routing, observability, and management.
        
        Frosty empowers developers and organizations to remain LLM-agnostic, enabling seamless integration, management, and switching between various LLM providers without vendor lock-in. 
        With Frosty, you can:
        
        - Flexibly integrate with multiple LLM providers like OpenAI, Anthropic, and Mistral.
        - Future-proof your applications by easily switching to new or better-performing models as they become available.
        - Optimize costs by choosing models based on performance and pricing, avoiding vendor lock-in.
        
        For the most up-to-date documentation and usage examples, please visit the [Frosty AI Documentation](https://docs.gofrosty.ai/frosty-ai-docs/frosty-ai-documentation).
    
