{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc7d5f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cortical_tools.datasets.v1dd import client\n",
    "# from cortexclient.mesh_vertex import *\n",
    "\n",
    "# rid = 864691132544823185\n",
    "# vass = VertexAssigner(root_id=rid, caveclient=client.cave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6e3b231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4023587ea6e9496e842e5335c3175de3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing complex chunks...:   0%|          | 0/744 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rid = 864691132544823185\n",
    "\n",
    "mapping, vass = client.mesh.compute_vertex_to_l2_mapping(\n",
    "    rid,\n",
    "    return_assigner=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a59e9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pf_df = client.tables.proofreading_status_and_strategy(status_axon=True).query()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66065b69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([157013146664435759, 157013146664435759, 157013146664435759, ...,\n",
       "       171579752191100135, 171579752191100135, 171579752191100135],\n",
       "      shape=(1126948,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.mesh.mesh_l2_mappings[rid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4647b3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nglui import skeletons\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_df = vass.chunk_df.copy()\n",
    "chunk_df['b'] = np.random.random(chunk_df.shape[0])\n",
    "chunk_df['g'] = np.random.random(chunk_df.shape[0])\n",
    "chunk_df['r'] = np.random.random(chunk_df.shape[0])\n",
    "\n",
    "vert_df = pd.DataFrame(\n",
    "    {\n",
    "        'point_x': vass.vertices[:,0],\n",
    "        'point_y': vass.vertices[:,1],\n",
    "        'point_z': vass.vertices[:,2],\n",
    "        'mesh_label': vass.mesh_label_index,\n",
    "    }\n",
    ")\n",
    "\n",
    "vert_df = vert_df.merge(\n",
    "    chunk_df[['r', 'g', 'b']],\n",
    "    right_index=True,\n",
    "    left_on='mesh_label',\n",
    "    how='left',\n",
    ")\n",
    "\n",
    "vert_df = vert_df.fillna(1)\n",
    "\n",
    "skltor = skeletons.SkeletonManager(\n",
    "    client.cave,\n",
    "    cloudpath='gs://csm-skel/ngl3',\n",
    "    vertex_attributes=['r', 'g', 'b',],\n",
    "    initialize_info=True,\n",
    ")\n",
    "skltor.upload_skeleton(\n",
    "    root_id = rid,\n",
    "    vertices= vass.vertices,\n",
    "    edges = [],\n",
    "    vertex_attribute_data=vert_df[['r', 'g', 'b']],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e938ecc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "864691132544823185"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b02a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "grps = [grp for _, grp in vass.chunk_df_multi.groupby('chunk_number')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d42e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3154571e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for grp in tqdm.tqdm(grps):\n",
    "    vass.process_multicomponent_chunk(\n",
    "        grp,\n",
    "        vass.vertices,\n",
    "        vass.faces,\n",
    "        ts = vass.timestamp,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c443404d",
   "metadata": {},
   "outputs": [],
   "source": [
    "grp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea568977",
   "metadata": {},
   "outputs": [],
   "source": [
    "vass.process_multicomponent_chunk(\n",
    "    grp,\n",
    "    vass.vertices,\n",
    "    vass.faces,\n",
    "    ts = vass.timestamp,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3b570a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_rows = grp\n",
    "vertices = vass.vertices\n",
    "faces = vass.faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb1f27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pts = np.array(chunk_rows[[\"pt_x\", \"pt_y\", \"pt_z\"]].values, dtype=float)\n",
    "components = create_component_dict(chunk_rows, vertices, faces)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d7287b",
   "metadata": {},
   "outputs": [],
   "source": [
    "components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca72e6ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cad8fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_all = bbox_mask(chunk_rows.iloc[0], vertices, inclusive=True)\n",
    "vertices_chunk = vertices[mask_all]\n",
    "faces_filter = faces[np.all(mask_all[faces], axis=1)]\n",
    "relabel = {v: k for k, v in enumerate(np.flatnonzero(mask_all))}\n",
    "faces_chunk = fastremap.remap(\n",
    "    faces_filter,\n",
    "    relabel,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec054e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_in = bbox_mask(chunk_rows.iloc[0], vertices_chunk, inclusive=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a879d6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "faces_not_touching_edge = faces_chunk[np.all(mask_in[faces_chunk], axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f5c742",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_identity = np.array([[ii, ii, ii] for ii in range(mask_in.shape[0])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cab27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vertex_cc = gyp.connected_components(\n",
    "    np.vstack(\n",
    "        [np.atleast_2d(faces_not_touching_edge).reshape(-1, 3), face_identity]\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66972f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vertex_cc[~mask_in] = -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e4c4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "components = []\n",
    "assigned_vertices = np.full(mask_all.shape[0], False, dtype=bool)\n",
    "comp_id = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ea899d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ii in np.unique(vertex_cc[mask_in]):\n",
    "    comp_mask = np.full(mask_all.shape, False, dtype=bool)\n",
    "    comp_mask[mask_all] = vertex_cc == ii\n",
    "    comp_verts, comp_faces = component_submesh(\n",
    "        vertex_cc == ii, vertices_chunk, faces_chunk\n",
    "    )\n",
    "    assigned_vertices[comp_mask] = True\n",
    "    if comp_faces.shape[0] == 0:\n",
    "        continue\n",
    "    components.append(\n",
    "        {\n",
    "            \"component_id\": comp_id,\n",
    "            \"vertices\": comp_verts,\n",
    "            \"faces\": comp_faces,\n",
    "            \"mask\": comp_mask,\n",
    "            \"vertices_in\": vertices[comp_mask],\n",
    "        }\n",
    "    )\n",
    "    comp_id += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc05021",
   "metadata": {},
   "outputs": [],
   "source": [
    "components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b126d2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "faces_chunk_mask = np.flatnonzero(np.any(mask_in[vass.faces], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ec1e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "minds = np.flatnonzero(mask_in)\n",
    "relabel = {v: k for k, v in enumerate(minds)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0e17c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_mask = mask_in[vass.faces]\n",
    "faces_relabel = fastremap.remap(\n",
    "    vass.faces[np.all(face_mask, axis=1)],\n",
    "    relabel,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17877396",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_identity = np.array([[ii, ii, ii] for ii in range(len(minds))])\n",
    "vertex_cc = gyp.connected_components(\n",
    "    np.vstack([np.atleast_2d(faces_relabel).reshape(-1, 3), face_identity])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bd3e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "components = []\n",
    "assigned_vertices = np.full(mask_in.shape[0], False, dtype=bool)\n",
    "comp_id = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f078e13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ii = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aaa85f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_verts, comp_faces, comp_mask = component_submesh(\n",
    "            vertex_cc == ii, mask_in, vass.vertices, vass.faces, faces_chunk_mask\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89723c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "component_mask = mask_in.copy()\n",
    "component_mask[mask_in] = vertex_cc == ii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5eef006",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_touch_component = np.full(vass.faces.shape[0], False, dtype=bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f833372b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_faces = vass.faces[faces_chunk_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff9bc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "within_component_mask = vertex_cc == ii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135ff7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "relabel = np.where()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5c8d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "within_component_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb43546",
   "metadata": {},
   "outputs": [],
   "source": [
    "remap_dict = {k: ii for ii, k in enumerate(np.flatnonzero(within_component_mask))}\n",
    "chunk_faces_short = fastremap.remap(\n",
    "    chunk_faces, remap_dict\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dda0121",
   "metadata": {},
   "outputs": [],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1f6455",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d743c78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bcc240",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "np.flatnonzero(mask_in[vass.faces].sum(axis=1)>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ac4cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "faces_touching_vertices_numba(\n",
    "    vass.faces,\n",
    "    np.flatnonzero(mask_in),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44de5147",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "np.any(mask_in[vass.faces], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15b9da9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa6147d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nglui import statebuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba1c38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(mesh_label == -1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bba23e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_label = vass.lvl2_map()\n",
    "chunk_df = vass.chunk_df.copy()\n",
    "chunk_df['b'] = np.random.random(chunk_df.shape[0])\n",
    "chunk_df['g'] = np.random.random(chunk_df.shape[0])\n",
    "chunk_df['r'] = np.random.random(chunk_df.shape[0])\n",
    "\n",
    "vert_df = pd.DataFrame(\n",
    "    {\n",
    "        'point_x': vass.vertices[:,0],\n",
    "        'point_y': vass.vertices[:,1],\n",
    "        'point_z': vass.vertices[:,2],\n",
    "        'mesh_label': vass.mesh_label,\n",
    "    }\n",
    ")\n",
    "\n",
    "vert_df = vert_df.merge(\n",
    "    chunk_df[['r', 'g', 'b']],\n",
    "    right_index=True,\n",
    "    left_on='mesh_label',\n",
    "    how='left',\n",
    ")\n",
    "\n",
    "vert_df = vert_df.fillna(1)\n",
    "from nglui import skeletons\n",
    "skltor = skeletons.SkeletonManager(\n",
    "    client.cave,\n",
    "    cloudpath='gs://csm-skel/ngl3',\n",
    "    vertex_attributes=['r', 'g', 'b',],\n",
    "    initialize_info=True,\n",
    ")\n",
    "skltor.upload_skeleton(\n",
    "    root_id = rid,\n",
    "    vertices= vass.vertices,\n",
    "    edges = [],\n",
    "    vertex_attribute_data=vert_df[['r', 'g', 'b']],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53000853",
   "metadata": {},
   "outputs": [],
   "source": [
    "skltor.cloudpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474717b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c7bb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "vass.vertices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bc7093",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(vass.mesh_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68fb45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.neuroglancer_url(clipboard=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648291fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "(vass.mesh_label == -1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fac212",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, l2id in vass.chunk_df['l2id'].items():\n",
    "    skltor.upload_skeleton(\n",
    "        root_id = l2id,\n",
    "        vertices= vass.vertices[mesh_label == idx],\n",
    "        edges = [],\n",
    "        vertex_attribute_data=vert_df.query(\"mesh_label == @idx\")[['r', 'g', 'b']],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7dcb4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f567e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vass.chunk_df.query('l2id==168346295256221013')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce26514",
   "metadata": {},
   "outputs": [],
   "source": [
    "vass.chunk_df_multi.query('chunk_number == 361071634')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a6546b",
   "metadata": {},
   "outputs": [],
   "source": [
    "grps = [grp for _, grp in vass.chunk_df_multi.groupby('chunk_number')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f32f7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "grps[43]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776d169e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = client.cave.info.segmentation_cloudvolume()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39db0956",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = client.now() - datetime.timedelta(days=4*365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e68dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.cave.chunkedgraph.get_root_timestamps(169402444692849255)[0] - datetime.timedelta(seconds=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0519827",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.scattered_points([101197, 107655, 7874], agglomerate=True, stop_layer=2, timestamp=client.cave.chunkedgraph.get_root_timestamps(169402444692849255)[0] - datetime.timedelta(seconds=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42c38b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.scattered_points([101197, 107655, 7874], agglomerate=True, stop_layer=2,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee9c449",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.cave.chunkedgraph.get_roots()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cba7392",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_rows = vass.chunk_df_multi.query('chunk_number == 361071634')\n",
    "pts = chunk_rows[['pt_x', 'pt_y', 'pt_z']].values\n",
    "vertices = vass.vertices\n",
    "faces = vass.faces\n",
    "ts = vass.timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f6b158",
   "metadata": {},
   "outputs": [],
   "source": [
    "components, unassigned_mask = create_component_dict(chunk_rows, vertices, faces)\n",
    "\n",
    "wn_results = []\n",
    "for comp in components:\n",
    "    wn_results.append(\n",
    "        gyp.fast_winding_number(pts, comp[\"vertices\"], comp[\"faces\"])\n",
    "    )\n",
    "wn_results = np.array(wn_results).T\n",
    "\n",
    "pt_assign, mesh_assign = linear_sum_assignment(\n",
    "    np.array(wn_results) / np.max(wn_results), maximize=True\n",
    ")\n",
    "if len(pts) < len(components):\n",
    "    mesh_assign = mesh_assign[: len(pt_assign)]\n",
    "if len(pts) > len(components):\n",
    "    pt_assign = pt_assign[: len(mesh_assign)]\n",
    "result_df = pd.DataFrame(\n",
    "    {\n",
    "        \"representative_pt\": pt_assign.astype(int),\n",
    "        \"graph_comp\": mesh_assign.astype(int),\n",
    "    }\n",
    ")\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27870466",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1ae1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_distance = 400\n",
    "ratio_better = 0.25\n",
    "\n",
    "assigned_components = result_df[\"graph_comp\"].unique()\n",
    "\n",
    "first_comps = []\n",
    "second_comps = []\n",
    "first_assigned = []\n",
    "second_assigned = []\n",
    "ds = []\n",
    "kdtrees = [spatial.KDTree(comp[\"vertices\"]) for comp in components]\n",
    "for comp_a, comp_b in combinations(components, 2):\n",
    "    first_comps.append(comp_a[\"component_id\"])\n",
    "    second_comps.append(comp_b[\"component_id\"])\n",
    "    first_assigned.append(comp_a[\"component_id\"] in assigned_components)\n",
    "    second_assigned.append(comp_b[\"component_id\"] in assigned_components)\n",
    "    if not (\n",
    "        comp_a[\"component_id\"] in assigned_components\n",
    "        and comp_b[\"component_id\"] in assigned_components\n",
    "    ):\n",
    "        comp_ds = np.array(list(kdtrees[comp_a['component_id']].sparse_distance_matrix(\n",
    "            kdtrees[comp_b['component_id']], max_distance=max_distance / ratio_better, output_type='dok_matrix'\n",
    "        ).values()))\n",
    "        if len(comp_ds) > 0:\n",
    "            ds.append(np.min(comp_ds))\n",
    "        else:\n",
    "            ds.append(np.inf)\n",
    "    else:\n",
    "        ds.append(np.inf)\n",
    "distance_graph = pd.DataFrame(\n",
    "    {\n",
    "        \"first_comp\": first_comps,\n",
    "        \"second_comp\": second_comps,\n",
    "        \"first_assigned\": first_assigned,\n",
    "        \"second_assigned\": second_assigned,\n",
    "        \"distance\": ds,\n",
    "    }\n",
    ")\n",
    "distance_graph = distance_graph[distance_graph[\"distance\"] < max_distance]\n",
    "distance_graph[\"evaluated\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec12e607",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72170a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "while not np.all(distance_graph[\"evaluated\"]):\n",
    "    pairs_to_consider = distance_graph.query(\n",
    "        \"evaluated == False and first_assigned != second_assigned\"\n",
    "    ).sort_values(\"distance\")\n",
    "    if len(pairs_to_consider) == 0:\n",
    "        break\n",
    "    for gph_idx, row in pairs_to_consider.iterrows():\n",
    "        distance_graph.loc[gph_idx, \"evaluated\"] = True\n",
    "        if row[\"first_assigned\"]:\n",
    "            assigned_comp = row[\"first_comp\"]\n",
    "            unassigned_comp = row[\"second_comp\"]\n",
    "        else:\n",
    "            assigned_comp = row[\"second_comp\"]\n",
    "            unassigned_comp = row[\"first_comp\"]\n",
    "        ds_edge = (\n",
    "            pairs_to_consider.drop(index=gph_idx)\n",
    "            .query(\n",
    "                \"first_comp == @unassigned_comp or second_comp == @unassigned_comp and evaluated == False and first_assigned!=second_assigned\"\n",
    "            )[\"distance\"]\n",
    "            .values\n",
    "        )\n",
    "        do_assign = False\n",
    "        if len(ds_edge) == 0:\n",
    "            do_assign = True\n",
    "        elif row[\"distance\"] < ratio_better * np.min(ds_edge):\n",
    "            do_assign = True\n",
    "        if do_assign:\n",
    "            best_pt = result_df.query(\"graph_comp == @assigned_comp\")[\n",
    "                \"representative_pt\"\n",
    "            ].values[0]\n",
    "            result_df.loc[result_df.index[-1] + 1] = {\n",
    "                \"representative_pt\": best_pt,\n",
    "                \"graph_comp\": unassigned_comp,\n",
    "            }\n",
    "            distance_graph.loc[\n",
    "                distance_graph[\"first_comp\"] == unassigned_comp,\n",
    "                \"first_assigned\",\n",
    "            ] = True\n",
    "            distance_graph.loc[\n",
    "                distance_graph[\"second_comp\"] == unassigned_comp,\n",
    "                \"second_assigned\",\n",
    "            ] = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee871c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447ca05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50842fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729966e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(components) > len(pt_assign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1d1456",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19751d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_distance = 400\n",
    "ratio_better = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575d120f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394c6c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vass.representative_point_via_proximity(\n",
    "    components=components,\n",
    "    result_df=result_df,\n",
    "    max_distance=max_distance,\n",
    "    ratio_better=ratio_better,\n",
    ")aa\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1bd119",
   "metadata": {},
   "outputs": [],
   "source": [
    "assigned_components = result_df[\"graph_comp\"].unique()\n",
    "if len(assigned_components) == 0:\n",
    "    print('this one')\n",
    "vert_assigned = {\n",
    "    comp[\"component_id\"]: comp[\"vertices_in\"]\n",
    "    for comp in components\n",
    "    if comp[\"component_id\"] in assigned_components\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42af8ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "unassigned_components = [\n",
    "    comp\n",
    "    for comp in components\n",
    "    if comp[\"component_id\"] not in assigned_components\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121fc6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vass.find_closest_assigned_component(\n",
    "    unassigned_components[0],\n",
    "    vert_assigned,\n",
    "    max_distance=400,\n",
    "    ratio_better=0.25,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f172aa6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp = unassigned_components[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adb4252",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(vert_assigned) == 1:\n",
    "    print('nuttin')\n",
    "ds = np.array(\n",
    "    [np.min(cdist(comp[\"vertices\"], v)) for v in vert_assigned.values()]\n",
    ")\n",
    "print(ds)\n",
    "dist_sort = np.argsort(ds)\n",
    "if (\n",
    "    ds[dist_sort[0]] < ratio_better * ds[dist_sort[1]]\n",
    "    and ds[dist_sort[0]] < max_distance\n",
    "):\n",
    "    print(list(vert_assigned.keys())[dist_sort[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dad56b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = np.array([np.min(cdist(comp[\"vertices\"], v)) for v in vert_assigned.values()])\n",
    "# ds[ds == 0] = np.inf  # Ignore zero distances, since they would be attached\n",
    "dist_sort = np.argsort(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a7258e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275fef1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8244ccb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_assigned = vass.representative_point_via_proximity(\n",
    "    components=components,\n",
    "    result_df=result_df,\n",
    "    max_distance=250,\n",
    "    ratio_better=0.25,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30bb160",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_assigned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586d6a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "skltor.cloudpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5504b08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vs = (\n",
    "    statebuilder.ViewerState(client=client.cave)\n",
    "    .add_layers_from_client(segmentation='seg')\n",
    "    .add_segments([rid])\n",
    "    .add_points(\n",
    "        point_column='pt',\n",
    "        data_resolution=[1,1,1],\n",
    "        segment_column='l2id',\n",
    "        data=vass.chunk_df,\n",
    "    )\n",
    ").to_clipboard(shorten=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f4529a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = client.cave.info.segmentation_cloudvolume()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e007c724",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c096e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.parallel = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73279bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "meshes = client.mesh.get_meshes(l2ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd7b6b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3325d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_df.query('l2id == 166086454928212643')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a301dee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf8a86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "components, unassigned_mask = create_component_dict(\n",
    "    chunk_rows,\n",
    "    vass._vertices,\n",
    "    vass._faces,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1301680",
   "metadata": {},
   "outputs": [],
   "source": [
    "components[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bf148b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266c5ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pts = np.array(chunk_rows[[\"pt_x\", \"pt_y\", \"pt_z\"]].values, dtype=float)\n",
    "\n",
    "wn_results = []\n",
    "for comp in components:\n",
    "    wn_results.append(\n",
    "        gyp.fast_winding_number(pts, comp[\"vertices\"], comp[\"faces\"])\n",
    "    )\n",
    "wn_results = np.array(wn_results).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bd8d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_assign, mesh_assign = linear_sum_assignment(\n",
    "    np.array(wn_results) / np.max(wn_results), maximize=True\n",
    ")\n",
    "\n",
    "if len(pts) < len(components):\n",
    "    mesh_assign = mesh_assign[: len(pt_assign)]\n",
    "if len(pts) > len(components):\n",
    "    pt_assign = pt_assign[: len(mesh_assign)]\n",
    "result_df = pd.DataFrame(\n",
    "    {\n",
    "        \"representative_pt\": pt_assign.astype(int),\n",
    "        \"graph_comp\": mesh_assign.astype(int),\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad646d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f4bcea",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(components) > len(pt_assign):\n",
    "    for comp in components:\n",
    "        # If you have not already assigned a point to this component, use the slower cloudvolume lookup\n",
    "        if comp[\"component_id\"] not in result_df[\"graph_comp\"].values:\n",
    "            point_to_component = vass.representative_point_via_lookup(\n",
    "                chunk_rows=chunk_rows,\n",
    "                comp=comp,\n",
    "                timestamp=vass._timestamp,\n",
    "            )\n",
    "            if point_to_component == -1:\n",
    "                continue\n",
    "            result_df.loc[result_df.index[-1] + 1] = {\n",
    "                \"representative_pt\": point_to_component,\n",
    "                \"graph_comp\": comp[\"component_id\"],\n",
    "            }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90967d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba4a4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2ids = chunk_rows[\"l2id\"].values\n",
    "l2id = vass.get_mesh_l2id_from_lookup(\n",
    "    comp,\n",
    "    point_counts=[10, 50, 100, 200, 500],\n",
    "    potential_l2ids=l2ids,\n",
    "    timestamp=vass._timestamp,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80dabdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vass.representative_point_via_lookup(\n",
    "    chunk_rows=chunk_rows,\n",
    "    comp=components[0],\n",
    "    timestamp=vass._timestamp,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e34a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2ids = chunk_rows[\"l2id\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf4cdab",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2id = vass.get_mesh_l2id_from_lookup(\n",
    "    comp,\n",
    "    point_counts=[10, 50, 100, 200, 500],\n",
    "    potential_l2ids=l2ids,\n",
    "    timestamp=vass._timestamp,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c6c168",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e5a55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "point_to_component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193f54e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "[c['component_id'] for c in components]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00108c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "wn_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fa3c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "vass.process_multicomponent_chunk(\n",
    "    chunk_rows,\n",
    "    vass._vertices,\n",
    "    vass._faces,\n",
    "    vass._timestamp,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e9780e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26a8d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_mapping = []\n",
    "for _, chunk_rows in tqdm(vass._chunk_df_multi.groupby(\"chunk_number\")):\n",
    "    id_mapping.extend(\n",
    "        vass.process_multicomponent_chunk(\n",
    "            chunk_rows, vass._vertices, vass._faces, vass._timestamp\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d437f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "grps = [grp for _, grp in vass._chunk_df_multi.groupby(\"chunk_number\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40303b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "grp = grps[484]\n",
    "vass.process_multicomponent_chunk(\n",
    "    grp, vass._vertices, vass._faces, vass._timestamp\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cf4902",
   "metadata": {},
   "outputs": [],
   "source": [
    "assignment_df, component_mask_dict, unassigned_mask = (\n",
    "    vass.assign_points_to_components(\n",
    "        grp,\n",
    "        vass._vertices,\n",
    "        vass._faces,\n",
    "        vass._timestamp,\n",
    "    )\n",
    ")\n",
    "\n",
    "chunk_rows = grp\n",
    "pts = np.array(chunk_rows[[\"pt_x\", \"pt_y\", \"pt_z\"]].values, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da77a5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "components, unassigned_mask = create_component_dict(chunk_rows, vass._vertices, vass._faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40d4c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85df3466",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951c9fc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813f7226",
   "metadata": {},
   "outputs": [],
   "source": [
    "[len(c['vertices']) for c in components]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc21f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "wn_results = []\n",
    "for comp in components:\n",
    "    wn_results.append(\n",
    "        gyp.fast_winding_number(pts, comp[\"vertices\"], comp[\"faces\"])\n",
    "    )\n",
    "wn_results = np.array(wn_results).T\n",
    "pt_assign, mesh_assign = linear_sum_assignment(\n",
    "    np.array(wn_results) / np.max(wn_results), maximize=True\n",
    ")\n",
    "if len(pts) < len(components):\n",
    "    mesh_assign = mesh_assign[: len(pt_assign)]\n",
    "if len(pts) > len(components):\n",
    "    print(\n",
    "        f\"More points than components for chunk number {chunk_rows.iloc[0, 'chunk_number']}\"\n",
    "    )\n",
    "    pt_assign = pt_assign[: len(mesh_assign)]\n",
    "result_df = pd.DataFrame(\n",
    "    {\n",
    "        \"representative_pt\": pt_assign.astype(int),\n",
    "        \"graph_comp\": mesh_assign.astype(int),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6630657e",
   "metadata": {},
   "outputs": [],
   "source": [
    "wn_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598f026a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49919bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_assign, mesh_assign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68373435",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394d96e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c4a8f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294ec506",
   "metadata": {},
   "outputs": [],
   "source": [
    "component_mask_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4635ec5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9329f57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "unassigned_mask.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e986eaae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8545d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_solo, df_multi = vass.get_chunk_dataframes(rid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb1b227",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_mapping_solo = vass.process_solo_chunks(df_solo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef0170c",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2ids, l2_pts = vass.get_l2_components(rid)\n",
    "vertices, faces = vass.get_mesh_data(rid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772ff605",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_df_solo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_df = vass.chunk_dataframe(l2ids, l2_pts)\n",
    "\n",
    "chunk_df_solo = chunk_df.drop_duplicates('chunk_number', keep=False)\n",
    "mesh_label = np.zeros(mesh.vertices.shape[0], dtype=int)-1\n",
    "for i, row in tqdm(chunk_df_solo.iterrows()):\n",
    "    mask = bbox_mask(row, mesh.vertices)\n",
    "    mesh_label[mask] = i\n",
    "\n",
    "chunk_df_multi = chunk_df[chunk_df.duplicated('chunk_number', keep=False)]\n",
    "grps = [group for _, group in chunk_df_multi.groupby('chunk_number')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd154475",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.cave.chunkedgraph.get_leaves(rid, stop_layer=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef32647a",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2ids = client.cave.chunkedgraph.get_\n",
    "pts = get_lvl2_points(l2ids, client.cave)\n",
    "\n",
    "chunk_df = chunk_dataframe(l2ids, pts, cv)\n",
    "\n",
    "chunk_df_solo = chunk_df.drop_duplicates('chunk_number', keep=False)\n",
    "mesh_label = np.zeros(mesh.vertices.shape[0], dtype=int)-1\n",
    "for i, row in tqdm(chunk_df_solo.iterrows()):\n",
    "    mask = bbox_mask(row, mesh.vertices)\n",
    "    mesh_label[mask] = i\n",
    "\n",
    "chunk_df_multi = chunk_df[chunk_df.duplicated('chunk_number', keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64333573",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12dce59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import fastremap\n",
    "import gpytoolbox as gyp\n",
    "import trimesh\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from scipy import sparse\n",
    "from scipy.spatial.distance import cdist\n",
    "import datetime\n",
    "import cloudvolume\n",
    "\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from contextlib import contextmanager\n",
    "from io import StringIO\n",
    "\n",
    "@contextmanager\n",
    "def suppress_output():\n",
    "    \"\"\"Context manager to suppress stdout and stderr output.\"\"\"\n",
    "    # Save original stdout and stderr\n",
    "    original_stdout = sys.stdout\n",
    "    original_stderr = sys.stderr\n",
    "    \n",
    "    try:\n",
    "        # Redirect to devnull or StringIO\n",
    "        with open(os.devnull, 'w') as devnull:\n",
    "            sys.stdout = devnull\n",
    "            sys.stderr = devnull\n",
    "            yield\n",
    "    finally:\n",
    "        # Restore original stdout and stderr\n",
    "        sys.stdout = original_stdout\n",
    "        sys.stderr = original_stderr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb134485",
   "metadata": {},
   "outputs": [],
   "source": [
    "pf_df = client.tables.proofreading_status_and_strategy(status_axon=True).query()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cd3200",
   "metadata": {},
   "outputs": [],
   "source": [
    "rid = pf_df.pt_root_id.iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36a89b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh = client.mesh.get_mesh(rid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e94931",
   "metadata": {},
   "outputs": [],
   "source": [
    "nrn = client.get_skeleton(rid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4379bb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lvl2_points(\n",
    "    l2ids,\n",
    "    caveclient,\n",
    "):\n",
    "    data = caveclient.l2cache.get_l2data(l2ids, attributes=['rep_coord_nm'])\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            'lvl2_id': [int(x) for x in data.keys()],\n",
    "            'pt_x': [x['rep_coord_nm'][0] for x in data.values()],\n",
    "            'pt_y': [x['rep_coord_nm'][1] for x in data.values()],\n",
    "            'pt_z': [x['rep_coord_nm'][2] for x in data.values()],\n",
    "        }\n",
    "    ).set_index('lvl2_id')\n",
    "\n",
    "    return df.loc[l2ids][['pt_x', 'pt_y', 'pt_z']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83f8e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = client.cave.info.segmentation_cloudvolume()\n",
    "cv.image.lru.resize(10*1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35223882",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_to_nm(xyz_ch, cv):\n",
    "    \"\"\"Map a chunk location to Euclidean space\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    xyz_ch : array-like\n",
    "        Nx3 array of chunk indices\n",
    "    cv : cloudvolume.CloudVolume\n",
    "        CloudVolume object associated with the chunked space\n",
    "    voxel_resolution : list, optional\n",
    "        Voxel resolution, by default [4, 4, 40]\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.array\n",
    "        Nx3 array of spatial points\n",
    "    \"\"\"\n",
    "    base_location = (cv.meta.voxel_offset(0) * cv.mip_resolution(0))\n",
    "    x_vox = np.atleast_2d(xyz_ch) * cv.meta.graph_chunk_size * cv.mip_resolution(0)\n",
    "    return base_location + x_vox\n",
    "\n",
    "\n",
    "def chunk_dims(cv):\n",
    "    \"\"\"Gets the size of a chunk in euclidean space\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cv : cloudvolume.CloudVolume\n",
    "        Chunkedgraph-targeted cloudvolume object\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.array\n",
    "        3-element box dimensions of a chunk in nanometers.\n",
    "    \"\"\"\n",
    "    dims = chunk_to_nm([1, 1, 1], cv) - chunk_to_nm([0, 0, 0], cv)\n",
    "    return np.squeeze(dims)\n",
    "\n",
    "def adjust_for_draco(\n",
    "    vals,\n",
    "    draco_size,\n",
    "):\n",
    "    \"Adjust grid locations to align with the discrete draco grid\"\n",
    "    return draco_size * np.floor(vals / draco_size)\n",
    "\n",
    "def make_chunk_bbox(l2ids, cv, adjust_draco=True):\n",
    "    chunk_numbers = [int(cv.meta.decode_chunk_position_number(l)) for l in l2ids]\n",
    "    chunk_grid = np.array([np.array(cv.meta.decode_chunk_position(l)) for l in l2ids])\n",
    "    chunk_start = chunk_to_nm(chunk_grid, cv)\n",
    "    chunk_end = chunk_start + chunk_dims(cv)\n",
    "\n",
    "    if adjust_draco:\n",
    "        draco_size = cv.meta.get_draco_grid_size(0)\n",
    "        chunk_start = adjust_for_draco(chunk_start, draco_size)\n",
    "        chunk_end = adjust_for_draco(chunk_end, draco_size)\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            'l2id': l2ids.astype(int),\n",
    "            'chunk_x': chunk_grid[:, 0],\n",
    "            'chunk_y': chunk_grid[:, 1],\n",
    "            'chunk_z': chunk_grid[:, 2],\n",
    "            'bbox_start_x': chunk_start[:, 0],\n",
    "            'bbox_start_y': chunk_start[:, 1],\n",
    "            'bbox_start_z': chunk_start[:, 2],\n",
    "            'bbox_end_x': chunk_end[:, 0],\n",
    "            'bbox_end_y': chunk_end[:, 1],\n",
    "            'bbox_end_z': chunk_end[:, 2],\n",
    "            'chunk_number': chunk_numbers,\n",
    "        }\n",
    "    )\n",
    "    return df\n",
    "\n",
    "def chunk_dataframe(l2ids, points, cv):\n",
    "    \"\"\"Create a dataframe of chunk bounding boxes for a neuron\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    l2ids : array-like\n",
    "        List of level 2 IDs\n",
    "    points : pd.DataFrame\n",
    "        DataFrame containing point coordinates\n",
    "    cv : cloudvolume.CloudVolume\n",
    "        CloudVolume object associated with the chunked space\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        DataFrame containing bounding boxes for each chunk in the neuron\n",
    "    \"\"\"\n",
    "    df = make_chunk_bbox(l2ids, cv)\n",
    "    pt_df = pd.DataFrame(\n",
    "        {\n",
    "            'l2id': l2ids.astype(int),\n",
    "            'pt_x': points[:, 0],\n",
    "            'pt_y': points[:, 1],\n",
    "            'pt_z': points[:, 2],\n",
    "        }\n",
    "    )\n",
    "    return df.merge(\n",
    "        pt_df,\n",
    "        on='l2id',\n",
    "        how='left',\n",
    "    )\n",
    "\n",
    "\n",
    "def bbox_mask(\n",
    "    row,\n",
    "    vertices,\n",
    "    inclusive=True,\n",
    "):\n",
    "    \"\"\"Create a mask for vertices within a bounding box defined by a row of chunk_df_solo\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    row : pd.Series\n",
    "        A row from chunk_df_solo containing bounding box coordinates\n",
    "    vertices : np.ndarray\n",
    "        Array of vertex positions\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        Boolean mask indicating which vertices are within the bounding box\n",
    "    \"\"\"\n",
    "    if inclusive:\n",
    "        return (\n",
    "            (vertices[:, 0] >= row['bbox_start_x'])\n",
    "            & (vertices[:, 0] <= row['bbox_end_x'])\n",
    "            & (vertices[:, 1] >= row['bbox_start_y'])\n",
    "            & (vertices[:, 1] <= row['bbox_end_y'])\n",
    "            & (vertices[:, 2] >= row['bbox_start_z'])\n",
    "            & (vertices[:, 2] <= row['bbox_end_z'])\n",
    "        )\n",
    "    else:\n",
    "        return (\n",
    "            (vertices[:, 0] >= row['bbox_start_x'])\n",
    "            & (vertices[:, 0] < row['bbox_end_x'])\n",
    "            & (vertices[:, 1] >= row['bbox_start_y'])\n",
    "            & (vertices[:, 1] < row['bbox_end_y'])\n",
    "            & (vertices[:, 2] >= row['bbox_start_z'])\n",
    "            & (vertices[:, 2] < row['bbox_end_z'])\n",
    "        )\n",
    "\n",
    "def component_submesh(\n",
    "    within_component_mask,\n",
    "    mask_in,\n",
    "    mask_all,\n",
    "    vertices,\n",
    "    faces,\n",
    "):\n",
    "    \"\"\"Create a submesh for the specific component of the mesh\"\"\"\n",
    "    component_mask = mask_in.copy()\n",
    "    component_mask[mask_in] = within_component_mask\n",
    "\n",
    "    face_mask_inclusive = mask_all[faces]\n",
    "    # I want faces that have all values in the boundary inclusive mask and any values in the component mask.\n",
    "\n",
    "    face_in_chunk = np.all(face_mask_inclusive, axis=1)\n",
    "    face_touch_component = np.any(component_mask[faces], axis=1)\n",
    "\n",
    "    component_faces = faces[face_in_chunk & face_touch_component]\n",
    "    component_vertex_indices = np.unique(np.concatenate((component_faces.ravel(), np.flatnonzero(component_mask))))\n",
    "    vertex_mask = np.zeros(vertices.shape[0], dtype=bool)\n",
    "    vertex_mask[component_vertex_indices] = True\n",
    "    relabel = {v: k for k, v in enumerate(np.flatnonzero(vertex_mask))}\n",
    "    component_faces = fastremap.remap(component_faces, relabel)\n",
    "    return vertices[component_vertex_indices], component_faces, component_mask\n",
    "\n",
    "def create_component_dict(chunk_rows, vertices, faces):\n",
    "    mask_all = bbox_mask(chunk_rows.iloc[0], vertices, inclusive=True)\n",
    "    mask_in = bbox_mask(chunk_rows.iloc[0], vertices, inclusive=False)\n",
    "\n",
    "    minds = np.flatnonzero(mask_in)\n",
    "    relabel = {v:k for k,v in enumerate(minds)}\n",
    "\n",
    "    face_mask = mask_in[faces]\n",
    "    faces_relabel = fastremap.remap(\n",
    "        faces[np.all(face_mask, axis=1)],\n",
    "        relabel,\n",
    "    )\n",
    "\n",
    "    # Make sure isolated vertices are included in the components\n",
    "    face_identity = np.array([[ii, ii, ii] for ii in range(len(minds))])\n",
    "    vertex_cc = gyp.connected_components(np.vstack([faces_relabel, face_identity]))\n",
    "\n",
    "    # Now for each component, find the faces associated with its true vertices plus any faces that are only on the boundary of the chunk\n",
    "    components = []\n",
    "    for ii in np.unique(vertex_cc):\n",
    "        comp_verts, comp_faces, comp_mask = component_submesh(vertex_cc == ii, mask_in, mask_all, vertices, faces)\n",
    "        if comp_faces.shape[0] == 0:\n",
    "            continue\n",
    "        components.append(\n",
    "            {\n",
    "                'component_id': int(ii),\n",
    "                'vertices': comp_verts,\n",
    "                'faces': comp_faces,\n",
    "                'mask': comp_mask,\n",
    "            }\n",
    "        )\n",
    "    return components\n",
    "\n",
    "\n",
    "# def make_chunk_mesh(\n",
    "#     vertices,\n",
    "#     faces,\n",
    "#     mask,\n",
    "#     chunk_component_df,\n",
    "# ):\n",
    "#     \"Generate a mesh for the parts of a mesh within a chunk bounding box\"\n",
    "\n",
    "#     relabel = {v:k for k,v in chunk_component_df.to_dict()['mind'].items()}\n",
    "#     face_mask = mask[faces]\n",
    "#     faces_relabel = fastremap.remap(\n",
    "#         faces[np.all(face_mask, axis=1)],\n",
    "#         relabel,\n",
    "#     )\n",
    "\n",
    "#     edgeonly_faces = np.flatnonzero(np.sum(face_mask, axis=1) == 2)\n",
    "#     bonus_edges = []\n",
    "#     if len(edgeonly_faces) == 0:\n",
    "#         return trimesh.Trimesh(\n",
    "#             vertices=vertices[mask],\n",
    "#             faces=faces_relabel,\n",
    "#             validate=False,\n",
    "#             process=False,\n",
    "#         ), np.zeros((0,2), dtype=int)\n",
    "#     for row, row_mask in zip(faces[edgeonly_faces], mask[faces[edgeonly_faces]]):\n",
    "#         bonus_edges.append(row[row_mask])\n",
    "#     bonus_edges = fastremap.remap(bonus_edges, relabel)\n",
    "\n",
    "#     return trimesh.Trimesh(\n",
    "#         vertices=vertices[mask],\n",
    "#         faces=faces_relabel,\n",
    "#         validate=False,\n",
    "#         process=False,\n",
    "#     ), bonus_edges\n",
    "\n",
    "# def within_chunk_components(\n",
    "#     chunk_mesh,\n",
    "#     bonus_edges,\n",
    "# ):\n",
    "#     \"\"\"Determine vertex connected components within a chunk mesh\"\"\"\n",
    "\n",
    "#     mesh_edges = np.vstack([chunk_mesh.edges, bonus_edges])\n",
    "#     A = sparse.coo_matrix(\n",
    "#         (np.ones(mesh_edges.shape[0]), (mesh_edges[:,0], mesh_edges[:,1]) ),\n",
    "#         shape=(chunk_mesh.vertices.shape[0], chunk_mesh.vertices.shape[0]),\n",
    "#     )\n",
    "#     _, comp = sparse.csgraph.connected_components(A + A.T)\n",
    "#     return comp\n",
    "\n",
    "def assign_points_to_components(\n",
    "    chunk_rows,\n",
    "    vertices,\n",
    "    faces,\n",
    "    cv,\n",
    "    ts,\n",
    "):\n",
    "    \"\"\"Assign representative points to components in a chunk mesh.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        DataFrame containing the index of the representative point in the chunk_rows dataframe and the component ID.\n",
    "\n",
    "    dict\n",
    "        Dictionary mapping component IDs to masks for the vertices in the global mesh.\n",
    "    \"\"\"\n",
    "    pts = np.array(chunk_rows[['pt_x', 'pt_y', 'pt_z']].values, dtype=float)\n",
    "    components = create_component_dict(chunk_rows, vertices, faces)\n",
    "    if len(components) == 0:\n",
    "        return pd.DataFrame(\n",
    "            {\n",
    "                'representative_pt': [],\n",
    "                'graph_comp': [],\n",
    "            }\n",
    "        ), {}\n",
    "    wn_results = []\n",
    "    for comp in components:\n",
    "        wn_results.append(gyp.fast_winding_number(pts, comp['vertices'], comp['faces']))\n",
    "\n",
    "    pt_assign, mesh_assign = linear_sum_assignment(\n",
    "        np.array(wn_results) / np.max(wn_results),\n",
    "        maximize=True\n",
    "    )\n",
    "\n",
    "    # If there are more components than points, don't assign components to the lower-scoring ones\n",
    "    if len(pts) < len(components):\n",
    "        mesh_assign = mesh_assign[:len(pt_assign)]\n",
    "    if len(pts) > len(components):\n",
    "        print(f\"More points than components for chunk number {chunk_rows.iloc[0]['chunk_number']}\")\n",
    "        pt_assign = pt_assign[:len(mesh_assign)]\n",
    "    result_df = pd.DataFrame(\n",
    "        {\n",
    "            'representative_pt': pt_assign.astype(int),\n",
    "            'graph_comp': mesh_assign.astype(int),\n",
    "        }\n",
    "    )\n",
    "    comp_mask_dict = {}\n",
    "\n",
    "    if len(components) > len(pts):\n",
    "        for comp in components:\n",
    "            # If you have not already assigned a point to this component, use the slower cloudvolume lookup\n",
    "            if comp['component_id'] not in comp_mask_dict:\n",
    "                point_to_component = representative_point_via_lookup(\n",
    "                    chunk_rows=chunk_rows,\n",
    "                    comp=comp,\n",
    "                    timestamp=ts,\n",
    "                    cv=cv,\n",
    "                )\n",
    "                if point_to_component == -1:\n",
    "                    continue\n",
    "                result_df.loc[result_df.index[-1] + 1] = {'representative_pt': point_to_component, 'graph_comp': comp['component_id']}\n",
    "\n",
    "    for comp in components:\n",
    "        if comp['component_id'] in result_df['graph_comp'].values:\n",
    "            comp_mask_dict[comp['component_id']] = comp['mask']\n",
    "\n",
    "    return result_df, comp_mask_dict\n",
    "\n",
    "\n",
    "def get_mesh_l2id_from_lookup(\n",
    "    comp: dict,\n",
    "    timestamp: datetime.datetime,\n",
    "    cv: cloudvolume.CloudVolume,\n",
    "    point_counts: list = [10, 50, 100, 200, 400, 1000],\n",
    "    potential_l2ids: np.ndarray = None,\n",
    "):\n",
    "\n",
    "    comp_bbox  = np.vstack([np.min(comp['vertices'], axis=0), np.max(comp['vertices'], axis=0)])\n",
    "    not_enough_points = True\n",
    "\n",
    "    while not_enough_points:\n",
    "        if len(point_counts) == 0:\n",
    "            return -1\n",
    "        N = point_counts.pop(0)\n",
    "        random_points = np.random.uniform(\n",
    "            low=comp_bbox[0],\n",
    "            high=comp_bbox[1],\n",
    "            size=(N, 3)\n",
    "        )\n",
    "        with suppress_output():\n",
    "            pt_lookup = np.array(list(cv.scattered_points(\n",
    "                random_points,\n",
    "                mip=0,\n",
    "                coord_resolution=[1,1,1],\n",
    "                agglomerate=True,\n",
    "                stop_layer=2,\n",
    "                timestamp=timestamp,\n",
    "            ).values()))\n",
    "\n",
    "        if potential_l2ids is None:\n",
    "            potential_l2ids = np.unique(pt_lookup)\n",
    "        point_in_root = np.isin(pt_lookup, potential_l2ids)\n",
    "        if np.sum(point_in_root) >= 1:\n",
    "            not_enough_points = False\n",
    "        elif point_in_root.sum() == 0:\n",
    "            print(\"No points found in the root. Trying again with more points.\")\n",
    "            continue\n",
    "        l2ids, counts = np.unique(pt_lookup[point_in_root], return_counts=True)\n",
    "        return l2ids[np.argmax(counts)]\n",
    "\n",
    "def representative_point_via_lookup(\n",
    "        chunk_rows,\n",
    "        comp,\n",
    "        timestamp,\n",
    "        cv,\n",
    "        point_counts=[10, 50, 100, 200, 400, 1000],\n",
    "    ):\n",
    "    l2ids = chunk_rows['l2id'].values\n",
    "    l2id = get_mesh_l2id_from_lookup(\n",
    "        comp,\n",
    "        cv=cv,\n",
    "        point_counts=point_counts,\n",
    "        potential_l2ids=l2ids,\n",
    "        timestamp=timestamp,\n",
    "    )\n",
    "    if l2id == -1:\n",
    "        return -1\n",
    "    else:\n",
    "        return int(np.flatnonzero(l2ids == l2id)[0])\n",
    "    \n",
    "def all_on_border(\n",
    "    vertices,\n",
    "    chunk_row,\n",
    "):\n",
    "    return np.all(\n",
    "        vertices[:, 0] == chunk_row['bbox_start_x']\n",
    "    ) | np.all(\n",
    "        vertices[:, 1] == chunk_row['bbox_start_y']\n",
    "    ) | np.all(\n",
    "        vertices[:, 2] == chunk_row['bbox_start_z']\n",
    "    )\n",
    "\n",
    "def restrict_submesh(submesh):\n",
    "    submesh.faces = submesh.faces[~np.all(submesh.faces==0, axis=1)]\n",
    "    inds = np.unique(submesh.faces)\n",
    "    submesh.vertices = submesh.vertices[inds]\n",
    "    submesh.faces = fastremap.remap(\n",
    "        submesh.faces,\n",
    "        {v: k for k, v in enumerate(inds)},\n",
    "    )\n",
    "    return submesh\n",
    "\n",
    "def process_multicomponent_chunk(\n",
    "    chunk_rows: pd.DataFrame,\n",
    "    vertices: np.ndarray,\n",
    "    faces: np.ndarray,\n",
    "    timestamp: datetime.datetime,\n",
    "):\n",
    "    \"\"\"Process one chunk of a mesh defined by its vertices and faces\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    chunk_rows : pd.DataFrame\n",
    "        DataFrame containing chunk bounding box information and vertex positions\n",
    "    vertices : np.ndarray\n",
    "        Array of vertex positions for the complete mesh\n",
    "    faces : np.ndarray\n",
    "        Array of face indices for the complete mesh\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        A tuple containing two arrays, both with one entry for every vertex contained in the chunk bounding box:\n",
    "        - `mind`: Indices of mesh vertices in the chunk\n",
    "        - `l2id_index`: Indices of the representative points in the chunk as defined by the chunk_rows DataFrame\n",
    "    \"\"\"\n",
    "    \n",
    "    # To get the right mesh faces for association, we need to include the vertices on chunk bounds even if we don't plan to assign values to them\n",
    "    assignment_df, component_mask = assign_points_to_components(\n",
    "        chunk_rows,\n",
    "        vertices,\n",
    "        faces,\n",
    "        timestamp,\n",
    "    )\n",
    "\n",
    "    return assignment_df, component_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18d2f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookup_boundary_point_from_proximity(\n",
    "    vertices,\n",
    "    pts,\n",
    "):\n",
    "    \"\"\"Given a set of vertices that are only along the boundary of a chunk, find the spatially closest point to the vertices\"\"\"\n",
    "    dists = cdist(pts, vertices)\n",
    "    closest_indices = np.argmin(dists, axis=1)\n",
    "    return \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fba1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_chunk_submeshes(\n",
    "    vertices,\n",
    "    faces,\n",
    "    mask_inside,\n",
    "    mask_all,\n",
    "    chunk_component_df,\n",
    "):\n",
    "    \"Generate a mesh for the parts of a mesh within a chunk bounding box\"\n",
    "\n",
    "    relabel = {v:k for k,v in chunk_component_df.to_dict()['mind'].items()}\n",
    "    face_mask = mask_all[faces]\n",
    "    faces_relabel = fastremap.remap(\n",
    "        faces[np.all(face_mask, axis=1)],\n",
    "        relabel,\n",
    "    )\n",
    "\n",
    "    edgeonly_faces = np.flatnonzero(np.sum(face_mask, axis=1) == 2)\n",
    "    bonus_edges = []\n",
    "    if len(edgeonly_faces) == 0:\n",
    "        return trimesh.Trimesh(\n",
    "            vertices=vertices[mask_all],\n",
    "            faces=faces_relabel,\n",
    "            validate=False,\n",
    "            process=False,\n",
    "        ), np.zeros((0,2), dtype=int)\n",
    "    for row, row_mask in zip(faces[edgeonly_faces], mask_all[faces[edgeonly_faces]]):\n",
    "        bonus_edges.append(row[row_mask])\n",
    "    bonus_edges = fastremap.remap(bonus_edges, relabel)\n",
    "\n",
    "    return trimesh.Trimesh(\n",
    "        vertices=vertices[mask_all],\n",
    "        faces=faces_relabel,\n",
    "        validate=False,\n",
    "        process=False,\n",
    "    ), bonus_edges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c6083c",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2ids = nrn.anno.lvl2_ids.df.lvl2_id.values\n",
    "pts = get_lvl2_points(l2ids, client.cave)\n",
    "\n",
    "chunk_df = chunk_dataframe(l2ids, pts, cv)\n",
    "\n",
    "chunk_df_solo = chunk_df.drop_duplicates('chunk_number', keep=False)\n",
    "mesh_label = np.zeros(mesh.vertices.shape[0], dtype=int)-1\n",
    "for i, row in tqdm(chunk_df_solo.iterrows()):\n",
    "    mask = bbox_mask(row, mesh.vertices)\n",
    "    mesh_label[mask] = i\n",
    "\n",
    "chunk_df_multi = chunk_df[chunk_df.duplicated('chunk_number', keep=False)]\n",
    "grps = [group for _, group in chunk_df_multi.groupby('chunk_number')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb80c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_rows = grps[887]\n",
    "pts = chunk_rows[['pt_x', 'pt_y', 'pt_z']].values\n",
    "vertices = mesh.vertices\n",
    "faces = mesh.faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8586d89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def component_submesh(\n",
    "    within_component_mask,\n",
    "    mask_in,\n",
    "    mask_all,\n",
    "    vertices,\n",
    "    faces,\n",
    "):\n",
    "    \"\"\"Create a submesh for the specific component of the mesh\"\"\"\n",
    "    component_mask = mask_in.copy()\n",
    "    component_mask[mask_in] = within_component_mask\n",
    "\n",
    "    face_mask_inclusive = mask_all[faces]\n",
    "    # I want faces that have all values in the boundary inclusive mask and any values in the component mask.\n",
    "\n",
    "    face_in_chunk = np.all(face_mask_inclusive, axis=1)\n",
    "    face_touch_component = np.any(component_mask[faces], axis=1)\n",
    "\n",
    "    component_faces = faces[face_in_chunk & face_touch_component]\n",
    "    component_vertex_indices = np.unique(np.concatenate((component_faces.ravel(), np.flatnonzero(component_mask))))\n",
    "    vertex_mask = np.zeros(vertices.shape[0], dtype=bool)\n",
    "    vertex_mask[component_vertex_indices] = True\n",
    "    relabel = {v: k for k, v in enumerate(np.flatnonzero(vertex_mask))}\n",
    "    component_faces = fastremap.remap(component_faces, relabel)\n",
    "    return vertices[component_vertex_indices], component_faces, component_mask\n",
    "\n",
    "def create_component_dict(chunk_rows, vertices, faces):\n",
    "    mask_all = bbox_mask(chunk_rows.iloc[0], vertices, inclusive=True)\n",
    "    mask_in = bbox_mask(chunk_rows.iloc[0], vertices, inclusive=False)\n",
    "\n",
    "    minds = np.flatnonzero(mask_in)\n",
    "    relabel = {v:k for k,v in enumerate(minds)}\n",
    "\n",
    "    face_mask = mask_in[faces]\n",
    "    faces_relabel = fastremap.remap(\n",
    "        faces[np.all(face_mask, axis=1)],\n",
    "        relabel,\n",
    "    )\n",
    "\n",
    "    # Make sure isolated vertices are included in the components\n",
    "    face_identity = np.array([[ii, ii, ii] for ii in range(len(minds))])\n",
    "    vertex_cc = gyp.connected_components(np.vstack([faces_relabel, face_identity]))\n",
    "\n",
    "    # Now for each component, find the faces associated with its true vertices plus any faces that are only on the boundary of the chunk\n",
    "    components = []\n",
    "    assigned_vertices = np.full(mask_in.shape[0], False, dtype=bool)\n",
    "    for ii in np.unique(vertex_cc):\n",
    "        comp_verts, comp_faces, comp_mask = component_submesh(vertex_cc == ii, mask_in, mask_all, vertices, faces)\n",
    "        assigned_vertices[comp_mask] = True\n",
    "        if comp_faces.shape[0] == 0:\n",
    "            continue\n",
    "        components.append(\n",
    "            {\n",
    "                'component_id': int(ii),\n",
    "                'vertices': comp_verts,\n",
    "                'faces': comp_faces,\n",
    "                'mask': comp_mask,\n",
    "            }\n",
    "        )\n",
    "    unassigned_mask = np.logical_and(mask_in, np.logical_not(assigned_vertices))\n",
    "    return components, unassigned_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a1ca97",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_rows.iloc[0, 'chunk_number']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b6a314",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import cloudvolume\n",
    "\n",
    "def assign_points_to_components(\n",
    "    chunk_rows,\n",
    "    vertices,\n",
    "    faces,\n",
    "    cv,\n",
    "    ts,\n",
    "):\n",
    "    \"\"\"Assign representative points to components in a chunk mesh.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        DataFrame containing the index of the representative point in the chunk_rows dataframe and the component ID.\n",
    "\n",
    "    dict\n",
    "        Dictionary mapping component IDs to masks for the vertices in the global mesh.\n",
    "    \"\"\"\n",
    "    pts = np.array(chunk_rows[['pt_x', 'pt_y', 'pt_z']].values, dtype=float)\n",
    "    components = create_component_dict(chunk_rows, vertices, faces)\n",
    "    if len(components) == 0:\n",
    "        return pd.DataFrame(\n",
    "            {\n",
    "                'representative_pt': [],\n",
    "                'graph_comp': [],\n",
    "            }\n",
    "        ), {}\n",
    "    wn_results = []\n",
    "    for comp in components:\n",
    "        wn_results.append(gyp.fast_winding_number(pts, comp['vertices'], comp['faces']))\n",
    "\n",
    "    pt_assign, mesh_assign = linear_sum_assignment(\n",
    "        np.array(wn_results) / np.max(wn_results),\n",
    "        maximize=True\n",
    "    )\n",
    "\n",
    "    # If there are more components than points, don't assign components to the lower-scoring ones\n",
    "    if len(pts) < len(components):\n",
    "        mesh_assign = mesh_assign[:len(pt_assign)]\n",
    "    if len(pts) > len(components):\n",
    "        print(f\"More points than components for chunk number {chunk_rows.iloc[0, 'chunk_number']}\")\n",
    "        pt_assign = pt_assign[:len(mesh_assign)]\n",
    "    result_df = pd.DataFrame(\n",
    "        {\n",
    "            'representative_pt': pt_assign.astype(int),\n",
    "            'graph_comp': mesh_assign.astype(int),\n",
    "        }\n",
    "    )\n",
    "    comp_mask_dict = {}\n",
    "\n",
    "    if len(components) > len(pts):\n",
    "        for comp in components:\n",
    "            # If you have not already assigned a point to this component, use the slower cloudvolume lookup\n",
    "            if comp['component_id'] not in comp_mask_dict:\n",
    "                point_to_component = representative_point_via_lookup(\n",
    "                    chunk_rows=chunk_rows,\n",
    "                    comp=comp,\n",
    "                    timestamp=ts,\n",
    "                    cv=cv,\n",
    "                )\n",
    "                if point_to_component == -1:\n",
    "                    continue\n",
    "                result_df.loc[result_df.index[-1] + 1] = {'representative_pt': point_to_component, 'graph_comp': comp['component_id']}\n",
    "\n",
    "    for comp in components:\n",
    "        if comp['component_id'] in result_df['graph_comp'].values:\n",
    "            comp_mask_dict[comp['component_id']] = comp['mask']\n",
    "\n",
    "    return result_df, comp_mask_dict\n",
    "\n",
    "\n",
    "def get_mesh_l2id_from_lookup(\n",
    "    comp: dict,\n",
    "    timestamp: datetime.datetime,\n",
    "    cv: cloudvolume.CloudVolume,\n",
    "    point_counts: list = [10, 50, 100, 200, 400, 1000],\n",
    "    potential_l2ids: np.ndarray = None,\n",
    "):\n",
    "\n",
    "    comp_bbox  = np.vstack([np.min(comp['vertices'], axis=0), np.max(comp['vertices'], axis=0)])\n",
    "    not_enough_points = True\n",
    "\n",
    "    while not_enough_points:\n",
    "        if len(point_counts) == 0:\n",
    "            return -1\n",
    "        N = point_counts.pop(0)\n",
    "        random_points = np.random.uniform(\n",
    "            low=comp_bbox[0],\n",
    "            high=comp_bbox[1],\n",
    "            size=(N, 3)\n",
    "        )\n",
    "        with suppress_output():\n",
    "            pt_lookup = np.array(list(cv.scattered_points(\n",
    "                random_points,\n",
    "                mip=0,\n",
    "                coord_resolution=[1,1,1],\n",
    "                agglomerate=True,\n",
    "                stop_layer=2,\n",
    "                timestamp=timestamp,\n",
    "            ).values()))\n",
    "\n",
    "        if potential_l2ids is None:\n",
    "            potential_l2ids = np.unique(pt_lookup)\n",
    "        point_in_root = np.isin(pt_lookup, potential_l2ids)\n",
    "        if np.sum(point_in_root) >= 1:\n",
    "            not_enough_points = False\n",
    "        elif point_in_root.sum() == 0:\n",
    "            print(\"No points found in the root. Trying again with more points.\")\n",
    "            continue\n",
    "        l2ids, counts = np.unique(pt_lookup[point_in_root], return_counts=True)\n",
    "        return l2ids[np.argmax(counts)]\n",
    "\n",
    "def representative_point_via_lookup(\n",
    "        chunk_rows,\n",
    "        comp,\n",
    "        timestamp,\n",
    "        cv,\n",
    "        point_counts=[10, 50, 100, 200, 400, 1000],\n",
    "    ):\n",
    "    l2ids = chunk_rows['l2id'].values\n",
    "    l2id = get_mesh_l2id_from_lookup(\n",
    "        comp,\n",
    "        cv=cv,\n",
    "        point_counts=point_counts,\n",
    "        potential_l2ids=l2ids,\n",
    "        timestamp=timestamp,\n",
    "    )\n",
    "    if l2id == -1:\n",
    "        return -1\n",
    "    else:\n",
    "        return int(np.flatnonzero(l2ids == l2id)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51097cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_out = []\n",
    "for ii, grp in tqdm(enumerate(grps)):\n",
    "    try:\n",
    "        all_out.append(\n",
    "            process_multicomponent_chunk(\n",
    "                grp,\n",
    "                mesh.vertices,\n",
    "                mesh.faces,\n",
    "            )\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing chunk {ii}: {e}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803505f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3a6571",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e1237e",
   "metadata": {},
   "outputs": [],
   "source": [
    "assignment_df, component_mask_dict = assign_points_to_components(\n",
    "    chunk_rows,\n",
    "    vertices,\n",
    "    faces,\n",
    "    cv=cv,\n",
    "    ts=ts,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d05df5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "component_mask_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ebaaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_mapping = []\n",
    "for _, row in assignment_df.iterrows():\n",
    "    id_mapping.append(\n",
    "        {\n",
    "            'l2id_idx': int(chunk_rows.index[row['representative_pt']]),\n",
    "            'vertex_mask': component_mask_dict[row['graph_comp']],\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc659b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ea6403",
   "metadata": {},
   "outputs": [],
   "source": [
    "assignment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19466d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3a22c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_rows.index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2915bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c4306f",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2ids[chunk_rows.index[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a47ee1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21ca07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "components = create_component_dict(chunk_rows, vertices, faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5110b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp = components[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc48fb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6996f2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = client.cave.chunkedgraph.get_root_timestamps(rid, latest=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44ec38a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c9c17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "blah = pd.DataFrame(\n",
    "    {\n",
    "        'thing': [1, 2, 3],\n",
    "        'other': [4, 5, 6],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6289b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "blah.loc[4] = {'thing': 7, 'other': 8} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de48b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "blah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884c1547",
   "metadata": {},
   "outputs": [],
   "source": [
    "blah.append(\n",
    "    {'thing': 7, 'other': 8}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e536a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180d3590",
   "metadata": {},
   "outputs": [],
   "source": [
    "pts = chunk_rows[['pt_x', 'pt_y', 'pt_z']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff62103f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pts / [9,9,45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddb4269",
   "metadata": {},
   "outputs": [],
   "source": [
    "point_to_mask_via_lookup(\n",
    "    chunk_rows=chunk_rows,\n",
    "    comp=comp,\n",
    "    timestamp=ts,\n",
    "    cv=cv,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad7880f",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_mesh_l2id_from_lookup(\n",
    "    comp,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87134080",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_inside = gyp.fast_winding_number(random_points, comp['vertices'], comp['faces'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d13701",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_lookup = np.array(list(cv.scattered_points(\n",
    "    inside_points,\n",
    "    mip=0,\n",
    "    coord_resolution=[1,1,1],\n",
    "    agglomerate=True,\n",
    "    stop_layer=2,\n",
    ").values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c054d79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affd5909",
   "metadata": {},
   "outputs": [],
   "source": [
    "rid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585bf43b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885861e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb6f67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.sca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c4b61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674b5f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2203252",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e79bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adecadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_rows = grps[886]\n",
    "assignment_df, component_masks = assign_points_to_components(chunk_rows, vertices, faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e066581c",
   "metadata": {},
   "outputs": [],
   "source": [
    "component_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a40916d",
   "metadata": {},
   "outputs": [],
   "source": [
    "components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f0554b",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_via_vertices = {}\n",
    "for ii, submesh in enumerate(submeshes):\n",
    "    if submesh[0].shape[0] > 0 and submesh[1].shape[0] == 0:\n",
    "        map_via_vertices[ii] = submesh[0]\n",
    "# map_via_faces = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899c62aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1105b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.vstack(list(map_via_vertices.values())) / [9, 9, 45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90482727",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_dist = cdist(pts,np.vstack(list(map_via_vertices.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb17d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "(pts / [9, 9, 45]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc681b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9783db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_sum_assignment(pc_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55e33f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910e5208",
   "metadata": {},
   "outputs": [],
   "source": [
    "for submesh in submeshes:\n",
    "    if submesh[1].shape[0] == 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8d37fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "wn_results = []\n",
    "for submesh in submeshes:\n",
    "    wn_results.append(gyp.fast_winding_number(pts, submesh[0], submesh[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966d51fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Every mesh is a row, every point is a column\n",
    "mesh_assign, pt_assign = linear_sum_assignment(\n",
    "    np.array(wn_results) / np.max(wn_results),\n",
    "    maximize=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4c5f84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2da1be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2534b95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_assign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee93641a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_assign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32c00e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "wn_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0ae77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_sum_assignment(np.array(wn_results), maximize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee76ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c79aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pts / [9,9,45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb976f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85b0f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wn_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9d3ffd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234b1d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc39739",
   "metadata": {},
   "outputs": [],
   "source": [
    "vertices[submeshes[0][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8770aa00",
   "metadata": {},
   "outputs": [],
   "source": [
    "pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc2054e",
   "metadata": {},
   "outputs": [],
   "source": [
    "verts_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea11610",
   "metadata": {},
   "outputs": [],
   "source": [
    "pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63962d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "submeshes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d8b551",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.full(False, len(minds), dtype=bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f158766",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbf70cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62849df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "component_mask = mask.copy()\n",
    "component_mask[mask] = vertex_cc == 0\n",
    "\n",
    "face_mask_inclusive = mask_all[faces]\n",
    "# I want faces that have all values in the boundary inclusive mask and any values in the component mask.\n",
    "\n",
    "face_in_chunk = np.all(face_mask_inclusive, axis=1)\n",
    "face_touch_component = np.any(component_mask[faces], axis=1)\n",
    "\n",
    "component_faces = faces[face_in_chunk & face_touch_component]\n",
    "unique_verts = np.unique(np.concatenate((component_faces.ravel(), np.flatnonzero(vertex_cc == 0))))\n",
    "component_vertices = vertices[unique_verts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cada17d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5259931d",
   "metadata": {},
   "outputs": [],
   "source": [
    "component_faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca547f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "835632 in np.flatnonzero(mask_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64cd61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.flatnonzero(component_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d6ed99",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isin(\n",
    "    faces[face_touch_component],\n",
    "    np.flatnonzero(mask_all),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413659ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.flatnonzero(face_in_chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d92ee1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_all = bbox_mask(chunk_rows.iloc[0], vertices, inclusive=True)\n",
    "mask = bbox_mask(chunk_rows.iloc[0], vertices, inclusive=False)\n",
    "\n",
    "chunk_component_df = pd.DataFrame(\n",
    "    {\n",
    "        'mind': np.flatnonzero(mask_all),\n",
    "        'include_in_label': mask[mask_all],\n",
    "    }\n",
    ")\n",
    "\n",
    "chunk_mesh, bonus_edges = make_chunk_mesh(vertices, faces, mask_all, chunk_component_df)\n",
    "\n",
    "comp = within_chunk_components(chunk_mesh, bonus_edges)\n",
    "chunk_component_df['graph_comp'] = comp\n",
    "\n",
    "pts = np.array(chunk_rows[['pt_x', 'pt_y', 'pt_z']].values, dtype=float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80101271",
   "metadata": {},
   "outputs": [],
   "source": [
    "submeshes= []\n",
    "for i in np.unique(comp):\n",
    "    submesh = chunk_mesh.copy()\n",
    "    submesh.update_vertices(comp==i)\n",
    "    # sm = restrict_submesh(submesh)\n",
    "    submeshes.append(submesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5746c0f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04ab5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_mesh.split(only_watertight=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f640769",
   "metadata": {},
   "outputs": [],
   "source": [
    "submeshes= []\n",
    "any_all_on_border = False\n",
    "for i in np.unique(comp):\n",
    "    submesh = tmesh.copy()\n",
    "    submesh.update_vertices(comp==i)\n",
    "    sm = restrict_submesh(submesh)\n",
    "    if all_on_border(sm.vertices, chunk_rows.iloc[0]):\n",
    "        any_all_on_border = True\n",
    "        break\n",
    "    submeshes.append(sm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf2cf8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_on_border(\n",
    "    sm.vertices,\n",
    "    chunk_rows.iloc[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b9aa90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffd74f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4854a329",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e3b762",
   "metadata": {},
   "outputs": [],
   "source": [
    "submeshes= []\n",
    "for i in np.unique(comp):\n",
    "    submesh = tmesh.copy()\n",
    "    submesh.update_vertices(comp==i)\n",
    "    submeshes.append(submesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43c1321",
   "metadata": {},
   "outputs": [],
   "source": [
    "pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52b3238",
   "metadata": {},
   "outputs": [],
   "source": [
    "submesh = submeshes[2]\n",
    "submesh.faces = submesh.faces[~np.all(submesh.faces==0, axis=1)]\n",
    "gyp.fast_winding_number(\n",
    "    pts,\n",
    "    submesh.vertices,\n",
    "    submesh.faces,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac3fffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "wn_results = []\n",
    "for submesh in submeshes:\n",
    "    if np.all(submesh.faces==0):\n",
    "        wn_results = [0] * len(pts)\n",
    "    wn_results.append(gyp.fast_winding_number(pts,submesh.vertices,submesh.faces))\n",
    "\n",
    "pt_assign, mesh_assign = linear_sum_assignment(\n",
    "    1-np.array(wn_results) / np.max(wn_results)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938bbac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "submeshes[2].faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23431b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "submeshes[2].vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e91817",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2ids = nrn.anno.lvl2_ids.df.lvl2_id.values\n",
    "pts = get_lvl2_points(l2ids, client.cave)\n",
    "chunk_df = chunk_dataframe(l2ids, pts, cv)\n",
    "chunk_df_solo = chunk_df.drop_duplicates('chunk_number', keep=False)\n",
    "mesh_label = np.zeros(mesh.vertices.shape[0], dtype=int)-1\n",
    "for i, row in tqdm(chunk_df_solo.iterrows()):\n",
    "    mask = bbox_mask(row, mesh.vertices)\n",
    "    mesh_label[mask] = i\n",
    "chunk_df_multi = chunk_df[chunk_df.duplicated('chunk_number', keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafb1566",
   "metadata": {},
   "outputs": [],
   "source": [
    "gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a19a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_out = []\n",
    "for ii, grp in tqdm(enumerate(grps)):\n",
    "    try:\n",
    "        all_out.append(\n",
    "            process_multicomponent_chunk(\n",
    "                grp,\n",
    "                mesh.vertices,\n",
    "                mesh.faces,\n",
    "            )\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing chunk {ii}: {e}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f79ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_rows = grps[887]\n",
    "vertices = mesh.vertices\n",
    "faces = mesh.faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2897da92",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4136ad9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_multicomponent_chunk(\n",
    "    chunk_rows,\n",
    "    mesh.vertices,\n",
    "    mesh.faces,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3154d4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_component_df = chunk_component_df.merge(\n",
    "    assignment_df,\n",
    "    on='graph_comp',\n",
    "    how='left',\n",
    ")\n",
    "\n",
    "chunk_component_df['l2id_index'] =chunk_component_df['representative_pt'].map(\n",
    "    chunk_rows.reset_index()['index'].to_dict()\n",
    ")\n",
    "chunk_component_df.query('include_in_label')['mind'].values, chunk_component_df.query('include_in_label')['l2id_index'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb6d93a",
   "metadata": {},
   "source": [
    "I had previously used both the vertices and any extra vertices on the face of the mesh, but this could over-connect the mesh via these second vertices.\n",
    "Instead of this approach, I think I should actually build my submeshes from the components of the purely within-chunk vertex graph and then attach all the extra faces (without re-doing components). This approach should also likely allow me to avoid this spatial fallback.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debd88c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_component_df.query('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38304672",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "pdb.pm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fd1dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_all = bbox_mask(chunk_rows.iloc[0], vertices, inclusive=True)\n",
    "mask = bbox_mask(chunk_rows.iloc[0], vertices, inclusive=False)\n",
    "\n",
    "chunk_component_df = pd.DataFrame(\n",
    "    {\n",
    "        'mind': np.flatnonzero(mask_all),\n",
    "        'include_in_label': mask[mask_all],\n",
    "    }\n",
    ")\n",
    "\n",
    "tmesh, bonus_edges = make_chunk_mesh(vertices, faces, mask_all, chunk_component_df)\n",
    "\n",
    "comp = within_chunk_components(tmesh, bonus_edges)\n",
    "chunk_component_df['graph_comp'] = comp\n",
    "\n",
    "pts = np.array(chunk_rows[['pt_x', 'pt_y', 'pt_z']].values, dtype=float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea4e111",
   "metadata": {},
   "outputs": [],
   "source": [
    "assignment_df = assign_points_to_components(\n",
    "    tmesh,\n",
    "    comp,\n",
    "    pts,\n",
    "    chunk_rows.iloc[0],\n",
    ")\n",
    "assignment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb82a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "wn_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e0367b",
   "metadata": {},
   "outputs": [],
   "source": [
    "    assignment_df = assign_points_to_components(\n",
    "        tmesh,\n",
    "        comp,\n",
    "        pts,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f059cc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "submeshes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bbe805",
   "metadata": {},
   "outputs": [],
   "source": [
    "restrict_submesh = submeshes[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c5013b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import cKDTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32c571a",
   "metadata": {},
   "outputs": [],
   "source": [
    "kdtree = cKDTree(pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be66a8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eed4d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist, pdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cb9c22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf42a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = cdist(\n",
    "    pts,\n",
    "    tmesh.vertices\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f295b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_per_comp = [np.min(ds[:, comp==ii], axis=1) for ii in np.unique(comp)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ad314f",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_sum_assignment(np.array(min_per_comp) / np.max(np.array(min_per_comp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802b9e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pts / [9,9,45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca2d6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_rows.l2id.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8aa02ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29e6995",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff30f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023261fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ii in np.unique(comp):\n",
    "    ds[comp==ii]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8768458",
   "metadata": {},
   "outputs": [],
   "source": [
    "pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4eeaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2892170e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = restrict_submesh(submeshes[1])\n",
    "sm.faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b39b60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "submeshes= []\n",
    "for i in np.unique(comp):\n",
    "    submesh = tmesh.copy()\n",
    "    submesh.update_vertices(comp==i)\n",
    "    submeshes.append(submesh)\n",
    "\n",
    "wn_results = []\n",
    "for submesh in submeshes:\n",
    "    sm = restrict_submesh(submesh)\n",
    "    wn_results.append(gyp.fast_winding_number(pts, sm.vertices, sm.faces))\n",
    "\n",
    "# pt_assign, mesh_assign = linear_sum_assignment(\n",
    "#     1-np.array(wn_results) / np.max(wn_results)\n",
    "# )\n",
    "\n",
    "# wn_results = []\n",
    "# for submesh in submeshes:\n",
    "#     wn_results.append(gyp.fast_winding_number(pts,submesh.vertices,submesh.faces))\n",
    "\n",
    "# pt_assign, mesh_assign = linear_sum_assignment(\n",
    "#     1-np.array(wn_results) / np.max(wn_results)\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec2778a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wn_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17aa841",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7027230b",
   "metadata": {},
   "outputs": [],
   "source": [
    "wn_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516a1757",
   "metadata": {},
   "outputs": [],
   "source": [
    "submeshes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdf6e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "wn_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53688d79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8fd7e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b646cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vertices = mesh.vertices\n",
    "faces = mesh.faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178bd9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "minds, labels = process_multicomponent_chunk(chunk_rows, vertices, faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038892d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "pdb.pm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbe0c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "minds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f8916e",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2ids[[26,27]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d125edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask[mask_all]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ccb58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_all[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32df6dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_component_df = pd.DataFrame(\n",
    "    {\n",
    "        'mind': np.flatnonzero(mask),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816f6616",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(chunk_to_nm(\n",
    "    [292, 218, 13],\n",
    "    cv=cv\n",
    ")) / [9,9,45] + (chunk_dims(cv) / [9,9,45])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c01b4d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969c00b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.vstack(\n",
    "    chunk_to_nm(\n",
    "        chunk_df[['chunk_x', 'chunk_y', 'chunk_z']],\n",
    "        cv=cv\n",
    "    )\n",
    ")[[26,27]] / [9,9,45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07fb39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.vstack(\n",
    "    chunk_to_nm(\n",
    "        chunk_df[['chunk_x', 'chunk_y', 'chunk_z']],\n",
    "        cv=cv\n",
    "    )\n",
    ")[[26,27]] / [9,9,45] + chunk_dims(cv) / [9,9,45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81b8543",
   "metadata": {},
   "outputs": [],
   "source": [
    "grps[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89df3e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_out = []\n",
    "for ii, grp in tqdm(enumerate(grps)):\n",
    "    try:\n",
    "        all_out.append(\n",
    "            process_multicomponent_chunk(\n",
    "                grp,\n",
    "                mesh.vertices,\n",
    "                mesh.faces,\n",
    "            )\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing chunk {ii}: {e}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d1f05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "grps[887][]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c215d62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_rows = grps[887]\n",
    "faces = mesh.faces\n",
    "vertices = mesh.vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34eb1674",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_all = bbox_mask(chunk_rows.iloc[0], vertices, inclusive=True)\n",
    "mask = bbox_mask(chunk_rows.iloc[0], vertices, inclusive=False)\n",
    "\n",
    "chunk_component_df = pd.DataFrame(\n",
    "    {\n",
    "        'mind': np.flatnonzero(mask_all),\n",
    "        'include_in_label': mask[mask_all],\n",
    "    }\n",
    ")\n",
    "\n",
    "tmesh, bonus_edges = make_chunk_mesh(vertices, faces, mask_all, chunk_component_df)\n",
    "\n",
    "comp = within_chunk_components(tmesh, bonus_edges)\n",
    "chunk_component_df['graph_comp'] = comp\n",
    "\n",
    "pts = np.array(chunk_rows[['pt_x', 'pt_y', 'pt_z']].values, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1aa99d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_all.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1007fb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_df['bbox_end_x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392aa11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf504c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vertices[mask][:,0] == chunk_rows.iloc[0]['bbox_start_x'], vertices[mask][:,1] == chunk_rows.iloc[0]['bbox_start_y'], vertices[mask][:,2] == chunk_rows.iloc[0]['bbox_start_z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86fcc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_rows.iloc[0]['bbox_start_x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10e34bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vertices[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8168d757",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.flatnonzero(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0200990c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vertices[np.unique(faces[np.any(faces==835632, axis=1)].ravel())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623c76fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "pts / [9,9,45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6a5322",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_rows[['pt_x', 'pt_y', 'pt_z']].values / [9,9,45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611fbbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "assignment_df = assign_points_to_components(\n",
    "    tmesh,\n",
    "    comp,\n",
    "    pts,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e268fcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "assignment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d963f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmesh.split(only_watertight=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d72f017",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt.s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e99608",
   "metadata": {},
   "outputs": [],
   "source": [
    "assignment_df = assign_points_to_components(\n",
    "    tmesh,\n",
    "    comp,\n",
    "    pts,\n",
    ")\n",
    "\n",
    "chunk_component_df = chunk_component_df.merge(\n",
    "    assignment_df,\n",
    "    on='graph_comp',\n",
    "    how='left',\n",
    ")\n",
    "\n",
    "chunk_component_df['l2id_index'] =chunk_component_df['representative_pt'].map(\n",
    "    chunk_rows.reset_index()['index'].to_dict()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08443c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastremap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380b1fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_component_df.graph_comp.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9edc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmesh.vertices[37]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98e6528",
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh.vertices[172]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19a10f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh.faces[np.any(mesh.faces == 172, axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6ce8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_mask = mask[mesh.faces[np.any(mesh.faces == 172, axis=1)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f5d89d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d19a777",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e225a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_component_df.query('mind == 160')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105ef5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_component_df.query('graph_comp==2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df7c1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmesh.split(only_watertight=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822116c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "relabel = {v:k for k,v in chunk_component_df.to_dict()['mind'].items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5051a123",
   "metadata": {},
   "outputs": [],
   "source": [
    "faces_relabel = fastremap.remap(\n",
    "    faces,\n",
    "    relabel,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6fdd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmesh = trimesh.Trimesh(\n",
    "    vertices=mesh.vertices[mask],\n",
    "    faces=faces_relabel,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c149cf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "submeshes = tmesh.split(only_watertight=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829bc7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pts = np.array(grp[['pt_x', 'pt_y', 'pt_z']].values, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295f83d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7982e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "submeshes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51790ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c3b75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import linear_sum_assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11300b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "wn_results = []\n",
    "for submesh in submeshes:\n",
    "    wn_results.append(gyp.fast_winding_number(pts,submesh.vertices,submesh.faces))\n",
    "\n",
    "pt_assign, mesh_assign = linear_sum_assignment(\n",
    "    1-np.array(wn_results) / np.max(wn_results)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771d1205",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_sum_assignment?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6736c962",
   "metadata": {},
   "outputs": [],
   "source": [
    "assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9fcaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "wn_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1bff11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83383288",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_sum_assignment(\n",
    "    wn_results\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84161046",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b543a811",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmesh.edgesk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4f7287",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = bbox_mask(grp.iloc[0], mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f9e89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ax.plot(\n",
    "    tmesh.vertices[:, 0],\n",
    "    tmesh.vertices[:, 2],\n",
    "    marker='o',\n",
    "    linestyle='None',\n",
    "    markersize=1,\n",
    "    alpha=0.5,\n",
    "    color='blue',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6ef84f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f068f44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "grp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d72e166",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf54612",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpytoolbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b35586",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = gpytoolbox.normalize_points("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d0ad7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nrn.anno.lvl2_ids.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3062bd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_df.drop_duplicates('chunk_number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce1732e",
   "metadata": {},
   "outputs": [],
   "source": [
    "k\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "micronsclient",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
