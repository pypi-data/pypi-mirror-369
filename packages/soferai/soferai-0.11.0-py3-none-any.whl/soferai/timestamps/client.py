# This file was auto-generated by Fern from our API Definition.

import typing
from ..core.client_wrapper import SyncClientWrapper
from ..transcribe.types.transcription_id import TranscriptionId
from ..core.request_options import RequestOptions
from .types.outline_topic import OutlineTopic
from ..core.pydantic_utilities import parse_obj_as
from ..transcribe.errors.authentication_error import AuthenticationError
from ..transcribe.errors.rate_limit_error import RateLimitError
from json.decoder import JSONDecodeError
from ..core.api_error import ApiError
from ..core.client_wrapper import AsyncClientWrapper

# this is used as the default value for optional parameters
OMIT = typing.cast(typing.Any, ...)


class TimestampsClient:
    def __init__(self, *, client_wrapper: SyncClientWrapper):
        self._client_wrapper = client_wrapper

    def outline(
        self,
        *,
        transcription_id: TranscriptionId,
        monotone: typing.Optional[bool] = OMIT,
        conclusion_bias: typing.Optional[bool] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> typing.List[OutlineTopic]:
        """
        Outline of topics discussed by timestamp, generated end-to-end from a transcription ID.

        This endpoint will:
        1) Fetch the transcript and word-level timestamps for the given transcription
        2) Generate chapter topics (title + starting_phrase) using an LLM from the transcript text
        3) Align each topic's starting phrase to timestamps

        Parameters
        ----------
        transcription_id : TranscriptionId
            ID of the transcription to process end-to-end

        monotone : typing.Optional[bool]
            If true, each topic is searched after the previous topic's start (with a small backoff)

        conclusion_bias : typing.Optional[bool]
            If true and a title includes the word "conclusion", search in the last third of the audio

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        typing.List[OutlineTopic]

        Examples
        --------
        import uuid

        from soferai import SoferAI

        client = SoferAI(
            api_key="YOUR_API_KEY",
        )
        client.timestamps.outline(
            transcription_id=uuid.UUID(
                "d5e9c84f-c2b2-4bf4-b4b0-7ffd7a9ffc32",
            ),
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "v1/timestamps/outline",
            method="POST",
            json={
                "transcription_id": transcription_id,
                "monotone": monotone,
                "conclusion_bias": conclusion_bias,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    typing.List[OutlineTopic],
                    parse_obj_as(
                        type_=typing.List[OutlineTopic],  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 401:
                raise AuthenticationError()
            if _response.status_code == 429:
                raise RateLimitError()
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)


class AsyncTimestampsClient:
    def __init__(self, *, client_wrapper: AsyncClientWrapper):
        self._client_wrapper = client_wrapper

    async def outline(
        self,
        *,
        transcription_id: TranscriptionId,
        monotone: typing.Optional[bool] = OMIT,
        conclusion_bias: typing.Optional[bool] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> typing.List[OutlineTopic]:
        """
        Outline of topics discussed by timestamp, generated end-to-end from a transcription ID.

        This endpoint will:
        1) Fetch the transcript and word-level timestamps for the given transcription
        2) Generate chapter topics (title + starting_phrase) using an LLM from the transcript text
        3) Align each topic's starting phrase to timestamps

        Parameters
        ----------
        transcription_id : TranscriptionId
            ID of the transcription to process end-to-end

        monotone : typing.Optional[bool]
            If true, each topic is searched after the previous topic's start (with a small backoff)

        conclusion_bias : typing.Optional[bool]
            If true and a title includes the word "conclusion", search in the last third of the audio

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        typing.List[OutlineTopic]

        Examples
        --------
        import asyncio
        import uuid

        from soferai import AsyncSoferAI

        client = AsyncSoferAI(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.timestamps.outline(
                transcription_id=uuid.UUID(
                    "d5e9c84f-c2b2-4bf4-b4b0-7ffd7a9ffc32",
                ),
            )


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            "v1/timestamps/outline",
            method="POST",
            json={
                "transcription_id": transcription_id,
                "monotone": monotone,
                "conclusion_bias": conclusion_bias,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    typing.List[OutlineTopic],
                    parse_obj_as(
                        type_=typing.List[OutlineTopic],  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 401:
                raise AuthenticationError()
            if _response.status_code == 429:
                raise RateLimitError()
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)
