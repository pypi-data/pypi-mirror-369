#!/usr/bin/env python3
"""
ç«¯åˆ°ç«¯æµ‹è¯•ï¼šä½¿ç”¨KIMI K2_OPEN AGENTIC INTELLIGENCE.pdf_MinerU_truncatedæµ‹è¯•headingè‡ªåŠ¨å…³è”
"""
import json
import os
from src.sequence_former.data_models import Chunk, LLMOutput, ProcessingState
from src.sequence_former.llm_processor import build_prompt
from src.sequence_former.postprocessor import finalize_chunks_and_update_state
from src.sequence_former.config import Settings

def test_end_to_end():
    """ç«¯åˆ°ç«¯æµ‹è¯•ä¸»å‡½æ•°"""
    # åˆ›å»ºsettingså¯¹è±¡
    settings = Settings(
        target_chunk_size=1000,
        chunk_size_tolerance=0.2,
        enable_vlm=False,
        input_path="test_input.txt"
    )

    # åŠ è½½æµ‹è¯•æ–‡æ¡£
    test_doc_path = "E:\\SequenceFormer\\examples\\sample_documents\\KIMI K2_OPEN AGENTIC INTELLIGENCE.pdf_MinerU_truncated\\full.md"

    if not os.path.exists(test_doc_path):
        print(f"âŒ æµ‹è¯•æ–‡æ¡£ä¸å­˜åœ¨: {test_doc_path}")
        return False

    # è¯»å–æµ‹è¯•æ–‡æ¡£å†…å®¹
    with open(test_doc_path, 'r', encoding='utf-8') as f:
        document_content = f.read()

    print(f"âœ… æˆåŠŸåŠ è½½æµ‹è¯•æ–‡æ¡£: {len(document_content)} å­—ç¬¦")

    # æ¨¡æ‹ŸLLMå“åº”ï¼ˆåŸºäºmineru_test_output.jsonlä¸­çš„å®é™…æ¨¡å¼ï¼‰
    mock_llm_response = {
        "hierarchical_headings": [
            "## 1 Introduction",
            "## 2 Model Architecture",
            "## 3 Training Methodology",
            "## 4 Evaluation Results",
            "## 5 Discussion",
            "## 6 Conclusions"
        ],
        "chunks": [
            {
                "start_page": 1,
                "start_line": 1,
                "end_page": 1,
                "end_line": 10,
                "summary": "Introduction to Kimi K2 as a 1T-parameter model with advanced capabilities",
                "heading": "## 1 Introduction",  # LLMè¿”å›äº†heading
                "metadata": {"type": "introduction", "section": "main"}
            },
            {
                "start_page": 2,
                "start_line": 1,
                "end_page": 2,
                "end_line": 15,
                "summary": "Overview of the transformer-based architecture design",
                "heading": None,  # LLMæœªè¿”å›headingï¼Œéœ€è¦è‡ªåŠ¨å…³è”
                "metadata": {"type": "architecture", "section": "technical"}
            },
            {
                "start_page": 20,
                "start_line": 6,
                "end_page": 20,
                "end_line": 7,
                "summary": "Summarizes Kimi K2 as a 1T-parameter model",
                "heading": "",  # LLMè¿”å›ç©ºå­—ç¬¦ä¸²ï¼Œéœ€è¦è‡ªåŠ¨å…³è”
                "metadata": {"headings": ["## 6 Conclusions"]}
            }
        ]
    }

    # åˆ›å»ºLLMè¾“å‡ºå¯¹è±¡
    llm_output = LLMOutput(
        hierarchical_headings=mock_llm_response["hierarchical_headings"],
        chunks=[Chunk(**chunk) for chunk in mock_llm_response["chunks"]]
    )

    print("\nğŸ“‹ æµ‹è¯•æ•°æ®æ¦‚è§ˆ:")
    print(f"  å±‚çº§æ ‡é¢˜: {len(llm_output.hierarchical_headings)} ä¸ª")
    print(f"  æ–‡æœ¬å—: {len(llm_output.chunks)} ä¸ª")

    # å¤„ç†å‰çš„headingçŠ¶æ€
    print("\nğŸ” å¤„ç†å‰çš„headingçŠ¶æ€:")
    for i, chunk in enumerate(llm_output.chunks):
        print(f"  Chunk {i+1}: heading='{chunk.heading}'")

    # åˆ›å»ºå¤„ç†çŠ¶æ€
    processing_state = ProcessingState(
        doc_id="test_kimi_document",
        hierarchical_headings=llm_output.hierarchical_headings,
        chunks=[]
    )

    # åº”ç”¨åå¤„ç†å™¨
    try:        # åˆ›å»ºæ¨¡æ‹Ÿçš„combined_enriched_lines
        combined_enriched_lines = []
        for line in document_content.split('\n'):
            combined_enriched_lines.append({
                'page': 1,
                'line': len(combined_enriched_lines) + 1,
                'text': line
            })

        # ä¿®å¤å‡½æ•°è°ƒç”¨ï¼Œæ·»åŠ ç¼ºå¤±çš„å‚æ•°
        reliable_chunks, new_state = finalize_chunks_and_update_state(
            llm_output,
            combined_enriched_lines,
            1,  # current_page_boundary
            processing_state,
            settings  # éœ€è¦åˆ›å»ºsettingså¯¹è±¡
        )
        processing_state = new_state
        print("\nâœ… åå¤„ç†å™¨æ‰§è¡ŒæˆåŠŸ")
    except Exception as e:
        print(f"âŒ åå¤„ç†å™¨æ‰§è¡Œå¤±è´¥: {e}")
        return False

    # éªŒè¯ç»“æœ
    print("\nğŸ¯ å¤„ç†åçš„headingçŠ¶æ€:")

    # è·å–å¤„ç†åçš„chunks
    all_chunks = reliable_chunks  # ä½¿ç”¨åå¤„ç†å™¨è¿”å›çš„chunks

    expected_headings = [
        "## 1 Introduction",  # å·²æœ‰headingä¿æŒä¸å˜
        "## 6 Conclusions",   # Noneå…³è”åˆ°æœ€åä¸€ä¸ªheading
        "## 6 Conclusions"    # ç©ºå­—ç¬¦ä¸²å…³è”åˆ°æœ€åä¸€ä¸ªheading
    ]

    # éªŒè¯æ¯ä¸ªchunkçš„heading
    for i, (chunk, expected_heading) in enumerate(zip(all_chunks, expected_headings)):
        actual_heading = chunk.heading if chunk.heading else "None"
        print(f"  Chunk {i+1}: heading='{actual_heading}' (æœŸæœ›: '{expected_heading}')")

        if actual_heading != expected_heading:
            print(f"    âŒ ä¸åŒ¹é…ï¼")
            return False

    print("âœ… headingè‡ªåŠ¨å…³è”éªŒè¯é€šè¿‡ï¼")

    # æµ‹è¯•metadataä¸­çš„headingä¿¡æ¯
    print("\nğŸ“Š æµ‹è¯•metadataä¸­çš„headingä¿¡æ¯...")
    for chunk in all_chunks:
        if hasattr(chunk, 'metadata') and chunk.metadata and 'heading' in chunk.metadata:
            print(f"  Chunk heading in metadata: {chunk.metadata['heading']}")

    return True

def test_metadata_heading_integration():
    """æµ‹è¯•metadataä¸­çš„headingä¿¡æ¯æ˜¯å¦æ­£ç¡®å¤„ç†"""
    print("\n=== æµ‹è¯•metadataä¸­çš„headingä¿¡æ¯é›†æˆ ===\n")

    # åˆ›å»ºåŒ…å«metadata headingçš„æµ‹è¯•æ•°æ®
    chunk_with_meta_heading = Chunk(
        start_page=1, start_line=1, end_page=1, end_line=5,
        summary="æµ‹è¯•æ‘˜è¦",
        heading=None,  # éœ€è¦è‡ªåŠ¨å…³è”
        metadata={"headings": ["## æµ‹è¯•æ ‡é¢˜"]}
    )

    hierarchical_headings = ["## æµ‹è¯•æ ‡é¢˜", "## å­æ ‡é¢˜"]

    # åº”ç”¨headingå…³è”
    from src.sequence_former.postprocessor import _associate_chunk_with_heading
    _associate_chunk_with_heading(chunk_with_meta_heading, hierarchical_headings)

    print(f"Metadataä¸­çš„headings: {chunk_with_meta_heading.metadata.get('headings', [])}")
    print(f"è‡ªåŠ¨å…³è”åçš„heading: '{chunk_with_meta_heading.heading}'")

    # éªŒè¯æ˜¯å¦ä¼˜å…ˆä½¿ç”¨hierarchical_headings
    expected = "## å­æ ‡é¢˜"  # åº”è¯¥ä½¿ç”¨æœ€åä¸€ä¸ªhierarchical_heading
    success = chunk_with_meta_heading.heading == expected

    if success:
        print("âœ… æ­£ç¡®ä¼˜å…ˆä½¿ç”¨hierarchical_headingsè€Œémetadataä¸­çš„headings")
    else:
        print(f"âŒ æœŸæœ›heading='{expected}'ï¼Œå®é™…='{chunk_with_meta_heading.heading}'")

    return success

if __name__ == "__main__":
    success = test_end_to_end()
    if success:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼headingè‡ªåŠ¨å…³è”åŠŸèƒ½æ­£å¸¸å·¥ä½œ")
    else:
        print("\nâŒ æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä»£ç ")