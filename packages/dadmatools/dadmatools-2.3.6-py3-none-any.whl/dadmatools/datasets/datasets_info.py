{"PersianNews": {"name": "PersianNews", "version": "1.0.0", "task": "Classification", "splits": ["train", "test", "dev"], "description": "source: https://huggingface.co/HooshvareLab/bert-fa-base-uncased-clf-persiannews", "size": {"train": 13179, "dev": 1469, "test": 1623}, "filenames": ["persian_news/train.csv", "persian_news/test.csv", "persian_news/dev.csv"]}, "WikipediaCorpus": {"name": "WikipediaCorpus", "version": "20211201", "task": "Corpus", "description": "fawiki dump progress on 20211201 / All pages, current versions only.", "size": 2184117, "filenames": ["cleaned_wiki.txt"]}, "FaSpell": {"name": "FaSpell", "version": "1.0.0", "task": "Spell-Checking", "splits": ["main", "ocr"], "description": "FASpell dataset was developed for the evaluation of spell checking algorithms. It contains a set of pairs of misspelled Persian words and their corresponding corrected forms similar to the ASpell dataset used for English.", "size": {"main": 5062, "ocr": 800}, "filenames": ["faspell_main.txt", "faspell_ocr.txt"]}, "PersianTweets": {"name": "PersianTweets", "version": "2020", "task": "Corpus", "splits": [], "description": "LSCP: Enhanced Large Scale Colloquial Persian Language Understanding <br>\nLearn more about this study at https://iasbs.ac.ir/~ansari/lscp/", "size": 20665964, "filenames": ["lscp-0.5-fa-normalized.txt"]}, "PnSummary": {"name": "PnSummary", "version": "1.0.0", "task": "Summarization", "splits": ["train", "test", "dev"], "description": "source: https://github.com/hooshvare/pn-summary", "size": {"train": 13179, "dev": 1469, "test": 5503}, "filenames": ["pn_summary/train.csv", "pn_summary/test.csv", "pn_summary/dev.csv"]}, "TEP": {"name": "TEP", "version": "1.0.0", "task": "Translation", "splits": [], "description": "TEP: Tehran English-Persian parallel corpus", "size": 612086, "filenames": ["TEP.en-fa.en", "TEP.en-fa.fa"]}, "PerUDT": {"name": "PerUDT", "version": "1.0.0", "task": "Treebank", "splits": ["train", "test", "dev"], "description": "The Persian Universal Dependency Treebank (PerUDT) is the result of automatic coversion of Persian Dependency Treebank (PerDT) with extensive manual corrections", "size": {"train": 26196, "test": 1455, "dev": 1456}, "filenames": ["fa_perdt-ud-train.conllu", "fa_perdt-ud-dev.conllu", "fa_perdt-ud-test.conllu"]}, "FarsTail": {"name": "FarsTail", "version": "1.0.0", "task": "Textual-Entailment", "splits": ["train", "test", "val"], "description": "source: https://github.com/dml-qom/FarsTail", "size": {"train": 7266, "test": 1564, "val": 1537}, "filenames": ["Train-word.csv", "Test-word.csv", "Val-word.csv"]}, "Peyma": {"name": "Peyma", "version": "1.0.0", "task": "NER", "splits": [], "description": "source: http://nsurl.org/2019-2/tasks/task-7-named-entity-recognition-ner-for-farsi/", "size": 10016, "filenames": ["peyma/600K", "peyma/300K"]}, "snappfoodSentiment": {"name": "snappfoodSentiment", "version": "1.0.0", "task": "Sentiment-Analysis", "splits": ["train", "test", "dev"], "description": "source: https://huggingface.co/HooshvareLab/bert-fa-base-uncased-sentiment-snappfood", "size": {"train": 56516, "dev": 6274, "test": 6972}, "filenames": ["snappfood/train.csv", "snappfood/test.csv", "snappfood/dev.csv"]}, "PersianNer": {"name": "PersianNer", "version": "1.0.0", "task": "NER", "splits": [], "description": "source: https://github.com/Text-Mining/Persian-NER", "size": 976599, "filenames": ["Persian-NER-part1.txt", "Persian-NER-part2.txt", "Persian-NER-part3.txt", "Persian-NER-part4.txt", "Persian-NER-part5.txt"]}, "ARMAN": {"name": "ARMAN", "version": "1.0.0", "task": "NER", "splits": ["train", "test"], "description": "ARMAN dataset holds 7,682 sentences with 250,015 sentences tagged over six different classes.\n\nOrganization\nLocation\nFacility\nEvent\nProduct\nPerson", "filenames": ["train_fold1.txt", "train_fold2.txt", "train_fold3.txt", "test_fold1.txt", "test_fold2.txt", "test_fold3.txt"], "size": {"train": 15361, "test": 7680}}, "PerSent": {"name": "PerSent", "version": "1.0.0", "task": "SA", "splits": [], "description": "persent lexicon", "size": 1490, "filenames": ["PerSent.xlsx"]}}