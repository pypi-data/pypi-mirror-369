{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b00f47d",
   "metadata": {},
   "source": [
    "## The MSM forward algorithm.\n",
    "\n",
    "This section simulates what happens in the fitting method of the Markov Switching Multifractal (MSM) model. Differently from standard HMMs, the MSM cannot be fit using the EM algorithm, and requires numerical methods to be applied to the likelihood function instead. \n",
    "\n",
    "We start by importing the necessary packages and by creating a test series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c6d341b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "\n",
    "ts_test = jnp.array(np.random.normal(50, 10, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2d3cbc",
   "metadata": {},
   "source": [
    "The model requires the following hyperparameters:\n",
    " - `num_latent`: how many volatility components, integer.\n",
    " - `marg_prob_mass`: the probability mass of the marginal distribution of the latent states, needs to sum to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fdb41a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_latent = 3\n",
    "marg_prob = jnp.full(2, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4416cf4b",
   "metadata": {},
   "source": [
    "For this simulation we also use example parameters. In the `MSM` class the parameters are instead found starting from an intial guess using the `MSM.fit()` method.\n",
    "\n",
    "By assumption, all the parameters need to be positive, and have further individual constrains:\n",
    "\n",
    "- `marg_support`: the support of the marginal probability mass defined in the parameters. It needs to have unity expectation. In the symmetric binomial case, this can be enforced by specifying one value $m_0$, and having the second value be $2- m_0$.\n",
    "\n",
    "- `unconditional_term`: the unconditional distribution of the model, a positive double.\n",
    "\n",
    "- `arrival_gdistance`: the geometric distance between the Poisson arrivals of each latent volatility component, a positive double.\n",
    "\n",
    "- `hf_arrival`: the highest poisson arrival probability (i.e. the proability of state switch of the highest frequency component)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62ab1868",
   "metadata": {},
   "outputs": [],
   "source": [
    "m0 = 0.45677\n",
    "m_support = jnp.array([2-m0, m0])\n",
    "unconditional_term = 1.0\n",
    "arrival_gdistance = 3.0\n",
    "hf_arrival = 0.98"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799501ae",
   "metadata": {},
   "source": [
    "As in the `MSM` class, we proceed to initialize the components of the forward algorithm: the ergotic distribution of the model, the emission probabilities (data likelihood) and the transition tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5108e977",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fractrics._ts_components._HMM._initial_distribution import multiplicative_cascade\n",
    "from fractrics._ts_components._HMM._data_likelihood import dlk_normal\n",
    "from fractrics._ts_components._HMM._transition_tensor import poisson_arrival\n",
    "\n",
    "# simulating what happens in the __init__ of the model: initialization of components\n",
    "indis_fn = multiplicative_cascade(marg_prob_mass=marg_prob, num_latent=n_latent)\n",
    "dl_fn = dlk_normal(ts_test)\n",
    "trtens_fn = poisson_arrival(num_latent=n_latent, marg_prob_mass=marg_prob)\n",
    "\n",
    "# computing components\n",
    "latent_states = indis_fn.support(uncond_term=unconditional_term, marg_support=m_support)\n",
    "ergotic_distr = indis_fn.mass()\n",
    "data_likelihood = dl_fn.likelihood(latent_states=latent_states)\n",
    "transition_tensor = trtens_fn.t_tensor(arrival_gdistance=arrival_gdistance, hf_arrival=hf_arrival)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58dcb09e",
   "metadata": {},
   "source": [
    "Then the forward class takes them as input and computes the recursion for all datapoints. The forward returns the negative log likelihood of the model, the final posterior distribution of the latent states, and all the intermediate updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b778ffc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fractrics._ts_components._HMM._forward import factor_transition\n",
    "\n",
    "forward_fn = factor_transition(num_latent=n_latent)\n",
    "forward_predictive_fn = forward_fn.make_predictive_function(*transition_tensor)\n",
    "predictive = forward_predictive_fn(prior=ergotic_distr)\n",
    "\n",
    "nll, posterior, list = forward_fn.update(ergotic_distr, data_likelihood, transition_tensor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usami",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
