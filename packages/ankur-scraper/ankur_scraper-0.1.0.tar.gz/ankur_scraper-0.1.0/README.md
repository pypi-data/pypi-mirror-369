# ğŸ•·ï¸ Ankur Scraper

**Ankur Scraper** is a modular, production-ready website scraping tool built with Python. It crawls and extracts structured content from websites â€” including dynamic pages rendered with JavaScript â€” and saves the results in a clean JSON format.

---

## ğŸš€ Features

- âœ… Crawl internal links (with max depth)
- âœ… Extract visible, structured text (section-wise)
- âœ… Supports static and dynamic (JS-rendered) pages
- âœ… Respects `robots.txt`
- âœ… CLI interface with arguments
- âœ… Logs everything to file + rich-colored terminal
- âœ… Testable, extensible, and publishable as a Python package

---

## ğŸ“¦ Project Structure

```bash
ankur_scraper/
â”œâ”€â”€ ankur_scraper/
â”‚ â”œâ”€â”€ init.py
â”‚ â”œâ”€â”€ cli.py
â”‚ â”œâ”€â”€ core/
â”‚ â”‚ â”œâ”€â”€ crawler.py
â”‚ â”‚ â”œâ”€â”€ dispatcher.py
â”‚ â”‚ â”œâ”€â”€ html_extractor.py
â”‚ â”‚ â”œâ”€â”€ page_scraper.py
â”‚ â”œâ”€â”€ logging_config.py
â”‚ â””â”€â”€ logs/
â”‚ â”œâ”€â”€ info.log
â”‚ â”œâ”€â”€ error.log
â”‚ â””â”€â”€ general.log
â”œâ”€â”€ tests/
â”‚ â”œâ”€â”€ test_crawler.py
â”‚ â”œâ”€â”€ test_html_extractor.py
â”‚ â”œâ”€â”€ test_page_scraper.py
â”‚ â”œâ”€â”€ test_integration.py
â”‚ â””â”€â”€ conftest.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ setup.py
â””â”€â”€ README.md
```

## ğŸ”§ Installation

Clone the project and install dependencies:

```bash
git clone https://github.com/your-org/ankur_scraper.git
cd ankur_scraper
python -m venv venv
source venv/bin/activate  # or venv\Scripts\activate on Windows

pip install -r requirements.txt

# Install Playwright drivers (for dynamic scraping)
playwright install
```

## ğŸ•¹ï¸ Usage (CLI)

```bash
python -m ankur_scraper.cli \
  --url "https://example.com" \
  --depth 1 \
  --output results.json \
  --dynamic \
  --timeout 10
```

## Command Line Options

| Option | Description |
|--------|-------------|
| `--url` | Starting URL to scrape (required) |
| `--depth` | How deep to crawl within the domain |
| `--output` | File path to save JSON output |
| `--dynamic` | Use dynamic scraping (Playwright) |
| `--timeout` | Timeout for each page (seconds) |

## Usage Examples

```bash
# Basic usage
script --url https://example.com

# With depth and output
script --url https://example.com --depth 2 --output results.json

# With dynamic scraping and timeout
script --url https://example.com --dynamic --timeout 30
```

## ğŸ§ª Running Tests

### Unit Tests

```bash
pytest tests/ --tb=short
```

### Integration Tests (Live Web)

```bash
pytest tests/test_integration.py -m integration
```

Integration tests make real HTTP calls to sites like example.com.

Add pytest.ini for markers:

```ini
# pytest.ini
[pytest]
markers =
    integration: mark tests as integration
```

## ğŸ“„ Output Format

Every page section is saved as a structured object:

```json
{
  "content": "Text content here...",
  "metadata": {
    "section": "About Us",
    "source_url": "https://example.com/about",
    "extraction_time": "2025-07-14 12:34:56"
  }
}
```

## ğŸ“š Logging

Logs are written to both terminal and file:

- logs/info.log: general operations
- logs/error.log: failed links and errors
- logs/general.log: warnings, summaries

Terminal output is rich-colored with emojis and timestamps.

## ğŸ“¦ Packaging & Publishing

This scraper is fully structured as a pip-installable package.

Install Locally for CLI Use

```bash
pip install .
```

Now you can run:

```bash
ankur-scraper --url "https://..." --output output.json
```

### Publish to PyPI

Ensure you have build and twine:

```bash
pip install build twine
```

### Build and publish

```bash
python -m build
twine upload dist/*
```

Update version in setup.py before publishing!

## ğŸ“Œ Dependencies

- httpx: Fast, async-capable HTTP requests
- beautifulsoup4 + lxml: HTML parsing
- tldextract: Domain filtering
- playwright: JS rendering (headless)
- rich: Beautiful terminal output
- pytest: Testing

## ğŸ¤ Contributing

- Fork the repo
- Make changes in a branch
- Run tests: pytest
- Submit a PR

## ğŸ§  Future Ideas

- Save to Markdown or plaintext
- URL exclusion filters
- Config file/ENV mode
- Docker support
- CI/CD for publishing

## ğŸ§‘â€ğŸ’» Maintainer

Made with â¤ï¸ by Ankur Global Solutions
