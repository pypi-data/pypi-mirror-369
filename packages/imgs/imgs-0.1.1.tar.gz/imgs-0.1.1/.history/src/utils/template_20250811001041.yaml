output_dir: ./output
do_train: true
do_eval: false
eval_steps: null
eval_delay: 0
# 'no', 'steps', 'epoch'
eval_strategy: 'no'

per_device_train_batch_size: 8
per_device_eval_batch_size: 8
auto_find_batch_size: false
gradient_accumulation_steps: 1

learning_rate: 5e-5
weight_decay: 0.0
num_train_epochs: 3.0
max_steps: -1
lr_scheduler_type: linear
warmup_ratio: 0.0
warmup_steps: 0

# 'debug', 'info', 'warning', 'error' and 'critical', plus a 'passive' level which doesn't set anything and lets the application set the level.
log_level: passive
log_on_each_node: true
# 'no', 'steps', 'epoch'
logging_strategy: steps
logging_first_step: false
logging_steps: 500

# 'no', 'steps', 'epoch', 'best'
save_strategy: steps
save_steps: 500
save_total_limit: null
save_only_model: false

seed: 42
data_seed: None

use_ipex: false
bf16: false
fp16: false
tf32: null

dataloader_drop_last: false
dataloader_num_workers: 0
dataloader_prefetch_factor: 2
dataloader_pin_memory: true
dataloader_persistent_workers: false
remove_unused_columns: true
label_names: null

run_name: null
report_to: null


push_to_hub: false
hub_model_id: null
# 'end', 'every_save', 'checkpoint', 'all_checkpoints'
hub_strategy: 'every_save'
hub_revision: null

gradient_checkpointing: false
torch_compile: false


resume_from_checkpoint: null


use_liger_kernel: true