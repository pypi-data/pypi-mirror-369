\begin{table}[]
\begin{tabular}{l|l}
AdaBoost\_learning\_rate & $\mathcal{U}^l(10^{0.01}, 10^{1.0})$ \\ \hline
AdaBoost\_n\_estimators & $\mathcal{U}^d(10, 100)$ \\ \hline
CNB\_alpha & $\mathcal{U}(0, 1)$ \\ \hline
ElasticNet\_alpha & $\mathcal{U}^l(10^{-5}, 10^{0})$ \\ \hline
ElasticNet\_l1\_ratio & $\mathcal{U}(0.0, 1.0)$ \\ \hline
Featsel\_Variance & $\mathcal{B}(1.0)$ \\ \hline
FeatureScaling & {[robust\_z\_score]} \\ \hline
Imputation & {[True]} \\ \hline
ImputationMethod & {[mean, median, most\_frequent, constant]} \\ \hline
ImputationNeighbours & $\mathcal{U}^d(5, 10)$ \\ \hline
ImputationSkipAllNaN & {[True]} \\ \hline
LDA\_shrinkage & $\mathcal{U}^l(10^{-5}, 10^{0})$ \\ \hline
LDA\_solver & {[svd, lsqr, eigen]} \\ \hline
LRC & $\mathcal{U}(0.01, 1.0)$ \\ \hline
LR\_l1\_ratio & $\mathcal{U}(0.0, 1.0)$ \\ \hline
LR\_solver & {[lbfgs, saga]} \\ \hline
LRpenalty & {[l1, l2, elasticnet]} \\ \hline
LightGBM\_max\_depth & $\mathcal{U}^d(3, 15)$ \\ \hline
LightGBM\_min\_child\_samples & $\mathcal{U}^d(5, 50)$ \\ \hline
LightGBM\_min\_child\_weight & $\mathcal{U}^l(10^{-7}, 10^{-3})$ \\ \hline
LightGBM\_num\_leaves & $\mathcal{U}^d(5, 100)$ \\ \hline
LightGBM\_reg\_alpha & $\mathcal{U}(0.01, 1.0)$ \\ \hline
LightGBM\_reg\_lambda & $\mathcal{U}(0.01, 1.0)$ \\ \hline
OneHotEncoding & {[True]} \\ \hline
PCAType & {[95variance, 10, 50, 100]} \\ \hline
QDA\_reg\_param & $\mathcal{U}^l(10^{-5}, 10^{0})$ \\ \hline
RFE & $\mathcal{B}(0.0)$ \\ \hline
RFE\_estimator & {[Lasso, LR, RF]} \\ \hline
RFE\_lasso\_alpha & $\mathcal{U}(0.1, 1.5)$ \\ \hline
RFE\_n\_features\_to\_select & $\mathcal{U}^d(10.0, 100.0)$ \\ \hline
RFE\_n\_trees & $\mathcal{U}^d(10, 100)$ \\ \hline
RFE\_step & $\mathcal{U}^d(1, 10)$ \\ \hline
RFmax\_depth & $\mathcal{U}^d(5, 10)$ \\ \hline
RFmin\_samples\_split & $\mathcal{U}^d(2, 5)$ \\ \hline
RFn\_estimators & $\mathcal{U}^d(10, 100)$ \\ \hline
ReliefDistanceP & $\mathcal{U}^d(1, 4)$ \\ \hline
ReliefNN & $\mathcal{U}^d(2, 6)$ \\ \hline
ReliefNumFeatures & $\mathcal{U}^d(10, 50)$ \\ \hline
ReliefSampleSize & $\mathcal{U}(0.75, 0.95)$ \\ \hline
ReliefUse & $\mathcal{B}(0.0)$ \\ \hline
Resampling\_Method & {[RandomUnderSampling, RandomOverSampling, NearMiss, NeighbourhoodCleaningRule, ADASYN, BorderlineSMOTE, SMOTE, SMOTEENN, SMOTETomek]} \\ \hline
Resampling\_Use & $\mathcal{B}(0.0)$ \\ \hline
Resampling\_k\_neighbors & $\mathcal{U}^d(5, 20)$ \\ \hline
Resampling\_n\_cores & {[1]} \\ \hline
Resampling\_n\_neighbors & $\mathcal{U}^d(3, 15)$ \\ \hline
Resampling\_sampling\_strategy & {[auto, majority, minority, not minority, not majority, all]} \\ \hline
Resampling\_threshold\_cleaning & $\mathcal{U}(0.25, 0.75)$ \\ \hline
SGD\_alpha & $\mathcal{U}^l(10^{-5}, 10^{0})$ \\ \hline
SGD\_l1\_ratio & $\mathcal{U}(0.0, 1.0)$ \\ \hline
SGD\_loss & {[squared\_loss, huber, epsilon\_insensitive, squared\_epsilon\_insensitive]} \\ \hline
SGD\_penalty & {[none, l2, l1]} \\ \hline
SVMC & $\mathcal{U}^l(10^{0}, 10^{6})$ \\ \hline
SVMKernel & {[linear, poly, rbf]} \\ \hline
SVMcoef0 & $\mathcal{U}(0, 1)$ \\ \hline
SVMdegree & $\mathcal{U}^d(1, 7)$ \\ \hline
SVMgamma & $\mathcal{U}^l(10^{-5}, 10^{0})$ \\ \hline
SelectFromModel & $\mathcal{B}(0.0)$ \\ \hline
SelectFromModel\_estimator & {[Lasso, LR, RF]} \\ \hline
SelectFromModel\_lasso\_alpha & $\mathcal{U}(0.1, 1.5)$ \\ \hline
SelectFromModel\_n\_trees & $\mathcal{U}^d(10, 100)$ \\ \hline
SelectGroups & {[True]} \\ \hline
StatisticalTestMetric & {[MannWhitneyU]} \\ \hline
StatisticalTestThreshold & $\mathcal{U}^l(10^{-3.0}, 10^{-0.5})$ \\ \hline
StatisticalTestUse & $\mathcal{B}(0.0)$ \\ \hline
UsePCA & $\mathcal{B}(0.275)$ \\ \hline
XGB\_boosting\_rounds & $\mathcal{U}^d(10, 100)$ \\ \hline
XGB\_colsample\_bytree & $\mathcal{U}(0.3, 1.0)$ \\ \hline
XGB\_gamma & $\mathcal{U}(0.01, 10.0)$ \\ \hline
XGB\_learning\_rate & $\mathcal{U}^l(10^{0.01}, 10^{1.0})$ \\ \hline
XGB\_max\_depth & $\mathcal{U}^d(3, 15)$ \\ \hline
XGB\_min\_child\_weight & $\mathcal{U}^d(1, 7)$ \\ \hline
classifiers & {[SVR, RFR, ElasticNet, Lasso, AdaBoostRegressor, XGBRegressor, LinR, Ridge]} \\ \hline
coliage\_features & {[False]} \\ \hline
dicom\_features & {[False]} \\ \hline
fractal\_features & {[True, False]} \\ \hline
histogram\_features & {[True, False]} \\ \hline
location\_features & {[True, False]} \\ \hline
log\_features & {[False]} \\ \hline
max\_iter & {[100000]} \\ \hline
orientation\_features & {[True, False]} \\ \hline
original\_features & {[True]} \\ \hline
phase\_features & {[False]} \\ \hline
random\_seed & $\mathcal{U}^d(0, 4294967295)$ \\ \hline
rgrd\_features & {[True, False]} \\ \hline
semantic\_features & {[False]} \\ \hline
shape\_features & {[True, False]} \\ \hline
texture\_gabor\_features & {[False]} \\ \hline
texture\_glcm\_features & {[True, False]} \\ \hline
texture\_glcmms\_features & {[True, False]} \\ \hline
texture\_gldm\_features & {[True, False]} \\ \hline
texture\_gldzm\_features & {[True, False]} \\ \hline
texture\_glrlm\_features & {[True, False]} \\ \hline
texture\_glszm\_features & {[True, False]} \\ \hline
texture\_lbp\_features & {[True, False]} \\ \hline
texture\_ngldm\_features & {[True, False]} \\ \hline
texture\_ngtdm\_features & {[True, False]} \\ \hline
toolbox & {[PREDICT]} \\ \hline
vessel\_features & {[False]} \\ \hline
wavelet\_features & {[True, False]} \\ \hline

\end{tabular}
\end{table}
