{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flow SDK Advanced Features\n",
    "\n",
    "This notebook explores advanced Flow SDK features for production workloads, including instance catalogs, persistent storage, multi-node computing, and self-managing tasks.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "1. **Instance Catalog** - Query and select optimal instances\n",
    "2. **Storage Management** - Persistent volumes and data transfer\n",
    "3. **Multi-Node Computing** - Distributed and parallel tasks\n",
    "4. **Port Forwarding** - Interactive services and tunneling\n",
    "5. **Custom Startup Scripts** - Advanced initialization\n",
    "6. **Self-Terminating Tasks** - Cost optimization patterns\n",
    "7. **Monitoring & Observability** - Logging and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "from flow import Flow, TaskConfig\n",
    "from flow.models import Instance, Volume\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Instance Catalog - Finding the Right Compute\n",
    "\n",
    "Flow SDK provides a powerful catalog system to find instances that match your requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query instance catalog\n",
    "with Flow() as flow:\n",
    "    # Find GPU instances under $20/hour\n",
    "    requirements = {\n",
    "        \"max_price\": 20.0,\n",
    "        \"min_gpu_count\": 1,\n",
    "        \"gpu_memory_gb\": 16  # Minimum GPU memory\n",
    "    }\n",
    "    \n",
    "    print(\"Searching for GPU instances...\\n\")\n",
    "    instances = flow.find_instances(requirements, limit=10)\n",
    "    \n",
    "    # Display results\n",
    "    for inst in instances:\n",
    "        print(f\"Instance: {inst.instance_type}\")\n",
    "        print(f\"  Provider: {inst.provider}\")\n",
    "        print(f\"  Region: {inst.region}\")\n",
    "        print(f\"  GPUs: {inst.gpu_count}x {inst.gpu_type}\")\n",
    "        print(f\"  GPU Memory: {inst.gpu_memory_gb}GB\")\n",
    "        print(f\"  Price: ${inst.price_per_hour}/hour\")\n",
    "        print(f\"  Available: {inst.available}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced catalog queries\n",
    "with Flow() as flow:\n",
    "    # Query 1: Find instances for large model training\n",
    "    large_model_requirements = {\n",
    "        \"instance_type\": \"gpu.nvidia.h100\",  # Specific GPU type\n",
    "        \"min_gpu_count\": 8,\n",
    "        \"region\": \"us-west-2\",\n",
    "        \"max_price\": 100.0\n",
    "    }\n",
    "    \n",
    "    print(\"Large model training instances:\")\n",
    "    instances = flow.find_instances(large_model_requirements, limit=5)\n",
    "    for inst in instances:\n",
    "        print(f\"  {inst.instance_type}: {inst.gpu_count} GPUs @ ${inst.price_per_hour}/hr\")\n",
    "    \n",
    "    # Query 2: Find CPU instances for data processing\n",
    "    cpu_requirements = {\n",
    "        \"min_cpu_count\": 32,\n",
    "        \"min_memory_gb\": 128,\n",
    "        \"max_price\": 5.0,\n",
    "        \"gpu_count\": 0  # No GPUs needed\n",
    "    }\n",
    "    \n",
    "    print(\"\\nHigh-CPU instances for data processing:\")\n",
    "    instances = flow.find_instances(cpu_requirements, limit=5)\n",
    "    for inst in instances:\n",
    "        print(f\"  {inst.instance_type}: {inst.cpu_count} CPUs, {inst.memory_gb}GB RAM @ ${inst.price_per_hour}/hr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smart instance selection based on workload\n",
    "def select_optimal_instance(workload_type, budget_per_hour):\n",
    "    \"\"\"Select optimal instance for workload type.\"\"\"\n",
    "    workload_configs = {\n",
    "        \"inference\": {\n",
    "            \"min_gpu_count\": 1,\n",
    "            \"gpu_memory_gb\": 16,\n",
    "            \"preferred_gpu\": \"t4\"\n",
    "        },\n",
    "        \"training\": {\n",
    "            \"min_gpu_count\": 1,\n",
    "            \"gpu_memory_gb\": 40,\n",
    "            \"preferred_gpu\": \"a100\"\n",
    "        },\n",
    "        \"large_training\": {\n",
    "            \"min_gpu_count\": 8,\n",
    "            \"gpu_memory_gb\": 80,\n",
    "            \"preferred_gpu\": \"h100\"\n",
    "        },\n",
    "        \"data_processing\": {\n",
    "            \"min_cpu_count\": 32,\n",
    "            \"min_memory_gb\": 128,\n",
    "            \"gpu_count\": 0\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    requirements = workload_configs.get(workload_type, {})\n",
    "    requirements[\"max_price\"] = budget_per_hour\n",
    "    \n",
    "    with Flow() as flow:\n",
    "        instances = flow.find_instances(requirements, limit=3)\n",
    "        if instances:\n",
    "            # Return best price/performance\n",
    "            return instances[0]\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "for workload in [\"inference\", \"training\", \"data_processing\"]:\n",
    "    instance = select_optimal_instance(workload, budget_per_hour=20.0)\n",
    "    if instance:\n",
    "        print(f\"{workload.title()}: {instance.instance_type} @ ${instance.price_per_hour}/hr\")\n",
    "    else:\n",
    "        print(f\"{workload.title()}: No instances found within budget\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Storage Management - Persistent Volumes\n",
    "\n",
    "Flow SDK provides comprehensive storage management for persistent data across tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and manage volumes\n",
    "with Flow() as flow:\n",
    "    # Create a new volume\n",
    "    volume = flow.create_volume(\n",
    "        name=\"ml-datasets\",\n",
    "        size_gb=100\n",
    "    )\n",
    "    \n",
    "    print(f\"Created volume: {volume.id}\")\n",
    "    print(f\"  Name: {volume.name}\")\n",
    "    print(f\"  Size: {volume.size_gb}GB\")\n",
    "    print(f\"  Status: {volume.status}\")\n",
    "    \n",
    "    # List all volumes\n",
    "    print(\"\\nAll volumes:\")\n",
    "    volumes = flow.list_volumes()\n",
    "    for vol in volumes:\n",
    "        print(f\"  {vol.name} ({vol.id}): {vol.size_gb}GB - {vol.status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task with existing volume\n",
    "config = TaskConfig(\n",
    "    name=\"use-existing-volume\",\n",
    "    instance_type=\"gpu.nvidia.t4\",\n",
    "    volumes=[\n",
    "        {\n",
    "            \"volume_id\": \"vol-123456\",  # Attach existing volume\n",
    "            \"mount_path\": \"/data\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"scratch\",  # Create new volume\n",
    "            \"size_gb\": 50,\n",
    "            \"mount_path\": \"/scratch\"\n",
    "        }\n",
    "    ],\n",
    "    command=\"\"\"\n",
    "        echo \"=== Volume Information ===\"\n",
    "        df -h | grep -E '(Filesystem|/data|/scratch)'\n",
    "        \n",
    "        echo \"\\n=== Existing data ===\"\n",
    "        ls -la /data/\n",
    "        \n",
    "        echo \"\\n=== Processing data ===\"\n",
    "        # Process data from persistent volume\n",
    "        python process.py --input /data/dataset --output /scratch/results\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "print(\"Task configuration with volumes:\")\n",
    "print(f\"  Existing volume: {config.volumes[0]['volume_id']}\")\n",
    "print(f\"  New volume: {config.volumes[1]['name']} ({config.volumes[1]['size_gb']}GB)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data upload/download workflow\n",
    "upload_download_example = \"\"\"\n",
    "# Upload local data to volume\n",
    "with Flow() as flow:\n",
    "    # Upload directory\n",
    "    flow.upload_directory(\n",
    "        volume_id=\"vol-123456\",\n",
    "        local_path=\"./datasets/imagenet\",\n",
    "        remote_path=\"/datasets/imagenet\"\n",
    "    )\n",
    "    \n",
    "    # Upload single file\n",
    "    flow.upload_file(\n",
    "        volume_id=\"vol-123456\",\n",
    "        local_path=\"./models/checkpoint.pt\",\n",
    "        remote_path=\"/models/checkpoint.pt\"\n",
    "    )\n",
    "\n",
    "# Download results after task completion\n",
    "with Flow() as flow:\n",
    "    # Download directory\n",
    "    flow.download_directory(\n",
    "        volume_id=\"vol-123456\",\n",
    "        remote_path=\"/results\",\n",
    "        local_path=\"./results\"\n",
    "    )\n",
    "\"\"\"\n",
    "\n",
    "print(\"Data Transfer Example:\")\n",
    "print(upload_download_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Multi-Node Computing - Distributed Tasks\n",
    "\n",
    "Flow SDK supports multi-node tasks for distributed computing workloads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Multi-node configuration\nmulti_node_config = TaskConfig(\n    name=\"distributed-training\",\n    instance_type=\"gpu.nvidia.a100\",\n    instance_count=4,  # Launch 4 nodes\n    environment={\n        # Must be configured per node:\n        \"FLOW_NODE_RANK\": \"0\",  # Set differently for each node\n        \"FLOW_NODE_COUNT\": \"4\",\n        \"FLOW_NODE_0_IP\": \"SET_ME\",  # IP of rank 0 node\n        \"MASTER_PORT\": \"29500\"\n    },\n    command=\"\"\"\n        echo \"=== Node Information ===\"\n        echo \"Node Rank: ${FLOW_NODE_RANK}\"\n        echo \"Total Nodes: ${FLOW_NODE_COUNT}\"\n        echo \"Master Node: ${FLOW_NODE_0_IP}\"\n        echo \"\"\n        \n        # Set up distributed training environment\n        export MASTER_ADDR=${FLOW_NODE_0_IP}\n        export WORLD_SIZE=${FLOW_NODE_COUNT}\n        export RANK=${FLOW_NODE_RANK}\n        \n        # Run distributed training\n        python -m torch.distributed.launch \\\n            --nproc_per_node=1 \\\n            --nnodes=${WORLD_SIZE} \\\n            --node_rank=${RANK} \\\n            --master_addr=${MASTER_ADDR} \\\n            --master_port=${MASTER_PORT} \\\n            train_distributed.py\n    \"\"\"\n)\n\nprint(\"Multi-node configuration:\")\nprint(f\"  Nodes: {multi_node_config.instance_count}\")\nprint(f\"  Instance type: {multi_node_config.instance_type}\")\nprint(f\"  Total GPUs: {multi_node_config.instance_count * 1}\")\nprint(\"\\nNOTE: Environment variables must be set manually per node\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distributed data processing example\n",
    "data_parallel_config = TaskConfig(\n",
    "    name=\"parallel-data-processing\",\n",
    "    instance_type=\"cpu.large\",\n",
    "    instance_count=10,  # 10 parallel workers\n",
    "    volumes=[{\n",
    "        \"volume_id\": \"shared-data-vol\",\n",
    "        \"mount_path\": \"/data\"\n",
    "    }],\n",
    "    command=\"\"\"\n",
    "        # Each node processes a subset of data\n",
    "        TOTAL_FILES=1000\n",
    "        FILES_PER_NODE=$((TOTAL_FILES / FLOW_NODE_COUNT))\n",
    "        START=$((FLOW_NODE_RANK * FILES_PER_NODE))\n",
    "        END=$((START + FILES_PER_NODE))\n",
    "        \n",
    "        echo \"Node $FLOW_NODE_RANK processing files $START to $END\"\n",
    "        \n",
    "        # Process assigned files\n",
    "        for i in $(seq $START $END); do\n",
    "            python process_file.py --input /data/file_$i.json --output /data/processed/\n",
    "        done\n",
    "        \n",
    "        echo \"Node $FLOW_NODE_RANK completed\"\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "print(\"Data parallel processing:\")\n",
    "print(f\"  Workers: {data_parallel_config.instance_count}\")\n",
    "print(f\"  Files per worker: 100\")\n",
    "print(f\"  Total throughput: {data_parallel_config.instance_count * 100} files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Port Forwarding - Interactive Services\n",
    "\n",
    "Enable port forwarding to run interactive services like Jupyter, TensorBoard, or custom web applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Interactive service with port forwarding\ninteractive_config = TaskConfig(\n    name=\"ml-workspace\",\n    instance_type=\"gpu.nvidia.a10g\",\n    ports=[\n        8888,  # Jupyter\n        6006,  # TensorBoard\n        8501,  # Streamlit\n        5000   # Flask API\n    ],\n    command=\"\"\"\n        # Install required packages\n        pip install jupyter tensorboard streamlit flask\n        \n        # Start services\n        echo \"Starting ML workspace services...\"\n        \n        # Start Jupyter (background)\n        jupyter notebook \\\n            --ip=0.0.0.0 \\\n            --port=8888 \\\n            --no-browser \\\n            --allow-root \\\n            --NotebookApp.token='flow-demo-token' &\n        \n        # Start TensorBoard (background)\n        tensorboard --logdir=/logs --port=6006 --bind_all &\n        \n        # Start Streamlit app (background)\n        streamlit run app.py --server.port=8501 --server.address=0.0.0.0 &\n        \n        # Keep services running\n        echo \"All services started. Press Ctrl+C to stop.\"\n        sleep infinity\n    \"\"\"\n)\n\nprint(\"Interactive ML Workspace:\")\nprint(f\"  Ports: {interactive_config.ports}\")\nprint(\"\\nAfter task starts, access services at:\")\nprint(\"  Jupyter: http://<instance-ip>:8888 (token: flow-demo-token)\")\nprint(\"  TensorBoard: http://<instance-ip>:6006\")\nprint(\"  Streamlit: http://<instance-ip>:8501\")\nprint(\"  API: http://<instance-ip>:5000\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SSH tunnel setup for secure access\n",
    "tunnel_setup = \"\"\"\n",
    "# After task starts, create SSH tunnel for secure access\n",
    "\n",
    "# Get task info\n",
    "task_info = task.get_info()\n",
    "instance_ip = task_info['instance_ip']\n",
    "\n",
    "# Create SSH tunnel command\n",
    "tunnel_cmd = f'''\n",
    "ssh -L 8888:localhost:8888 \\\n",
    "    -L 6006:localhost:6006 \\\n",
    "    -L 8501:localhost:8501 \\\n",
    "    -L 5000:localhost:5000 \\\n",
    "    ubuntu@{instance_ip}\n",
    "'''\n",
    "\n",
    "print(f\"SSH Tunnel Command:\")\n",
    "print(tunnel_cmd)\n",
    "print(\"\\nThen access services locally:\")\n",
    "print(\"  Jupyter: http://localhost:8888\")\n",
    "print(\"  TensorBoard: http://localhost:6006\")\n",
    "print(\"  Streamlit: http://localhost:8501\")\n",
    "print(\"  API: http://localhost:5000\")\n",
    "\"\"\"\n",
    "\n",
    "print(\"SSH Tunnel Setup:\")\n",
    "print(tunnel_setup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Custom Startup Scripts - Advanced Initialization\n",
    "\n",
    "Create sophisticated startup scripts for complex environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced startup script with error handling\n",
    "startup_script = '''\n",
    "#!/bin/bash\n",
    "set -euo pipefail  # Exit on error, undefined vars, pipe failures\n",
    "\n",
    "# Logging setup\n",
    "LOG_FILE=\"/var/log/flow-task.log\"\n",
    "exec 1> >(tee -a \"$LOG_FILE\")\n",
    "exec 2>&1\n",
    "\n",
    "echo \"[$(date)] Starting Flow task initialization\"\n",
    "\n",
    "# Function for retrying commands\n",
    "retry() {\n",
    "    local n=1\n",
    "    local max=5\n",
    "    local delay=5\n",
    "    while true; do\n",
    "        \"$@\" && break || {\n",
    "            if [[ $n -lt $max ]]; then\n",
    "                ((n++))\n",
    "                echo \"[$(date)] Command failed. Attempt $n/$max:\"\n",
    "                sleep $delay;\n",
    "            else\n",
    "                echo \"[$(date)] Command failed after $n attempts.\"\n",
    "                return 1\n",
    "            fi\n",
    "        }\n",
    "    done\n",
    "}\n",
    "\n",
    "# System setup\n",
    "echo \"[$(date)] Configuring system...\"\n",
    "sudo sysctl -w vm.overcommit_memory=1\n",
    "sudo sysctl -w net.core.somaxconn=1024\n",
    "\n",
    "# Install dependencies with retry\n",
    "echo \"[$(date)] Installing dependencies...\"\n",
    "retry sudo apt-get update\n",
    "retry sudo apt-get install -y htop nvtop iotop git-lfs\n",
    "\n",
    "# Setup Python environment\n",
    "echo \"[$(date)] Setting up Python environment...\"\n",
    "python -m venv /opt/venv\n",
    "source /opt/venv/bin/activate\n",
    "retry pip install --upgrade pip setuptools wheel\n",
    "retry pip install -r /data/requirements.txt\n",
    "\n",
    "# Configure CUDA\n",
    "if command -v nvidia-smi &> /dev/null; then\n",
    "    echo \"[$(date)] Configuring CUDA...\"\n",
    "    export CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "    export CUDA_VISIBLE_DEVICES=0,1,2,3\n",
    "    nvidia-smi --persistence-mode=1\n",
    "fi\n",
    "\n",
    "# Mount cloud storage\n",
    "if [ -n \"${S3_BUCKET:-}\" ]; then\n",
    "    echo \"[$(date)] Mounting S3 bucket...\"\n",
    "    retry s3fs $S3_BUCKET /mnt/s3 -o allow_other\n",
    "fi\n",
    "\n",
    "# Start monitoring\n",
    "echo \"[$(date)] Starting monitoring services...\"\n",
    "nohup nvidia-smi dmon -s pucvmet -d 30 > /var/log/gpu-monitor.log &\n",
    "nohup iostat -x 30 > /var/log/io-monitor.log &\n",
    "\n",
    "# Signal readiness\n",
    "echo \"[$(date)] Initialization complete\"\n",
    "touch /tmp/flow-ready\n",
    "\n",
    "# Run main application\n",
    "echo \"[$(date)] Starting main application...\"\n",
    "cd /workspace\n",
    "exec python main.py\n",
    "'''\n",
    "\n",
    "# Create task with advanced startup\n",
    "advanced_config = TaskConfig(\n",
    "    name=\"advanced-startup\",\n",
    "    instance_type=\"gpu.nvidia.a100\",\n",
    "    startup_script=startup_script,\n",
    "    command=\"echo 'Main application running'\"\n",
    ")\n",
    "\n",
    "print(\"Advanced startup script features:\")\n",
    "print(\"  - Error handling and retries\")\n",
    "print(\"  - Comprehensive logging\")\n",
    "print(\"  - System configuration\")\n",
    "print(\"  - Environment setup\")\n",
    "print(\"  - Monitoring services\")\n",
    "print(\"  - Cloud storage mounting\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Self-Terminating Tasks - Cost Optimization\n",
    "\n",
    "Implement tasks that monitor themselves and terminate when appropriate to optimize costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Self-terminating training task\n",
    "self_terminating_config = TaskConfig(\n",
    "    name=\"auto-stop-training\",\n",
    "    instance_type=\"gpu.nvidia.a100\",\n",
    "    max_price_per_hour=50.0,\n",
    "    command=\"\"\"\n",
    "        python << 'EOF'\n",
    "import time\n",
    "import subprocess\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Training parameters\n",
    "MAX_RUNTIME = timedelta(hours=4)\n",
    "IDLE_TIMEOUT = timedelta(minutes=15)\n",
    "CONVERGENCE_THRESHOLD = 0.001\n",
    "\n",
    "start_time = datetime.now()\n",
    "last_improvement = datetime.now()\n",
    "best_loss = float('inf')\n",
    "\n",
    "def should_terminate():\n",
    "    \"\"\"Check if task should terminate.\"\"\"\n",
    "    # Check max runtime\n",
    "    if datetime.now() - start_time > MAX_RUNTIME:\n",
    "        print(\"Max runtime reached\")\n",
    "        return True\n",
    "    \n",
    "    # Check idle timeout\n",
    "    if datetime.now() - last_improvement > IDLE_TIMEOUT:\n",
    "        print(\"No improvement for 15 minutes\")\n",
    "        return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "# Simulated training loop\n",
    "for epoch in range(1000):\n",
    "    # Simulate training\n",
    "    loss = 1.0 / (epoch + 1)  # Decreasing loss\n",
    "    \n",
    "    print(f\"Epoch {epoch}: loss={loss:.4f}\")\n",
    "    \n",
    "    # Check for improvement\n",
    "    if loss < best_loss - CONVERGENCE_THRESHOLD:\n",
    "        best_loss = loss\n",
    "        last_improvement = datetime.now()\n",
    "    \n",
    "    # Check termination conditions\n",
    "    if should_terminate():\n",
    "        print(f\"Terminating: final loss={best_loss:.4f}\")\n",
    "        # Cancel own task\n",
    "        task_name = os.environ.get('FLOW_TASK_NAME')\n",
    "        if task_name:\n",
    "            subprocess.run(['flow', 'cancel', task_name])\n",
    "        break\n",
    "    \n",
    "    # Check convergence\n",
    "    if loss < 0.01:\n",
    "        print(\"Model converged!\")\n",
    "        break\n",
    "    \n",
    "    time.sleep(2)  # Simulate work\n",
    "\n",
    "print(\"Training completed\")\n",
    "EOF\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "print(\"Self-terminating task features:\")\n",
    "print(\"  - Maximum runtime limit (4 hours)\")\n",
    "print(\"  - Idle timeout (15 minutes without improvement)\")\n",
    "print(\"  - Convergence detection\")\n",
    "print(\"  - Automatic task cancellation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cost-aware task scheduling\n",
    "cost_aware_script = '''\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "import requests\n",
    "\n",
    "# Cost monitoring\n",
    "BUDGET_LIMIT = 100.0  # Maximum spend in dollars\n",
    "PRICE_PER_HOUR = float(os.environ.get('FLOW_INSTANCE_PRICE', '10.0'))\n",
    "start_time = datetime.now()\n",
    "\n",
    "def get_current_cost():\n",
    "    \"\"\"Calculate current cost.\"\"\"\n",
    "    runtime_hours = (datetime.now() - start_time).total_seconds() / 3600\n",
    "    return runtime_hours * PRICE_PER_HOUR\n",
    "\n",
    "def check_spot_termination():\n",
    "    \"\"\"Check if spot instance is being terminated.\"\"\"\n",
    "    try:\n",
    "        # AWS spot instance termination notice\n",
    "        response = requests.get(\n",
    "            'http://169.254.169.254/latest/meta-data/spot/termination-time',\n",
    "            timeout=1\n",
    "        )\n",
    "        if response.status_code == 200:\n",
    "            print(f\"Spot termination notice: {response.text}\")\n",
    "            return True\n",
    "    except:\n",
    "        pass\n",
    "    return False\n",
    "\n",
    "# Main loop with cost monitoring\n",
    "while True:\n",
    "    current_cost = get_current_cost()\n",
    "    print(f\"Current cost: ${current_cost:.2f}\")\n",
    "    \n",
    "    # Check budget\n",
    "    if current_cost >= BUDGET_LIMIT:\n",
    "        print(f\"Budget limit reached: ${BUDGET_LIMIT}\")\n",
    "        break\n",
    "    \n",
    "    # Check spot termination\n",
    "    if check_spot_termination():\n",
    "        print(\"Saving checkpoint before termination...\")\n",
    "        # Save checkpoint logic here\n",
    "        break\n",
    "    \n",
    "    # Do work\n",
    "    # ...\n",
    "    \n",
    "    time.sleep(60)\n",
    "'''\n",
    "\n",
    "print(\"Cost-aware scheduling features:\")\n",
    "print(\"  - Budget limit enforcement\")\n",
    "print(\"  - Real-time cost tracking\")\n",
    "print(\"  - Spot instance termination handling\")\n",
    "print(\"  - Checkpoint saving on termination\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Monitoring and Observability\n",
    "\n",
    "Implement comprehensive monitoring for production workloads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Task with comprehensive monitoring\nmonitoring_config = TaskConfig(\n    name=\"monitored-training\",\n    instance_type=\"gpu.nvidia.a100\",\n    environment={\n        \"WANDB_API_KEY\": \"your-wandb-key\"\n    },\n    command=\"\"\"\n        # Install monitoring tools\n        pip install wandb prometheus-client psutil gpustat\n        \n        # Start metrics collection\n        python << 'MONITORING_EOF'\nimport os\nimport time\nimport psutil\nimport gpustat\nimport wandb\nfrom prometheus_client import start_http_server, Gauge\nimport threading\n\n# Initialize monitoring\nif os.environ.get('WANDB_API_KEY'):\n    wandb.init(project=\"flow-monitoring\")\n\n# Prometheus metrics\ngpu_utilization = Gauge('gpu_utilization_percent', 'GPU utilization')\ngpu_memory_used = Gauge('gpu_memory_used_mb', 'GPU memory used')\ncpu_usage = Gauge('cpu_usage_percent', 'CPU usage')\nmemory_usage = Gauge('memory_usage_percent', 'Memory usage')\n\n# Start Prometheus server\nstart_http_server(8000)\n\ndef collect_metrics():\n    \"\"\"Collect system metrics.\"\"\"\n    while True:\n        # CPU and memory\n        cpu_pct = psutil.cpu_percent(interval=1)\n        mem_pct = psutil.virtual_memory().percent\n        \n        # GPU stats\n        gpu_stats = gpustat.GPUStatCollection.new_query()\n        if gpu_stats.gpus:\n            gpu = gpu_stats.gpus[0]\n            gpu_util = gpu.utilization\n            gpu_mem = gpu.memory_used\n        else:\n            gpu_util = 0\n            gpu_mem = 0\n        \n        # Update Prometheus metrics\n        cpu_usage.set(cpu_pct)\n        memory_usage.set(mem_pct)\n        gpu_utilization.set(gpu_util)\n        gpu_memory_used.set(gpu_mem)\n        \n        # Log to W&B\n        if wandb.run:\n            wandb.log({\n                \"cpu_usage\": cpu_pct,\n                \"memory_usage\": mem_pct,\n                \"gpu_utilization\": gpu_util,\n                \"gpu_memory_mb\": gpu_mem\n            })\n        \n        # Print summary\n        print(f\"CPU: {cpu_pct:.1f}%, Mem: {mem_pct:.1f}%, \"\n              f\"GPU: {gpu_util}%, GPU Mem: {gpu_mem}MB\")\n        \n        time.sleep(10)\n\n# Start monitoring in background\nmonitor_thread = threading.Thread(target=collect_metrics, daemon=True)\nmonitor_thread.start()\n\n# Run main task\nprint(\"Starting main task with monitoring...\")\n# Your main task code here\ntime.sleep(300)  # Simulate work\n\nMONITORING_EOF\n    \"\"\"\n)\n\nprint(\"Monitoring features:\")\nprint(\"  - Real-time metrics collection\")\nprint(\"  - Prometheus metrics endpoint (port 8000)\")\nprint(\"  - Weights & Biases integration\")\nprint(\"  - GPU and system metrics\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log aggregation and analysis\n",
    "log_aggregation_example = \"\"\"\n",
    "# Structured logging setup\n",
    "import logging\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Configure structured logging\n",
    "class JSONFormatter(logging.Formatter):\n",
    "    def format(self, record):\n",
    "        log_obj = {\n",
    "            'timestamp': datetime.utcnow().isoformat(),\n",
    "            'level': record.levelname,\n",
    "            'message': record.getMessage(),\n",
    "            'module': record.module,\n",
    "            'task_id': os.environ.get('FLOW_TASK_ID'),\n",
    "            'node_rank': os.environ.get('FLOW_NODE_RANK', '0')\n",
    "        }\n",
    "        if hasattr(record, 'metrics'):\n",
    "            log_obj['metrics'] = record.metrics\n",
    "        return json.dumps(log_obj)\n",
    "\n",
    "# Setup logger\n",
    "logger = logging.getLogger('flow_task')\n",
    "handler = logging.StreamHandler()\n",
    "handler.setFormatter(JSONFormatter())\n",
    "logger.addHandler(handler)\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# Log with metrics\n",
    "logger.info('Training started', extra={'metrics': {'epoch': 0, 'loss': 1.0}})\n",
    "\"\"\"\n",
    "\n",
    "print(\"Structured Logging Example:\")\n",
    "print(log_aggregation_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Best Practices\n",
    "\n",
    "### Advanced Features Summary\n",
    "\n",
    "1. **Instance Catalog**\n",
    "   - Query by requirements (GPU, price, region)\n",
    "   - Smart instance selection\n",
    "   - Real-time availability\n",
    "\n",
    "2. **Storage Management**\n",
    "   - Persistent volumes across tasks\n",
    "   - Data upload/download\n",
    "   - Shared storage for multi-node\n",
    "\n",
    "3. **Multi-Node Computing**\n",
    "   - Distributed training support\n",
    "   - Environment variables for coordination\n",
    "   - Parallel data processing\n",
    "\n",
    "4. **Interactive Services**\n",
    "   - Port forwarding for web services\n",
    "   - SSH tunnel for secure access\n",
    "   - Long-running services\n",
    "\n",
    "5. **Cost Optimization**\n",
    "   - Self-terminating tasks\n",
    "   - Budget enforcement\n",
    "   - Spot instance handling\n",
    "\n",
    "### Best Practices\n",
    "\n",
    "- **Always set price limits** to avoid unexpected costs\n",
    "- **Use persistent volumes** for data that needs to survive tasks\n",
    "- **Implement monitoring** for production workloads\n",
    "- **Handle failures gracefully** with retries and checkpoints\n",
    "- **Optimize instance selection** based on workload requirements\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- **Notebook 5**: Real-World Examples - Complete ML workflows\n",
    "- Explore the Flow SDK documentation for more details\n",
    "- Join the community for tips and best practices"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}