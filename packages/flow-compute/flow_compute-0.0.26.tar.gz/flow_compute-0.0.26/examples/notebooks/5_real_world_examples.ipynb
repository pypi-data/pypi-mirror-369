{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flow SDK Real-World Examples\n",
    "\n",
    "This notebook demonstrates complete, production-ready workflows using Flow SDK. Each example represents a common use case in machine learning and data processing.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "1. **End-to-End ML Pipeline** - Data prep â†’ Training â†’ Evaluation â†’ Deployment\n",
    "2. **Hyperparameter Optimization** - Distributed grid/random search\n",
    "3. **Large Model Training** - Multi-node distributed training\n",
    "4. **Data Processing Pipeline** - ETL with checkpointing\n",
    "5. **ML Development Environment** - Jupyter + experiment tracking\n",
    "6. **Production Inference Service** - Auto-scaling API deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "from flow import Flow, TaskConfig\n",
    "import yaml\n",
    "import json\n",
    "from datetime import datetime\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. End-to-End ML Pipeline\n",
    "\n",
    "A complete machine learning pipeline from data preparation to model deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ML Pipeline configuration\n",
    "ml_pipeline_yaml = \"\"\"\n",
    "# ml-pipeline.yaml\n",
    "name: ml-pipeline\n",
    "description: End-to-end ML pipeline for image classification\n",
    "\n",
    "# Shared configuration\n",
    "defaults:\n",
    "  volumes:\n",
    "    - volume_id: ml-pipeline-data\n",
    "      mount_path: /data\n",
    "  environment:\n",
    "    PROJECT_NAME: image-classifier\n",
    "    PYTHONPATH: /workspace/src\n",
    "\n",
    "# Pipeline stages\n",
    "stages:\n",
    "  # Stage 1: Data Preparation\n",
    "  - name: data-preparation\n",
    "    instance_type: cpu.large\n",
    "    command: |\n",
    "      echo \"Stage 1: Data Preparation\"\n",
    "      \n",
    "      # Install dependencies\n",
    "      pip install pandas numpy pillow scikit-learn\n",
    "      \n",
    "      # Download and prepare dataset\n",
    "      python << 'EOF'\n",
    "      import os\n",
    "      import pandas as pd\n",
    "      from sklearn.model_selection import train_test_split\n",
    "      \n",
    "      # Load dataset metadata\n",
    "      print(\"Loading dataset...\")\n",
    "      # wget https://example.com/dataset.tar.gz\n",
    "      # tar -xzf dataset.tar.gz -C /data/raw/\n",
    "      \n",
    "      # Create train/val/test splits\n",
    "      print(\"Creating data splits...\")\n",
    "      # Process images and create splits\n",
    "      \n",
    "      # Save processed data\n",
    "      print(\"Saving processed data...\")\n",
    "      # Save to /data/processed/\n",
    "      \n",
    "      # Generate data statistics\n",
    "      stats = {\n",
    "          \"total_samples\": 50000,\n",
    "          \"train_samples\": 40000,\n",
    "          \"val_samples\": 5000,\n",
    "          \"test_samples\": 5000,\n",
    "          \"num_classes\": 10\n",
    "      }\n",
    "      \n",
    "      import json\n",
    "      with open('/data/processed/stats.json', 'w') as f:\n",
    "          json.dump(stats, f)\n",
    "      \n",
    "      print(\"Data preparation complete!\")\n",
    "      print(f\"Stats: {stats}\")\n",
    "      EOF\n",
    "\n",
    "  # Stage 2: Model Training\n",
    "  - name: model-training\n",
    "    instance_type: gpu.nvidia.a100\n",
    "    depends_on: [data-preparation]\n",
    "    command: |\n",
    "      echo \"Stage 2: Model Training\"\n",
    "      \n",
    "      # Install ML frameworks\n",
    "      pip install torch torchvision tensorboard wandb\n",
    "      \n",
    "      # Train model\n",
    "      python << 'EOF'\n",
    "      import torch\n",
    "      import torch.nn as nn\n",
    "      from torch.utils.data import DataLoader\n",
    "      import json\n",
    "      import os\n",
    "      \n",
    "      # Load data stats\n",
    "      with open('/data/processed/stats.json') as f:\n",
    "          stats = json.load(f)\n",
    "      \n",
    "      print(f\"Training on {stats['train_samples']} samples\")\n",
    "      \n",
    "      # Define model (ResNet50 for example)\n",
    "      model = torch.hub.load('pytorch/vision', 'resnet50', pretrained=True)\n",
    "      model.fc = nn.Linear(2048, stats['num_classes'])\n",
    "      model = model.cuda()\n",
    "      \n",
    "      # Training configuration\n",
    "      epochs = 10\n",
    "      batch_size = 64\n",
    "      learning_rate = 0.001\n",
    "      \n",
    "      optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "      criterion = nn.CrossEntropyLoss()\n",
    "      \n",
    "      # Training loop (simplified)\n",
    "      for epoch in range(epochs):\n",
    "          print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "          # Train on batches\n",
    "          # ...\n",
    "          \n",
    "          # Validation\n",
    "          val_acc = 0.85 + epoch * 0.01  # Simulated improvement\n",
    "          print(f\"Validation accuracy: {val_acc:.3f}\")\n",
    "          \n",
    "          # Save checkpoint\n",
    "          if epoch % 5 == 0:\n",
    "              checkpoint = {\n",
    "                  'epoch': epoch,\n",
    "                  'model_state': model.state_dict(),\n",
    "                  'optimizer_state': optimizer.state_dict(),\n",
    "                  'val_acc': val_acc\n",
    "              }\n",
    "              torch.save(checkpoint, f'/data/models/checkpoint_epoch_{epoch}.pt')\n",
    "      \n",
    "      # Save final model\n",
    "      torch.save(model.state_dict(), '/data/models/final_model.pt')\n",
    "      print(\"Training complete!\")\n",
    "      EOF\n",
    "\n",
    "  # Stage 3: Model Evaluation\n",
    "  - name: model-evaluation\n",
    "    instance_type: gpu.nvidia.t4\n",
    "    depends_on: [model-training]\n",
    "    command: |\n",
    "      echo \"Stage 3: Model Evaluation\"\n",
    "      \n",
    "      pip install torch torchvision matplotlib seaborn\n",
    "      \n",
    "      python << 'EOF'\n",
    "      import torch\n",
    "      import json\n",
    "      import numpy as np\n",
    "      import matplotlib.pyplot as plt\n",
    "      \n",
    "      # Load model\n",
    "      print(\"Loading trained model...\")\n",
    "      model = torch.hub.load('pytorch/vision', 'resnet50', pretrained=False)\n",
    "      model.fc = torch.nn.Linear(2048, 10)\n",
    "      model.load_state_dict(torch.load('/data/models/final_model.pt'))\n",
    "      model = model.cuda()\n",
    "      model.eval()\n",
    "      \n",
    "      # Evaluate on test set\n",
    "      print(\"Evaluating on test set...\")\n",
    "      test_accuracy = 0.92\n",
    "      test_loss = 0.23\n",
    "      \n",
    "      # Generate evaluation report\n",
    "      report = {\n",
    "          \"test_accuracy\": test_accuracy,\n",
    "          \"test_loss\": test_loss,\n",
    "          \"precision\": 0.91,\n",
    "          \"recall\": 0.90,\n",
    "          \"f1_score\": 0.905,\n",
    "          \"confusion_matrix\": [[95, 5], [8, 92]]  # Simplified 2x2\n",
    "      }\n",
    "      \n",
    "      # Save report\n",
    "      with open('/data/evaluation/report.json', 'w') as f:\n",
    "          json.dump(report, f, indent=2)\n",
    "      \n",
    "      print(f\"Test Accuracy: {test_accuracy:.3f}\")\n",
    "      print(\"Evaluation complete!\")\n",
    "      EOF\n",
    "\n",
    "  # Stage 4: Model Deployment Preparation\n",
    "  - name: deployment-prep\n",
    "    instance_type: cpu.medium\n",
    "    depends_on: [model-evaluation]\n",
    "    command: |\n",
    "      echo \"Stage 4: Deployment Preparation\"\n",
    "      \n",
    "      # Create deployment package\n",
    "      python << 'EOF'\n",
    "      import os\n",
    "      import json\n",
    "      import shutil\n",
    "      import subprocess\n",
    "      \n",
    "      # Load evaluation results\n",
    "      with open('/data/evaluation/report.json') as f:\n",
    "          report = json.load(f)\n",
    "      \n",
    "      # Check if model meets deployment criteria\n",
    "      if report['test_accuracy'] >= 0.90:\n",
    "          print(\"Model approved for deployment!\")\n",
    "          \n",
    "          # Create deployment package\n",
    "          os.makedirs('/data/deployment', exist_ok=True)\n",
    "          \n",
    "          # Copy model\n",
    "          shutil.copy('/data/models/final_model.pt', '/data/deployment/model.pt')\n",
    "          \n",
    "          # Create model metadata\n",
    "          metadata = {\n",
    "              \"model_name\": \"image-classifier-v1\",\n",
    "              \"model_type\": \"resnet50\",\n",
    "              \"accuracy\": report['test_accuracy'],\n",
    "              \"created_at\": str(datetime.now()),\n",
    "              \"framework\": \"pytorch\",\n",
    "              \"input_shape\": [3, 224, 224],\n",
    "              \"output_classes\": 10\n",
    "          }\n",
    "          \n",
    "          with open('/data/deployment/metadata.json', 'w') as f:\n",
    "              json.dump(metadata, f, indent=2)\n",
    "          \n",
    "          # Create deployment config\n",
    "          deploy_config = {\n",
    "              \"service_name\": \"image-classifier-api\",\n",
    "              \"model_path\": \"/models/model.pt\",\n",
    "              \"batch_size\": 32,\n",
    "              \"workers\": 4,\n",
    "              \"gpu_enabled\": True\n",
    "          }\n",
    "          \n",
    "          with open('/data/deployment/config.json', 'w') as f:\n",
    "              json.dump(deploy_config, f, indent=2)\n",
    "          \n",
    "          print(\"Deployment package created!\")\n",
    "      else:\n",
    "          print(f\"Model accuracy {report['test_accuracy']:.3f} below threshold\")\n",
    "          exit(1)\n",
    "      EOF\n",
    "\"\"\"\n",
    "\n",
    "# Display pipeline configuration\n",
    "pipeline_config = yaml.safe_load(ml_pipeline_yaml)\n",
    "print(\"ML Pipeline Stages:\")\n",
    "for stage in pipeline_config['stages']:\n",
    "    print(f\"  - {stage['name']}: {stage['instance_type']}\")\n",
    "    if 'depends_on' in stage:\n",
    "        print(f\"    Depends on: {stage['depends_on']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute ML pipeline\n",
    "def run_ml_pipeline():\n",
    "    \"\"\"Execute the complete ML pipeline.\"\"\"\n",
    "    with Flow() as flow:\n",
    "        # Create shared volume\n",
    "        volume = flow.create_volume(name=\"ml-pipeline-data\", size_gb=100)\n",
    "        print(f\"Created volume: {volume.id}\")\n",
    "        \n",
    "        # Parse pipeline stages\n",
    "        pipeline_config = yaml.safe_load(ml_pipeline_yaml)\n",
    "        defaults = pipeline_config['defaults']\n",
    "        \n",
    "        # Track task dependencies\n",
    "        completed_tasks = {}\n",
    "        \n",
    "        # Execute stages in order\n",
    "        for stage in pipeline_config['stages']:\n",
    "            # Wait for dependencies\n",
    "            if 'depends_on' in stage:\n",
    "                for dep in stage['depends_on']:\n",
    "                    if dep in completed_tasks:\n",
    "                        print(f\"Waiting for {dep}...\")\n",
    "                        completed_tasks[dep].wait()\n",
    "            \n",
    "            # Create task config\n",
    "            config = TaskConfig(\n",
    "                name=stage['name'],\n",
    "                instance_type=stage['instance_type'],\n",
    "                command=stage['command'],\n",
    "                volumes=defaults['volumes'],\n",
    "                environment=defaults['environment']\n",
    "            )\n",
    "            \n",
    "            # Submit task\n",
    "            print(f\"\\nStarting stage: {stage['name']}\")\n",
    "            task = flow.run(config, wait=False)\n",
    "            completed_tasks[stage['name']] = task\n",
    "        \n",
    "        # Wait for pipeline completion\n",
    "        print(\"\\nWaiting for pipeline to complete...\")\n",
    "        for name, task in completed_tasks.items():\n",
    "            task.wait()\n",
    "            print(f\"{name}: {task.status}\")\n",
    "        \n",
    "        print(\"\\nPipeline execution complete!\")\n",
    "\n",
    "# Uncomment to run\n",
    "# run_ml_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Hyperparameter Optimization\n",
    "\n",
    "Distributed hyperparameter search across multiple configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter optimization setup\n",
    "def create_hyperparam_configs():\n",
    "    \"\"\"Generate hyperparameter configurations for grid search.\"\"\"\n",
    "    import itertools\n",
    "    \n",
    "    # Define search space\n",
    "    param_grid = {\n",
    "        'learning_rate': [0.001, 0.01, 0.1],\n",
    "        'batch_size': [32, 64, 128],\n",
    "        'optimizer': ['adam', 'sgd'],\n",
    "        'dropout': [0.2, 0.5],\n",
    "        'hidden_size': [128, 256, 512]\n",
    "    }\n",
    "    \n",
    "    # Generate all combinations\n",
    "    keys = param_grid.keys()\n",
    "    values = param_grid.values()\n",
    "    \n",
    "    configs = []\n",
    "    for combination in itertools.product(*values):\n",
    "        config = dict(zip(keys, combination))\n",
    "        configs.append(config)\n",
    "    \n",
    "    return configs\n",
    "\n",
    "# Generate configurations\n",
    "hyperparam_configs = create_hyperparam_configs()\n",
    "print(f\"Total configurations: {len(hyperparam_configs)}\")\n",
    "print(\"\\nFirst 5 configurations:\")\n",
    "for i, config in enumerate(hyperparam_configs[:5]):\n",
    "    print(f\"{i+1}: {config}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter optimization task\n",
    "hyperparam_task_template = \"\"\"\n",
    "#!/usr/bin/env python\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "# Load hyperparameters\n",
    "params = {params_json}\n",
    "print(f\"Training with parameters: {params}\")\n",
    "\n",
    "# Define model based on hyperparameters\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self, input_size=784, hidden_size=256, output_size=10, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Initialize model\n",
    "model = SimpleModel(\n",
    "    hidden_size=params['hidden_size'],\n",
    "    dropout=params['dropout']\n",
    ").cuda()\n",
    "\n",
    "# Setup optimizer\n",
    "if params['optimizer'] == 'adam':\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=params['learning_rate'])\n",
    "else:\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=params['learning_rate'])\n",
    "\n",
    "# Training loop (simplified)\n",
    "epochs = 20\n",
    "best_val_acc = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Simulate training\n",
    "    train_loss = 1.0 / (epoch + 1) + np.random.normal(0, 0.1)\n",
    "    \n",
    "    # Simulate validation\n",
    "    val_acc = min(0.95, 0.7 + epoch * 0.01 + params['learning_rate'] * 2)\n",
    "    val_acc += np.random.normal(0, 0.02)\n",
    "    \n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}: train_loss={train_loss:.4f}, val_acc={val_acc:.4f}\")\n",
    "    time.sleep(0.5)  # Simulate work\n",
    "\n",
    "# Save results\n",
    "results = {\n",
    "    'params': params,\n",
    "    'best_val_acc': float(best_val_acc),\n",
    "    'final_train_loss': float(train_loss),\n",
    "    'task_id': os.environ.get('FLOW_TASK_ID', 'unknown')\n",
    "}\n",
    "\n",
    "# Save to shared volume\n",
    "result_file = f\"/results/hyperparam_{params['learning_rate']}_{params['batch_size']}_{params['hidden_size']}.json\"\n",
    "os.makedirs(os.path.dirname(result_file), exist_ok=True)\n",
    "with open(result_file, 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(f\"\\nBest validation accuracy: {best_val_acc:.4f}\")\n",
    "print(f\"Results saved to: {result_file}\")\n",
    "\"\"\"\n",
    "\n",
    "# Launch hyperparameter search\n",
    "def run_hyperparam_search(configs, max_parallel=10):\n",
    "    \"\"\"Run distributed hyperparameter search.\"\"\"\n",
    "    with Flow() as flow:\n",
    "        # Create shared results volume\n",
    "        results_volume = flow.create_volume(name=\"hyperparam-results\", size_gb=10)\n",
    "        \n",
    "        tasks = []\n",
    "        \n",
    "        # Submit tasks in batches\n",
    "        for i, params in enumerate(configs[:max_parallel]):\n",
    "            # Create task-specific script\n",
    "            script = hyperparam_task_template.format(params_json=json.dumps(params))\n",
    "            \n",
    "            config = TaskConfig(\n",
    "                name=f\"hyperparam-{i}\",\n",
    "                instance_type=\"gpu.nvidia.t4\",\n",
    "                command=f\"python -c '{script}'\",\n",
    "                volumes=[{\n",
    "                    \"volume_id\": results_volume.id,\n",
    "                    \"mount_path\": \"/results\"\n",
    "                }]\n",
    "            )\n",
    "            \n",
    "            task = flow.run(config, wait=False)\n",
    "            tasks.append((params, task))\n",
    "            print(f\"Submitted task {i+1}/{len(configs)}\")\n",
    "        \n",
    "        # Wait for completion and collect results\n",
    "        print(\"\\nWaiting for tasks to complete...\")\n",
    "        results = []\n",
    "        \n",
    "        for params, task in tasks:\n",
    "            task.wait()\n",
    "            if task.status.value == \"completed\":\n",
    "                results.append(params)\n",
    "        \n",
    "        print(f\"\\nCompleted {len(results)} experiments\")\n",
    "        return results\n",
    "\n",
    "# Example usage\n",
    "print(\"Hyperparameter search configuration:\")\n",
    "print(f\"  Total experiments: {len(hyperparam_configs)}\")\n",
    "print(f\"  Instance type: gpu.nvidia.t4\")\n",
    "print(f\"  Parallel tasks: 10\")\n",
    "print(\"\\nTo run: results = run_hyperparam_search(hyperparam_configs)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Large Model Training - Multi-Node Distributed\n",
    "\n",
    "Training large language models across multiple GPUs and nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Large model distributed training configuration\n",
    "large_model_config = TaskConfig(\n",
    "    name=\"llm-training\",\n",
    "    instance_type=\"gpu.nvidia.a100\",  # 8x A100 GPUs per node\n",
    "    instance_count=4,  # 4 nodes = 32 GPUs total\n",
    "    environment={\n",
    "        \"MODEL_NAME\": \"gpt-7b\",\n",
    "        \"BATCH_SIZE\": \"4\",  # Per GPU\n",
    "        \"GRADIENT_ACCUMULATION_STEPS\": \"8\",\n",
    "        \"LEARNING_RATE\": \"1e-4\",\n",
    "        \"WARMUP_STEPS\": \"2000\",\n",
    "        \"SAVE_STEPS\": \"1000\",\n",
    "        \"WANDB_PROJECT\": \"llm-training\"\n",
    "    },\n",
    "    volumes=[\n",
    "        {\"volume_id\": \"training-data-vol\", \"mount_path\": \"/data\"},\n",
    "        {\"volume_id\": \"model-checkpoints-vol\", \"mount_path\": \"/checkpoints\"}\n",
    "    ],\n",
    "    command=\"\"\"\n",
    "#!/bin/bash\n",
    "set -e\n",
    "\n",
    "echo \"=== Large Model Distributed Training ===\"\n",
    "echo \"Node: $FLOW_NODE_RANK / $FLOW_NODE_COUNT\"\n",
    "echo \"Master: $FLOW_NODE_0_IP\"\n",
    "\n",
    "# Install dependencies\n",
    "pip install torch transformers datasets accelerate deepspeed wandb\n",
    "\n",
    "# Setup distributed environment\n",
    "export MASTER_ADDR=$FLOW_NODE_0_IP\n",
    "export MASTER_PORT=29500\n",
    "export WORLD_SIZE=$((FLOW_NODE_COUNT * 8))  # 8 GPUs per node\n",
    "export RANK=$((FLOW_NODE_RANK * 8))\n",
    "\n",
    "# Create DeepSpeed configuration\n",
    "cat > ds_config.json << 'DEEPSPEED_EOF'\n",
    "{\n",
    "  \"train_batch_size\": 128,\n",
    "  \"gradient_accumulation_steps\": 8,\n",
    "  \"fp16\": {\n",
    "    \"enabled\": true\n",
    "  },\n",
    "  \"zero_optimization\": {\n",
    "    \"stage\": 3,\n",
    "    \"offload_optimizer\": {\n",
    "      \"device\": \"cpu\"\n",
    "    },\n",
    "    \"offload_param\": {\n",
    "      \"device\": \"cpu\"\n",
    "    },\n",
    "    \"overlap_comm\": true,\n",
    "    \"contiguous_gradients\": true,\n",
    "    \"reduce_bucket_size\": 1e8\n",
    "  },\n",
    "  \"gradient_clipping\": 1.0,\n",
    "  \"wall_clock_breakdown\": true\n",
    "}\n",
    "DEEPSPEED_EOF\n",
    "\n",
    "# Training script\n",
    "python << 'TRAINING_EOF'\n",
    "import os\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorForLanguageModeling\n",
    ")\n",
    "from datasets import load_dataset\n",
    "import wandb\n",
    "\n",
    "# Initialize W&B on rank 0\n",
    "if int(os.environ.get('RANK', 0)) == 0:\n",
    "    wandb.init(\n",
    "        project=os.environ.get('WANDB_PROJECT', 'llm-training'),\n",
    "        name=f\"{os.environ['MODEL_NAME']}-{os.environ['FLOW_TASK_ID']}\"\n",
    "    )\n",
    "\n",
    "print(f\"Loading model: {os.environ['MODEL_NAME']}\")\n",
    "\n",
    "# Load model and tokenizer\n",
    "model_name = \"gpt2\"  # Use smaller model for demo\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "# Add padding token\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Load dataset\n",
    "print(\"Loading dataset...\")\n",
    "dataset = load_dataset(\"wikitext\", \"wikitext-2-raw-v1\")\n",
    "\n",
    "# Tokenize dataset\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"text\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=512\n",
    "    )\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Setup training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/checkpoints\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=int(os.environ['BATCH_SIZE']),\n",
    "    per_device_eval_batch_size=int(os.environ['BATCH_SIZE']),\n",
    "    gradient_accumulation_steps=int(os.environ['GRADIENT_ACCUMULATION_STEPS']),\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=500,\n",
    "    save_steps=int(os.environ['SAVE_STEPS']),\n",
    "    warmup_steps=int(os.environ['WARMUP_STEPS']),\n",
    "    learning_rate=float(os.environ['LEARNING_RATE']),\n",
    "    logging_steps=10,\n",
    "    logging_dir=\"/checkpoints/logs\",\n",
    "    deepspeed=\"ds_config.json\",\n",
    "    fp16=True,\n",
    "    report_to=[\"wandb\"] if int(os.environ.get('RANK', 0)) == 0 else [],\n",
    ")\n",
    "\n",
    "# Data collator\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False,\n",
    ")\n",
    "\n",
    "# Initialize trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    ")\n",
    "\n",
    "# Start training\n",
    "print(\"Starting distributed training...\")\n",
    "trainer.train()\n",
    "\n",
    "# Save final model\n",
    "if int(os.environ.get('RANK', 0)) == 0:\n",
    "    print(\"Saving final model...\")\n",
    "    trainer.save_model(\"/checkpoints/final\")\n",
    "    tokenizer.save_pretrained(\"/checkpoints/final\")\n",
    "\n",
    "print(\"Training complete!\")\n",
    "TRAINING_EOF\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "print(\"Large Model Training Configuration:\")\n",
    "print(f\"  Model: {large_model_config.environment['MODEL_NAME']}\")\n",
    "print(f\"  Nodes: {large_model_config.instance_count}\")\n",
    "print(f\"  Total GPUs: {large_model_config.instance_count * 8}\")\n",
    "print(f\"  Global batch size: {32 * 4 * 8}\")\n",
    "print(\"  Optimization: DeepSpeed ZeRO-3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Processing Pipeline with Checkpointing\n",
    "\n",
    "Large-scale data processing with fault tolerance and checkpointing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data processing pipeline with checkpointing\n",
    "data_pipeline_script = \"\"\"\n",
    "#!/usr/bin/env python\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "import hashlib\n",
    "\n",
    "class CheckpointedProcessor:\n",
    "    def __init__(self, checkpoint_dir=\"/data/checkpoints\"):\n",
    "        self.checkpoint_dir = checkpoint_dir\n",
    "        os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "        self.checkpoint_file = os.path.join(checkpoint_dir, \"processor_state.pkl\")\n",
    "        \n",
    "    def load_checkpoint(self):\n",
    "        \"\"\"Load processing state from checkpoint.\"\"\"\n",
    "        if os.path.exists(self.checkpoint_file):\n",
    "            with open(self.checkpoint_file, 'rb') as f:\n",
    "                state = pickle.load(f)\n",
    "                print(f\"Resuming from checkpoint: {state['processed_count']} files processed\")\n",
    "                return state\n",
    "        return {\n",
    "            'processed_files': set(),\n",
    "            'processed_count': 0,\n",
    "            'failed_files': [],\n",
    "            'start_time': datetime.now().isoformat()\n",
    "        }\n",
    "    \n",
    "    def save_checkpoint(self, state):\n",
    "        \"\"\"Save current processing state.\"\"\"\n",
    "        with open(self.checkpoint_file, 'wb') as f:\n",
    "            pickle.dump(state, f)\n",
    "    \n",
    "    def process_file(self, filepath):\n",
    "        \"\"\"Process a single file with error handling.\"\"\"\n",
    "        try:\n",
    "            # Simulate file processing\n",
    "            print(f\"Processing: {filepath}\")\n",
    "            \n",
    "            # Read file (simulated)\n",
    "            file_size = os.path.getsize(filepath) if os.path.exists(filepath) else 1000000\n",
    "            \n",
    "            # Simulate processing time based on file size\n",
    "            process_time = min(file_size / 1000000, 5)  # Max 5 seconds\n",
    "            time.sleep(process_time)\n",
    "            \n",
    "            # Generate output\n",
    "            output = {\n",
    "                'input_file': filepath,\n",
    "                'file_size': file_size,\n",
    "                'processed_at': datetime.now().isoformat(),\n",
    "                'checksum': hashlib.md5(filepath.encode()).hexdigest(),\n",
    "                'records_processed': file_size // 100\n",
    "            }\n",
    "            \n",
    "            # Save output\n",
    "            output_file = filepath.replace('/input/', '/output/').replace('.raw', '.json')\n",
    "            os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "            with open(output_file, 'w') as f:\n",
    "                json.dump(output, f)\n",
    "            \n",
    "            return True, output\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filepath}: {e}\")\n",
    "            return False, str(e)\n",
    "    \n",
    "    def run(self, input_files):\n",
    "        \"\"\"Run processing pipeline with checkpointing.\"\"\"\n",
    "        # Load checkpoint\n",
    "        state = self.load_checkpoint()\n",
    "        \n",
    "        # Process files\n",
    "        for filepath in input_files:\n",
    "            # Skip already processed files\n",
    "            if filepath in state['processed_files']:\n",
    "                continue\n",
    "            \n",
    "            # Process file\n",
    "            success, result = self.process_file(filepath)\n",
    "            \n",
    "            if success:\n",
    "                state['processed_files'].add(filepath)\n",
    "                state['processed_count'] += 1\n",
    "            else:\n",
    "                state['failed_files'].append({\n",
    "                    'file': filepath,\n",
    "                    'error': result,\n",
    "                    'timestamp': datetime.now().isoformat()\n",
    "                })\n",
    "            \n",
    "            # Save checkpoint every 10 files\n",
    "            if state['processed_count'] % 10 == 0:\n",
    "                self.save_checkpoint(state)\n",
    "                print(f\"Checkpoint saved: {state['processed_count']} files processed\")\n",
    "        \n",
    "        # Final checkpoint\n",
    "        state['end_time'] = datetime.now().isoformat()\n",
    "        self.save_checkpoint(state)\n",
    "        \n",
    "        # Generate summary\n",
    "        summary = {\n",
    "            'total_files': len(input_files),\n",
    "            'processed_files': state['processed_count'],\n",
    "            'failed_files': len(state['failed_files']),\n",
    "            'start_time': state['start_time'],\n",
    "            'end_time': state['end_time']\n",
    "        }\n",
    "        \n",
    "        with open('/data/processing_summary.json', 'w') as f:\n",
    "            json.dump(summary, f, indent=2)\n",
    "        \n",
    "        print(f\"\\nProcessing complete!\")\n",
    "        print(f\"Processed: {summary['processed_files']}\")\n",
    "        print(f\"Failed: {summary['failed_files']}\")\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Get list of input files\n",
    "    input_files = []\n",
    "    for i in range(100):\n",
    "        input_files.append(f\"/data/input/file_{i:04d}.raw\")\n",
    "    \n",
    "    # Run processor\n",
    "    processor = CheckpointedProcessor()\n",
    "    processor.run(input_files)\n",
    "\"\"\"\n",
    "\n",
    "# Create data processing task\n",
    "data_processing_config = TaskConfig(\n",
    "    name=\"data-processing-pipeline\",\n",
    "    instance_type=\"cpu.large\",\n",
    "    instance_count=5,  # Process in parallel\n",
    "    volumes=[\n",
    "        {\"volume_id\": \"raw-data-vol\", \"mount_path\": \"/data/input\"},\n",
    "        {\"volume_id\": \"processed-data-vol\", \"mount_path\": \"/data/output\"},\n",
    "        {\"name\": \"checkpoints\", \"size_gb\": 10, \"mount_path\": \"/data/checkpoints\"}\n",
    "    ],\n",
    "    command=f\"python -c '{data_pipeline_script}'\"\n",
    ")\n",
    "\n",
    "print(\"Data Processing Pipeline:\")\n",
    "print(\"  Features:\")\n",
    "print(\"    - Automatic checkpointing\")\n",
    "print(\"    - Failure recovery\")\n",
    "print(\"    - Parallel processing\")\n",
    "print(\"    - Progress tracking\")\n",
    "print(f\"  Workers: {data_processing_config.instance_count}\")\n",
    "print(f\"  Instance type: {data_processing_config.instance_type}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ML Development Environment\n",
    "\n",
    "Complete ML development environment with Jupyter, experiment tracking, and model serving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ML Development Environment\nml_dev_env_config = TaskConfig(\n    name=\"ml-dev-environment\",\n    instance_type=\"gpu.nvidia.a10g\",\n    ports=[8888, 6006, 8501, 5000, 8000],  # Jupyter, TensorBoard, Streamlit, API, Prometheus\n    volumes=[\n        {\"name\": \"workspace\", \"size_gb\": 200, \"mount_path\": \"/workspace\"},\n        {\"name\": \"datasets\", \"size_gb\": 500, \"mount_path\": \"/datasets\"},\n        {\"name\": \"models\", \"size_gb\": 100, \"mount_path\": \"/models\"}\n    ],\n    environment={\n        \"JUPYTER_TOKEN\": \"ml-dev-token-123\",\n        \"MLFLOW_TRACKING_URI\": \"http://localhost:5000\"\n    },\n    command=\"\"\"\n#!/bin/bash\nset -e\n\necho \"=== Setting up ML Development Environment ===\"\n\n# Install comprehensive ML stack\npip install --upgrade pip\npip install \\\n    jupyter jupyterlab ipywidgets \\\n    numpy pandas scikit-learn matplotlib seaborn plotly \\\n    torch torchvision torchaudio transformers datasets \\\n    tensorflow tensorboard \\\n    mlflow wandb \\\n    streamlit gradio \\\n    fastapi uvicorn \\\n    pytest black flake8 mypy\n\n# Install Jupyter extensions\njupyter nbextension enable --py widgetsnbextension\n\n# Setup workspace structure\nmkdir -p /workspace/{notebooks,src,experiments,configs}\n\n# Create welcome notebook\ncat > /workspace/notebooks/Welcome.ipynb << 'NOTEBOOK_EOF'\n{\n \"cells\": [\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"# ML Development Environment\\\\n\",\n    \"\\\\n\",\n    \"## Available Services\\\\n\",\n    \"- **Jupyter Lab**: http://localhost:8888 (token: ml-dev-token-123)\\\\n\",\n    \"- **TensorBoard**: http://localhost:6006\\\\n\",\n    \"- **MLflow**: http://localhost:5000\\\\n\",\n    \"- **API Server**: http://localhost:8000\\\\n\",\n    \"\\\\n\",\n    \"## Quick Start\\\\n\",\n    \"1. Check GPU availability\\\\n\",\n    \"2. Load a dataset\\\\n\",\n    \"3. Train a model\\\\n\",\n    \"4. Track experiments\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"import torch\\\\n\",\n    \"import tensorflow as tf\\\\n\",\n    \"print(f'PyTorch: {torch.__version__}')\\\\n\",\n    \"print(f'TensorFlow: {tf.__version__}')\\\\n\",\n    \"print(f'CUDA Available: {torch.cuda.is_available()}')\\\\n\",\n    \"if torch.cuda.is_available():\\\\n\",\n    \"    print(f'GPU: {torch.cuda.get_device_name(0)}')\"\n   ]\n  }\n ],\n \"metadata\": {\n  \"kernelspec\": {\n   \"display_name\": \"Python 3\",\n   \"language\": \"python\",\n   \"name\": \"python3\"\n  }\n },\n \"nbformat\": 4,\n \"nbformat_minor\": 4\n}\nNOTEBOOK_EOF\n\n# Start MLflow server\necho \"Starting MLflow server...\"\nmlflow server \\\n    --host 0.0.0.0 \\\n    --port 5000 \\\n    --backend-store-uri sqlite:////workspace/mlflow.db \\\n    --default-artifact-root /workspace/mlflow-artifacts &\n\n# Start TensorBoard\necho \"Starting TensorBoard...\"\ntensorboard --logdir=/workspace/experiments --port=6006 --bind_all &\n\n# Create simple model serving API\ncat > /workspace/api.py << 'API_EOF'\nfrom fastapi import FastAPI\nfrom pydantic import BaseModel\nimport torch\nimport numpy as np\n\napp = FastAPI(title=\"ML Model API\")\n\nclass PredictionRequest(BaseModel):\n    data: list\n\nclass PredictionResponse(BaseModel):\n    prediction: list\n    confidence: float\n\n@app.get(\"/\")\ndef root():\n    return {\"message\": \"ML Model API\", \"status\": \"ready\"}\n\n@app.post(\"/predict\", response_model=PredictionResponse)\ndef predict(request: PredictionRequest):\n    # Dummy prediction\n    data = np.array(request.data)\n    prediction = data.mean(axis=0).tolist()\n    confidence = np.random.uniform(0.8, 0.99)\n    return PredictionResponse(prediction=prediction, confidence=confidence)\n\n@app.get(\"/health\")\ndef health():\n    return {\"status\": \"healthy\", \"gpu_available\": torch.cuda.is_available()}\nAPI_EOF\n\n# Start API server\necho \"Starting API server...\"\ncd /workspace && uvicorn api:app --host 0.0.0.0 --port 8000 &\n\n# Start Jupyter Lab (foreground)\necho \"Starting Jupyter Lab...\"\njupyter lab \\\n    --ip=0.0.0.0 \\\n    --port=8888 \\\n    --no-browser \\\n    --allow-root \\\n    --NotebookApp.token=$JUPYTER_TOKEN \\\n    --NotebookApp.notebook_dir=/workspace\n    \"\"\"\n)\n\nprint(\"ML Development Environment:\")\nprint(\"  Services:\")\nprint(\"    - JupyterLab (port 8888)\")\nprint(\"    - MLflow Tracking (port 5000)\")\nprint(\"    - TensorBoard (port 6006)\")\nprint(\"    - Model API (port 8000)\")\nprint(\"  Storage:\")\nprint(\"    - Workspace: 200GB\")\nprint(\"    - Datasets: 500GB\")\nprint(\"    - Models: 100GB\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Production Inference Service\n",
    "\n",
    "Auto-scaling production inference service with monitoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Production inference service\n",
    "inference_service_yaml = \"\"\"\n",
    "name: model-inference-service\n",
    "instance_type: gpu.nvidia.t4\n",
    "min_instances: 2\n",
    "max_instances: 10\n",
    "scale_up_threshold: 0.8  # CPU/GPU utilization\n",
    "scale_down_threshold: 0.3\n",
    "\n",
    "ports:\n",
    "  - 8080  # API endpoint\n",
    "  - 9090  # Prometheus metrics\n",
    "\n",
    "health_check:\n",
    "  endpoint: /health\n",
    "  interval: 30\n",
    "  timeout: 10\n",
    "  unhealthy_threshold: 3\n",
    "\n",
    "volumes:\n",
    "  - volume_id: production-models\n",
    "    mount_path: /models\n",
    "\n",
    "environment:\n",
    "  MODEL_NAME: image-classifier-v2\n",
    "  MODEL_PATH: /models/image-classifier-v2.pt\n",
    "  BATCH_SIZE: 32\n",
    "  MAX_BATCH_WAIT_MS: 100\n",
    "  WORKERS: 4\n",
    "\n",
    "command: |\n",
    "  #!/bin/bash\n",
    "  \n",
    "  # Install dependencies\n",
    "  pip install fastapi uvicorn torch torchvision pillow prometheus-client\n",
    "  \n",
    "  # Create inference service\n",
    "  cat > inference_service.py << 'SERVICE_EOF'\n",
    "  import os\n",
    "  import time\n",
    "  import torch\n",
    "  import torchvision.transforms as transforms\n",
    "  from fastapi import FastAPI, File, UploadFile, HTTPException\n",
    "  from fastapi.responses import JSONResponse\n",
    "  from prometheus_client import Counter, Histogram, Gauge, generate_latest\n",
    "  from PIL import Image\n",
    "  import io\n",
    "  import asyncio\n",
    "  from typing import List\n",
    "  import numpy as np\n",
    "  \n",
    "  # Metrics\n",
    "  request_count = Counter('inference_requests_total', 'Total inference requests')\n",
    "  request_duration = Histogram('inference_duration_seconds', 'Inference duration')\n",
    "  batch_size_gauge = Gauge('inference_batch_size', 'Current batch size')\n",
    "  gpu_utilization = Gauge('gpu_utilization_percent', 'GPU utilization')\n",
    "  \n",
    "  app = FastAPI(title=\"Model Inference Service\")\n",
    "  \n",
    "  # Load model\n",
    "  print(f\"Loading model from {os.environ['MODEL_PATH']}\")\n",
    "  model = torch.hub.load('pytorch/vision', 'resnet50', pretrained=True)\n",
    "  model.eval()\n",
    "  if torch.cuda.is_available():\n",
    "      model = model.cuda()\n",
    "  \n",
    "  # Image preprocessing\n",
    "  preprocess = transforms.Compose([\n",
    "      transforms.Resize(256),\n",
    "      transforms.CenterCrop(224),\n",
    "      transforms.ToTensor(),\n",
    "      transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "  ])\n",
    "  \n",
    "  # Batch collector\n",
    "  class BatchCollector:\n",
    "      def __init__(self, max_batch_size=32, max_wait_ms=100):\n",
    "          self.max_batch_size = max_batch_size\n",
    "          self.max_wait_ms = max_wait_ms\n",
    "          self.batch = []\n",
    "          self.futures = []\n",
    "          self.lock = asyncio.Lock()\n",
    "          self.last_batch_time = time.time()\n",
    "  \n",
    "  batch_collector = BatchCollector(\n",
    "      max_batch_size=int(os.environ['BATCH_SIZE']),\n",
    "      max_wait_ms=int(os.environ['MAX_BATCH_WAIT_MS'])\n",
    "  )\n",
    "  \n",
    "  @app.post(\"/predict\")\n",
    "  async def predict(file: UploadFile = File(...)):\n",
    "      request_count.inc()\n",
    "      \n",
    "      with request_duration.time():\n",
    "          # Read and preprocess image\n",
    "          contents = await file.read()\n",
    "          image = Image.open(io.BytesIO(contents))\n",
    "          input_tensor = preprocess(image)\n",
    "          \n",
    "          # Add to batch\n",
    "          future = asyncio.Future()\n",
    "          async with batch_collector.lock:\n",
    "              batch_collector.batch.append(input_tensor)\n",
    "              batch_collector.futures.append(future)\n",
    "              \n",
    "              # Process batch if full or timeout\n",
    "              if len(batch_collector.batch) >= batch_collector.max_batch_size or \\\n",
    "                 (time.time() - batch_collector.last_batch_time) * 1000 > batch_collector.max_wait_ms:\n",
    "                  await process_batch()\n",
    "          \n",
    "          # Wait for result\n",
    "          result = await future\n",
    "          return JSONResponse(result)\n",
    "  \n",
    "  async def process_batch():\n",
    "      \"\"\"Process accumulated batch.\"\"\"\n",
    "      batch = torch.stack(batch_collector.batch)\n",
    "      futures = batch_collector.futures\n",
    "      \n",
    "      batch_size_gauge.set(len(batch))\n",
    "      \n",
    "      # Clear batch\n",
    "      batch_collector.batch = []\n",
    "      batch_collector.futures = []\n",
    "      batch_collector.last_batch_time = time.time()\n",
    "      \n",
    "      # Run inference\n",
    "      if torch.cuda.is_available():\n",
    "          batch = batch.cuda()\n",
    "      \n",
    "      with torch.no_grad():\n",
    "          outputs = model(batch)\n",
    "          probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
    "          predictions = probabilities.argmax(dim=1)\n",
    "      \n",
    "      # Return results\n",
    "      for i, future in enumerate(futures):\n",
    "          result = {\n",
    "              \"class\": int(predictions[i]),\n",
    "              \"confidence\": float(probabilities[i].max()),\n",
    "              \"top_5\": probabilities[i].topk(5).indices.tolist()\n",
    "          }\n",
    "          future.set_result(result)\n",
    "  \n",
    "  @app.get(\"/health\")\n",
    "  def health_check():\n",
    "      return {\n",
    "          \"status\": \"healthy\",\n",
    "          \"model\": os.environ['MODEL_NAME'],\n",
    "          \"gpu_available\": torch.cuda.is_available()\n",
    "      }\n",
    "  \n",
    "  @app.get(\"/metrics\")\n",
    "  def metrics():\n",
    "      return generate_latest()\n",
    "  \n",
    "  # Background GPU monitoring\n",
    "  async def monitor_gpu():\n",
    "      while True:\n",
    "          if torch.cuda.is_available():\n",
    "              # Get GPU utilization (simulated)\n",
    "              util = torch.cuda.utilization()\n",
    "              gpu_utilization.set(util)\n",
    "          await asyncio.sleep(10)\n",
    "  \n",
    "  @app.on_event(\"startup\")\n",
    "  async def startup_event():\n",
    "      asyncio.create_task(monitor_gpu())\n",
    "  \n",
    "  SERVICE_EOF\n",
    "  \n",
    "  # Start service\n",
    "  uvicorn inference_service:app --host 0.0.0.0 --port 8080 --workers $WORKERS\n",
    "\"\"\"\n",
    "\n",
    "print(\"Production Inference Service:\")\n",
    "print(\"  Features:\")\n",
    "print(\"    - Auto-scaling (2-10 instances)\")\n",
    "print(\"    - Batch inference\")\n",
    "print(\"    - Health checks\")\n",
    "print(\"    - Prometheus metrics\")\n",
    "print(\"    - GPU optimization\")\n",
    "print(\"  Performance:\")\n",
    "print(\"    - Batch size: 32\")\n",
    "print(\"    - Max latency: 100ms\")\n",
    "print(\"    - Workers: 4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Summary\n\nThis notebook demonstrated production-ready workflows using Flow SDK:\n\n### 1. **End-to-End ML Pipeline**\n- Multi-stage pipeline with dependencies\n- Data prep â†’ Training â†’ Evaluation â†’ Deployment\n- Automatic checkpoint and model versioning\n\n### 2. **Hyperparameter Optimization**\n- Distributed grid/random search\n- Parallel experiment execution\n- Result aggregation and analysis\n\n### 3. **Large Model Training**\n- Multi-node distributed training\n- DeepSpeed optimization\n- Gradient accumulation and mixed precision\n\n### 4. **Data Processing Pipeline**\n- Fault-tolerant processing with checkpoints\n- Parallel data transformation\n- Progress tracking and recovery\n\n### 5. **ML Development Environment**\n- Complete ML stack (Jupyter, MLflow, TensorBoard)\n- Persistent workspace\n- Integrated tooling\n\n### 6. **Production Inference**\n- Auto-scaling service\n- Batch inference optimization\n- Monitoring and health checks\n\n### Best Practices Applied\n\n- **Cost Optimization**: Use appropriate instance types, set runtime limits\n- **Fault Tolerance**: Checkpointing, error handling, retries\n- **Monitoring**: Metrics, logging, health checks\n- **Scalability**: Multi-node support, auto-scaling\n- **Reproducibility**: Version control, experiment tracking\n\n### Next Steps\n\n1. Adapt these examples to your specific use cases\n2. Integrate with your existing ML infrastructure\n3. Explore Flow SDK's advanced features\n4. Join the community for support and best practices\n\nHappy building with Flow SDK! ðŸš€"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}