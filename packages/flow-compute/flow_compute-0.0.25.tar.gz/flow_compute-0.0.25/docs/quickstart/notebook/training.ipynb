{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flow SDK Training Notebook\n",
    "\n",
    "Train models from scratch using Flow SDK with support for distributed training, automatic checkpointing, and cost optimization.\n",
    "\n",
    "This notebook covers:\n",
    "- Single GPU training\n",
    "- Multi-GPU distributed training\n",
    "- Training from checkpoints\n",
    "- Monitoring training progress\n",
    "- Cost optimization strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's install and configure the Flow SDK:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Flow SDK\n",
    "!pip install flow-sdk --upgrade\n",
    "\n",
    "# Import required libraries\n",
    "import flow\n",
    "from flow import TaskConfig\n",
    "import json\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Dict, List\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Flow client\n",
    "flow_client = flow.Flow()\n",
    "\n",
    "# Check authentication\n",
    "print(\"‚úì Flow SDK initialized\")\n",
    "print(f\"API Endpoint: {flow_client.api_endpoint}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Quick Training Example\n",
    "\n",
    "Let's start with a simple ResNet training on CIFAR-10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training script\n",
    "simple_train_script = \"\"\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "import json\n",
    "\n",
    "# Training configuration\n",
    "config = {\n",
    "    'batch_size': 128,\n",
    "    'epochs': 10,\n",
    "    'learning_rate': 0.001,\n",
    "    'device': 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "}\n",
    "\n",
    "print(f\"Training on: {config['device']}\")\n",
    "if config['device'] == 'cuda':\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "\n",
    "# Data preparation\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=config['batch_size'], shuffle=False, num_workers=2)\n",
    "\n",
    "# Model setup\n",
    "model = models.resnet18(pretrained=False, num_classes=10)\n",
    "model = model.to(config['device'])\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=config['learning_rate'])\n",
    "\n",
    "# Training loop\n",
    "metrics = {'train_loss': [], 'test_accuracy': []}\n",
    "\n",
    "for epoch in range(config['epochs']):\n",
    "    # Training\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(config['device']), target.to(config['device'])\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        if batch_idx % 50 == 0:\n",
    "            print(f'Epoch {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)}] '\n",
    "                  f'Loss: {loss.item():.4f}')\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(config['device']), target.to(config['device'])\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    \n",
    "    accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    epoch_time = time.time() - start_time\n",
    "    \n",
    "    print(f'\\nEpoch {epoch}: Train Loss: {train_loss/len(train_loader):.4f}, '\n",
    "          f'Test Accuracy: {accuracy:.2f}%, Time: {epoch_time:.1f}s\\n')\n",
    "    \n",
    "    metrics['train_loss'].append(train_loss / len(train_loader))\n",
    "    metrics['test_accuracy'].append(accuracy)\n",
    "\n",
    "# Save model and metrics\n",
    "torch.save(model.state_dict(), 'resnet18_cifar10.pth')\n",
    "with open('training_metrics.json', 'w') as f:\n",
    "    json.dump(metrics, f)\n",
    "\n",
    "print(f\"\\nTraining complete! Final accuracy: {accuracy:.2f}%\")\n",
    "\"\"\"\n",
    "\n",
    "# Save script\n",
    "with open(\"/tmp/train_cifar10.py\", \"w\") as f:\n",
    "    f.write(simple_train_script)\n",
    "\n",
    "print(\"‚úì Training script created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure and run training\n",
    "training_config = TaskConfig(\n",
    "    name=\"cifar10-resnet-training\",\n",
    "    command=\"\"\"\n",
    "    pip install torch torchvision\n",
    "    python /workspace/train_cifar10.py\n",
    "    \"\"\",\n",
    "    instance_type=\"a100\",  # Single A100 80GB\n",
    "    upload_files={\"/tmp/train_cifar10.py\": \"train_cifar10.py\"},\n",
    "    download_patterns=[\"*.pth\", \"*.json\"],\n",
    "    max_price_per_hour=10.00,\n",
    "    max_run_time_hours=2\n",
    ")\n",
    "\n",
    "print(\"üöÄ Starting training job...\")\n",
    "training_task = flow_client.run(training_config)\n",
    "print(f\"Task ID: {training_task.task_id}\")\n",
    "print(f\"Status: {training_task.status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monitor training progress\n",
    "print(\"‚è≥ Monitoring training progress...\\n\")\n",
    "\n",
    "while True:\n",
    "    task_info = flow_client.get_task(training_task.task_id)\n",
    "    \n",
    "    if task_info.status in [\"completed\", \"failed\", \"cancelled\"]:\n",
    "        print(f\"\\nTask {task_info.status}!\")\n",
    "        break\n",
    "    \n",
    "    # Get recent logs\n",
    "    logs = task_info.logs(tail=5)\n",
    "    if logs:\n",
    "        print(logs)\n",
    "    \n",
    "    print(f\"\\nStatus: {task_info.status} | Cost: ${task_info.total_cost:.3f}\")\n",
    "    time.sleep(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Distributed Multi-GPU Training\n",
    "\n",
    "Scale up training with PyTorch Distributed Data Parallel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distributed training script\n",
    "distributed_script = \"\"\"\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.distributed as dist\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "\n",
    "def setup_distributed():\n",
    "    \"\"\"Initialize distributed training.\"\"\"\n",
    "    rank = int(os.environ.get('RANK', 0))\n",
    "    world_size = int(os.environ.get('WORLD_SIZE', 1))\n",
    "    \n",
    "    if world_size > 1:\n",
    "        dist.init_process_group(backend='nccl')\n",
    "        torch.cuda.set_device(rank)\n",
    "    \n",
    "    return rank, world_size\n",
    "\n",
    "def train_distributed():\n",
    "    rank, world_size = setup_distributed()\n",
    "    device = f'cuda:{rank}' if torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "    # Only print from rank 0\n",
    "    if rank == 0:\n",
    "        print(f\"Training on {world_size} GPUs\")\n",
    "        print(f\"Device: {torch.cuda.get_device_name(rank)}\")\n",
    "    \n",
    "    # Data preparation\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    # Use ImageNet subset or CIFAR-100 for demo\n",
    "    train_dataset = datasets.CIFAR100(\n",
    "        root='./data', \n",
    "        train=True, \n",
    "        download=True, \n",
    "        transform=transform\n",
    "    )\n",
    "    \n",
    "    # Distributed sampler\n",
    "    train_sampler = DistributedSampler(\n",
    "        train_dataset,\n",
    "        num_replicas=world_size,\n",
    "        rank=rank\n",
    "    ) if world_size > 1 else None\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=64,  # Per GPU batch size\n",
    "        shuffle=(train_sampler is None),\n",
    "        sampler=train_sampler,\n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    # Model setup\n",
    "    model = models.resnet50(pretrained=False, num_classes=100)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    if world_size > 1:\n",
    "        model = DDP(model, device_ids=[rank])\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(\n",
    "        model.parameters(), \n",
    "        lr=0.1 * world_size,  # Scale learning rate\n",
    "        momentum=0.9\n",
    "    )\n",
    "    \n",
    "    # Training loop\n",
    "    epochs = 5\n",
    "    for epoch in range(epochs):\n",
    "        if train_sampler:\n",
    "            train_sampler.set_epoch(epoch)\n",
    "        \n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        start_time = time.time()\n",
    "        \n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            if rank == 0 and batch_idx % 20 == 0:\n",
    "                print(f'Epoch {epoch} [{batch_idx * len(data) * world_size}'\n",
    "                      f'/{len(train_loader.dataset)}] Loss: {loss.item():.4f}')\n",
    "        \n",
    "        epoch_time = time.time() - start_time\n",
    "        \n",
    "        if rank == 0:\n",
    "            avg_loss = total_loss / len(train_loader)\n",
    "            throughput = len(train_loader.dataset) / epoch_time\n",
    "            print(f'\\nEpoch {epoch}: Avg Loss: {avg_loss:.4f}, '\n",
    "                  f'Time: {epoch_time:.1f}s, Throughput: {throughput:.1f} img/s\\n')\n",
    "    \n",
    "    # Save model (only from rank 0)\n",
    "    if rank == 0:\n",
    "        if world_size > 1:\n",
    "            torch.save(model.module.state_dict(), 'resnet50_distributed.pth')\n",
    "        else:\n",
    "            torch.save(model.state_dict(), 'resnet50_distributed.pth')\n",
    "        print(\"Model saved!\")\n",
    "    \n",
    "    # Cleanup\n",
    "    if world_size > 1:\n",
    "        dist.destroy_process_group()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_distributed()\n",
    "\"\"\"\n",
    "\n",
    "# Save script\n",
    "with open(\"/tmp/train_distributed.py\", \"w\") as f:\n",
    "    f.write(distributed_script)\n",
    "\n",
    "print(\"‚úì Distributed training script created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run distributed training on 4 GPUs\n",
    "distributed_config = TaskConfig(\n",
    "    name=\"distributed-resnet-training\",\n",
    "    command=\"\"\"\n",
    "    pip install torch torchvision\n",
    "    \n",
    "    # Run with torchrun for distributed training\n",
    "    torchrun \\\n",
    "        --nproc_per_node=4 \\\n",
    "        --master_port=29500 \\\n",
    "        /workspace/train_distributed.py\n",
    "    \"\"\",\n",
    "    instance_type=\"4xa100\",  # 4x A100 80GB\n",
    "    upload_files={\"/tmp/train_distributed.py\": \"train_distributed.py\"},\n",
    "    download_patterns=[\"*.pth\"],\n",
    "    max_price_per_hour=40.00,\n",
    "    max_run_time_hours=2\n",
    ")\n",
    "\n",
    "print(\"üöÄ Starting distributed training on 4x A100...\")\n",
    "dist_task = flow_client.run(distributed_config)\n",
    "print(f\"Task ID: {dist_task.task_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training with Checkpoints\n",
    "\n",
    "Implement automatic checkpointing for long-running training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpointing training script\n",
    "checkpoint_script = \"\"\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertForSequenceClassification, BertTokenizer, AdamW\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "class CheckpointManager:\n",
    "    def __init__(self, checkpoint_dir=\"checkpoints\"):\n",
    "        self.checkpoint_dir = checkpoint_dir\n",
    "        os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "        \n",
    "    def save_checkpoint(self, epoch, model, optimizer, metrics, is_best=False):\n",
    "        checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'metrics': metrics,\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        }\n",
    "        \n",
    "        # Save latest checkpoint\n",
    "        path = os.path.join(self.checkpoint_dir, 'checkpoint_latest.pth')\n",
    "        torch.save(checkpoint, path)\n",
    "        \n",
    "        # Save epoch checkpoint\n",
    "        epoch_path = os.path.join(self.checkpoint_dir, f'checkpoint_epoch_{epoch}.pth')\n",
    "        torch.save(checkpoint, epoch_path)\n",
    "        \n",
    "        # Save best model\n",
    "        if is_best:\n",
    "            best_path = os.path.join(self.checkpoint_dir, 'checkpoint_best.pth')\n",
    "            torch.save(checkpoint, best_path)\n",
    "            \n",
    "        print(f\"Checkpoint saved: epoch {epoch}\")\n",
    "    \n",
    "    def load_checkpoint(self, model, optimizer, checkpoint_name='checkpoint_latest.pth'):\n",
    "        path = os.path.join(self.checkpoint_dir, checkpoint_name)\n",
    "        if os.path.exists(path):\n",
    "            checkpoint = torch.load(path)\n",
    "            model.load_state_dict(checkpoint['model_state_dict'])\n",
    "            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "            print(f\"Resumed from epoch {checkpoint['epoch']}\")\n",
    "            return checkpoint['epoch'], checkpoint['metrics']\n",
    "        return 0, {}\n",
    "\n",
    "# Dummy dataset for demo\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, size=10000):\n",
    "        self.size = size\n",
    "        self.texts = [f\"Sample text {i}\" for i in range(size)]\n",
    "        self.labels = [i % 2 for i in range(size)]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.texts[idx], self.labels[idx]\n",
    "\n",
    "# Training with checkpoints\n",
    "def train_with_checkpoints():\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    print(f\"Training on: {device}\")\n",
    "    \n",
    "    # Model setup\n",
    "    model = BertForSequenceClassification.from_pretrained(\n",
    "        'bert-base-uncased',\n",
    "        num_labels=2\n",
    "    ).to(device)\n",
    "    \n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "    \n",
    "    # Checkpoint manager\n",
    "    ckpt_manager = CheckpointManager()\n",
    "    \n",
    "    # Try to resume from checkpoint\n",
    "    start_epoch, metrics = ckpt_manager.load_checkpoint(model, optimizer)\n",
    "    best_accuracy = metrics.get('best_accuracy', 0.0)\n",
    "    \n",
    "    # Data loading\n",
    "    dataset = TextDataset()\n",
    "    dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "    \n",
    "    # Training loop\n",
    "    epochs = 10\n",
    "    for epoch in range(start_epoch, epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        \n",
    "        for batch_idx, (texts, labels) in enumerate(dataloader):\n",
    "            # Tokenize\n",
    "            inputs = tokenizer(\n",
    "                texts, \n",
    "                return_tensors='pt', \n",
    "                padding=True, \n",
    "                truncation=True,\n",
    "                max_length=128\n",
    "            ).to(device)\n",
    "            \n",
    "            labels = torch.tensor(labels).to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(**inputs, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            \n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            predictions = outputs.logits.argmax(dim=-1)\n",
    "            correct += (predictions == labels).sum().item()\n",
    "            \n",
    "            # Save checkpoint every 100 batches\n",
    "            if batch_idx % 100 == 0:\n",
    "                ckpt_manager.save_checkpoint(\n",
    "                    epoch, model, optimizer,\n",
    "                    {'batch': batch_idx, 'loss': total_loss / (batch_idx + 1)}\n",
    "                )\n",
    "        \n",
    "        # Calculate epoch metrics\n",
    "        accuracy = correct / len(dataset)\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        \n",
    "        print(f\"\\nEpoch {epoch}: Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "        \n",
    "        # Save checkpoint\n",
    "        metrics = {\n",
    "            'loss': avg_loss,\n",
    "            'accuracy': accuracy,\n",
    "            'best_accuracy': max(best_accuracy, accuracy)\n",
    "        }\n",
    "        \n",
    "        is_best = accuracy > best_accuracy\n",
    "        if is_best:\n",
    "            best_accuracy = accuracy\n",
    "        \n",
    "        ckpt_manager.save_checkpoint(epoch, model, optimizer, metrics, is_best)\n",
    "    \n",
    "    print(f\"\\nTraining complete! Best accuracy: {best_accuracy:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_with_checkpoints()\n",
    "\"\"\"\n",
    "\n",
    "# Save script\n",
    "with open(\"/tmp/train_with_checkpoints.py\", \"w\") as f:\n",
    "    f.write(checkpoint_script)\n",
    "\n",
    "print(\"‚úì Checkpoint training script created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run training with checkpoints and persistent storage\n",
    "checkpoint_config = TaskConfig(\n",
    "    name=\"bert-checkpoint-training\",\n",
    "    command=\"\"\"\n",
    "    pip install torch transformers\n",
    "    python /workspace/train_with_checkpoints.py\n",
    "    \"\"\",\n",
    "    instance_type=\"a100\",\n",
    "    upload_files={\"/tmp/train_with_checkpoints.py\": \"train_with_checkpoints.py\"},\n",
    "    download_patterns=[\"checkpoints/*\"],\n",
    "    \n",
    "    # Enable automatic retries on spot instance preemption\n",
    "    retry_on_failure=True,\n",
    "    max_retries=3,\n",
    "    \n",
    "    # Cost optimization\n",
    "    max_price_per_hour=10.00,\n",
    "    max_run_time_hours=4,\n",
    "    \n",
    "    # Persistent volume for checkpoints\n",
    "    volumes=[\n",
    "        {\n",
    "            \"name\": \"training-checkpoints\",\n",
    "            \"mount_path\": \"/workspace/checkpoints\",\n",
    "            \"size_gb\": 50\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"üöÄ Starting checkpoint-enabled training...\")\n",
    "ckpt_task = flow_client.run(checkpoint_config)\n",
    "print(f\"Task ID: {ckpt_task.task_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training Pipeline with Monitoring\n",
    "\n",
    "Complete training pipeline with TensorBoard monitoring:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training pipeline with monitoring\n",
    "pipeline_config = TaskConfig(\n",
    "    name=\"training-pipeline-monitored\",\n",
    "    command=\"\"\"\n",
    "    # Install dependencies\n",
    "    pip install torch torchvision tensorboard matplotlib\n",
    "    \n",
    "    # Start TensorBoard in background\n",
    "    tensorboard --logdir=/workspace/logs --host=0.0.0.0 --port=6006 &\n",
    "    \n",
    "    # Create training script with TensorBoard logging\n",
    "    python - << 'EOF'\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Setup\n",
    "writer = SummaryWriter('/workspace/logs')\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Log system info\n",
    "if device == 'cuda':\n",
    "    writer.add_text('System/GPU', torch.cuda.get_device_name(0))\n",
    "    writer.add_text('System/CUDA', torch.version.cuda)\n",
    "\n",
    "# Data\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "trainset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "testset = datasets.MNIST('./data', train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Model\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = nn.functional.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        return nn.functional.log_softmax(x, dim=1)\n",
    "\n",
    "model = SimpleNet().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Log model graph\n",
    "dummy_input = torch.randn(1, 1, 28, 28).to(device)\n",
    "writer.add_graph(model, dummy_input)\n",
    "\n",
    "# Training loop with monitoring\n",
    "global_step = 0\n",
    "epochs = 5\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(trainloader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = nn.functional.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # Log to TensorBoard\n",
    "        if batch_idx % 10 == 0:\n",
    "            writer.add_scalar('Loss/train', loss.item(), global_step)\n",
    "            \n",
    "            # Log gradients\n",
    "            for name, param in model.named_parameters():\n",
    "                if param.grad is not None:\n",
    "                    writer.add_histogram(f'Gradients/{name}', param.grad, global_step)\n",
    "        \n",
    "        global_step += 1\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f'Epoch {epoch} [{batch_idx * len(data)}/{len(trainloader.dataset)}] '\n",
    "                  f'Loss: {loss.item():.6f}')\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in testloader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += nn.functional.nll_loss(output, target, reduction='sum').item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    \n",
    "    test_loss /= len(testloader.dataset)\n",
    "    accuracy = 100. * correct / len(testloader.dataset)\n",
    "    \n",
    "    # Log validation metrics\n",
    "    writer.add_scalar('Loss/test', test_loss, epoch)\n",
    "    writer.add_scalar('Accuracy/test', accuracy, epoch)\n",
    "    \n",
    "    print(f'\\nTest set: Avg loss: {test_loss:.4f}, '\n",
    "          f'Accuracy: {correct}/{len(testloader.dataset)} ({accuracy:.2f}%)\\n')\n",
    "\n",
    "# Save model\n",
    "torch.save(model.state_dict(), 'mnist_model.pth')\n",
    "writer.close()\n",
    "\n",
    "print(\"Training complete! TensorBoard logs saved to /workspace/logs\")\n",
    "EOF\n",
    "    \n",
    "    # Keep TensorBoard running\n",
    "    sleep infinity\n",
    "    \"\"\",\n",
    "    instance_type=\"a100\",\n",
    "    ports=[6006],  # TensorBoard port\n",
    "    download_patterns=[\"*.pth\", \"logs/*\"],\n",
    "    max_price_per_hour=10.00,\n",
    "    max_run_time_hours=2\n",
    ")\n",
    "\n",
    "print(\"üöÄ Starting training pipeline with monitoring...\")\n",
    "pipeline_task = flow_client.run(pipeline_config)\n",
    "print(f\"Task ID: {pipeline_task.task_id}\")\n",
    "print(\"\\nüìä TensorBoard will be available at port 6006 once training starts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Cost Analysis and Optimization\n",
    "\n",
    "Analyze training costs and optimize resource usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all training tasks from the last 24 hours\n",
    "import datetime\n",
    "\n",
    "training_tasks = flow_client.list_tasks(\n",
    "    created_after=datetime.datetime.now() - datetime.timedelta(days=1)\n",
    ")\n",
    "\n",
    "# Filter for training tasks\n",
    "training_tasks = [t for t in training_tasks if 'train' in t.name.lower()]\n",
    "\n",
    "# Analyze costs\n",
    "print(\"üí∞ Training Cost Analysis\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'Task Name':<30} {'Duration':<12} {'Cost':<10} {'Instance':<15}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "total_cost = 0\n",
    "total_gpu_hours = 0\n",
    "\n",
    "for task in training_tasks:\n",
    "    duration = getattr(task, 'duration_hours', 0)\n",
    "    cost = getattr(task, 'total_cost', 0)\n",
    "    total_cost += cost\n",
    "    \n",
    "    # Calculate GPU hours\n",
    "    gpu_count = 1\n",
    "    if '2xa100' in task.instance_type:\n",
    "        gpu_count = 2\n",
    "    elif '4xa100' in task.instance_type:\n",
    "        gpu_count = 4\n",
    "    elif '8xa100' in task.instance_type:\n",
    "        gpu_count = 8\n",
    "    \n",
    "    total_gpu_hours += duration * gpu_count\n",
    "    \n",
    "    print(f\"{task.name[:30]:<30} {duration:>6.2f} hrs  ${cost:>8.2f}  {task.instance_type:<15}\")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'Total:':<30} {'':<12} ${total_cost:>8.2f}\")\n",
    "print(f\"\\nTotal GPU-hours: {total_gpu_hours:.1f}\")\n",
    "print(f\"Average cost per GPU-hour: ${total_cost/total_gpu_hours:.2f}\" if total_gpu_hours > 0 else \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training cost optimization recommendations\n",
    "optimization_tips = \"\"\"\n",
    "üéØ Training Cost Optimization Tips:\n",
    "\n",
    "1. **Use Mixed Precision Training**\n",
    "   - 2x faster training with minimal accuracy loss\n",
    "   - Add: `--fp16` or use torch.cuda.amp\n",
    "\n",
    "2. **Gradient Checkpointing**\n",
    "   - Trade compute for memory\n",
    "   - Allows larger batch sizes on same GPU\n",
    "\n",
    "3. **Right-size Your Instance**\n",
    "   - Monitor GPU utilization\n",
    "   - Scale down if under 80% utilized\n",
    "\n",
    "4. **Use Spot Instances**\n",
    "   - Up to 70% cost savings\n",
    "   - Implement checkpointing for resilience\n",
    "\n",
    "5. **Optimize Data Loading**\n",
    "   - Use multiple workers: num_workers=4\n",
    "   - Pin memory: pin_memory=True\n",
    "   - Prefetch data to GPU\n",
    "\"\"\"\n",
    "\n",
    "print(optimization_tips)\n",
    "\n",
    "# Example optimized configuration\n",
    "optimized_config = TaskConfig(\n",
    "    name=\"optimized-training\",\n",
    "    command=\"\"\"\n",
    "    python train.py \\\n",
    "        --fp16 \\\n",
    "        --gradient_checkpointing \\\n",
    "        --batch_size 128 \\\n",
    "        --num_workers 4 \\\n",
    "        --pin_memory\n",
    "    \"\"\",\n",
    "    instance_type=\"a100\",\n",
    "    max_price_per_hour=8.00,  # Lower bid for spot\n",
    "    retry_on_failure=True     # Handle preemptions\n",
    ")\n",
    "\n",
    "print(\"\\nüìã Example optimized configuration created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Advanced Training Patterns\n",
    "\n",
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter sweep\n",
    "learning_rates = [1e-4, 5e-4, 1e-3]\n",
    "batch_sizes = [32, 64, 128]\n",
    "\n",
    "sweep_tasks = []\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for bs in batch_sizes:\n",
    "        config = TaskConfig(\n",
    "            name=f\"sweep-lr{lr}-bs{bs}\",\n",
    "            command=f\"\"\"\n",
    "            python train.py \\\n",
    "                --learning_rate {lr} \\\n",
    "                --batch_size {bs} \\\n",
    "                --epochs 5\n",
    "            \"\"\",\n",
    "            instance_type=\"a100\",\n",
    "            max_price_per_hour=10.00,\n",
    "            max_run_time_hours=1\n",
    "        )\n",
    "        \n",
    "        # task = flow_client.run(config)\n",
    "        # sweep_tasks.append(task)\n",
    "        print(f\"Would run: lr={lr}, batch_size={bs}\")\n",
    "\n",
    "print(f\"\\nüéØ Hyperparameter sweep: {len(learning_rates) * len(batch_sizes)} configurations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Parallel vs Model Parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison of parallelization strategies\n",
    "strategies = {\n",
    "    \"Data Parallel (DDP)\": {\n",
    "        \"description\": \"Split batch across GPUs, replicate model\",\n",
    "        \"best_for\": \"Models that fit on single GPU\",\n",
    "        \"instance\": \"4xa100\",\n",
    "        \"example\": \"ResNet, BERT-Base\"\n",
    "    },\n",
    "    \"Model Parallel\": {\n",
    "        \"description\": \"Split model layers across GPUs\",\n",
    "        \"best_for\": \"Models too large for single GPU\",\n",
    "        \"instance\": \"8xa100\",\n",
    "        \"example\": \"GPT-3, LLaMA-70B\"\n",
    "    },\n",
    "    \"Pipeline Parallel\": {\n",
    "        \"description\": \"Split model stages, micro-batching\",\n",
    "        \"best_for\": \"Very deep models\",\n",
    "        \"instance\": \"4xa100\",\n",
    "        \"example\": \"Deep ResNets, Transformers\"\n",
    "    },\n",
    "    \"3D Parallel\": {\n",
    "        \"description\": \"Combine all strategies\",\n",
    "        \"best_for\": \"Extreme scale training\",\n",
    "        \"instance\": \"8xa100\",\n",
    "        \"example\": \"LLaMA-2, GPT-4\"\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"üéØ Parallelization Strategy Guide\\n\")\n",
    "for strategy, info in strategies.items():\n",
    "    print(f\"**{strategy}**\")\n",
    "    print(f\"  Description: {info['description']}\")\n",
    "    print(f\"  Best for: {info['best_for']}\")\n",
    "    print(f\"  Recommended: {info['instance']}\")\n",
    "    print(f\"  Examples: {info['example']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Cleanup and Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of all training runs\n",
    "all_tasks = flow_client.list_tasks()\n",
    "training_tasks = [t for t in all_tasks if 'train' in t.name.lower()]\n",
    "\n",
    "print(\"üìä Training Session Summary\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Total training tasks: {len(training_tasks)}\")\n",
    "print(f\"Total cost: ${sum(getattr(t, 'total_cost', 0) for t in training_tasks):.2f}\")\n",
    "print(f\"Total GPU hours: {sum(getattr(t, 'duration_hours', 0) for t in training_tasks):.1f}\")\n",
    "\n",
    "# Cleanup running tasks\n",
    "running = [t for t in training_tasks if t.status == \"running\"]\n",
    "if running:\n",
    "    print(f\"\\n‚ö†Ô∏è  {len(running)} tasks still running\")\n",
    "    # Uncomment to stop all\n",
    "    # for task in running:\n",
    "    #     flow_client.cancel(task.task_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, you learned how to:\n",
    "\n",
    "1. **Run single GPU training** with PyTorch and TensorFlow\n",
    "2. **Scale to multi-GPU** with distributed training\n",
    "3. **Implement checkpointing** for fault tolerance\n",
    "4. **Monitor training** with TensorBoard\n",
    "5. **Analyze costs** and optimize resource usage\n",
    "6. **Use advanced patterns** like hyperparameter sweeps\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "- Start with single GPU and profile before scaling\n",
    "- Always implement checkpointing for long runs\n",
    "- Use mixed precision training for 2x speedup\n",
    "- Monitor GPU utilization to right-size instances\n",
    "- Mithril's dynamic pricing rewards flexible scheduling\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Explore [Fine-tuning Notebook](fine-tuning.ipynb) for model customization\n",
    "- Check [Inference Notebook](inference.ipynb) for deployment\n",
    "- Read [Distributed Training Guide](../../guides/distributed-training.md)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}