#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
P2 é˜¶æ®µæµ‹è¯•ï¼šä¸Šä¸‹æ–‡æ”¶é›†ä¸è®°å¿†ç®¡ç†å¢å¼ºåŠŸèƒ½
æµ‹è¯•æ™ºèƒ½ä¸Šä¸‹æ–‡æ”¶é›†ã€è®°å¿†ä¼˜å…ˆçº§ç®¡ç†ã€è¯­ä¹‰æœç´¢å’Œè‡ªåŠ¨æ‘˜è¦åŠŸèƒ½
"""

import asyncio
import sys
from pathlib import Path
from datetime import datetime, timedelta

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
sys.path.insert(0, str(Path.cwd()))

from solo_mcp.config import SoloConfig
from solo_mcp.tools.context import ContextTool, SmartContextCollector, ContextType, RelevanceLevel
from solo_mcp.tools.memory import MemoryTool, MemoryType, Priority
from solo_mcp.tools.index import IndexTool


def print_section(title: str):
    """æ‰“å°æµ‹è¯•ç« èŠ‚æ ‡é¢˜"""
    print(f"\n{'='*60}")
    print(f" {title}")
    print(f"{'='*60}")


def print_subsection(title: str):
    """æ‰“å°æµ‹è¯•å­ç« èŠ‚æ ‡é¢˜"""
    print(f"\n{'-'*40}")
    print(f" {title}")
    print(f"{'-'*40}")


async def test_smart_context_collection():
    """æµ‹è¯•æ™ºèƒ½ä¸Šä¸‹æ–‡æ”¶é›†åŠŸèƒ½"""
    print_section("P2 é˜¶æ®µæµ‹è¯•ï¼šæ™ºèƒ½ä¸Šä¸‹æ–‡æ”¶é›†")
    
    try:
        # åˆå§‹åŒ–é…ç½®å’Œå·¥å…·
        config = SoloConfig.load(Path.cwd())
        index = IndexTool(config)
        memory = MemoryTool(config)
        context = ContextTool(config, index, memory)
        
        # æµ‹è¯•åœºæ™¯1ï¼šPython ä»£ç å®ç°æŸ¥è¯¢
        print_subsection("åœºæ™¯1ï¼šPython ä»£ç å®ç°æŸ¥è¯¢")
        query1 = "implement python function for role planning algorithm"
        result1 = await context.collect_smart(query1, limit=4000)
        
        print(f"æŸ¥è¯¢: {query1}")
        print(f"æŸ¥è¯¢æ„å›¾åˆ†æ: {result1.get('query_intent', {})}")
        print(f"æ‰¾åˆ° {result1.get('items_count', 0)} ä¸ªç›¸å…³æ–‡ä»¶")
        print(f"æ€»å¤§å°: {result1.get('total_size', 0)} å­—ç¬¦")
        print(f"æ‘˜è¦:\n{result1.get('summary', '')[:500]}...")
        
        # æµ‹è¯•åœºæ™¯2ï¼šè°ƒè¯•é”™è¯¯æŸ¥è¯¢
        print_subsection("åœºæ™¯2ï¼šè°ƒè¯•é”™è¯¯æŸ¥è¯¢")
        query2 = "debug error in orchestrator tool conflict detection"
        result2 = await context.collect_smart(query2, limit=3000)
        
        print(f"æŸ¥è¯¢: {query2}")
        print(f"æŸ¥è¯¢æ„å›¾åˆ†æ: {result2.get('query_intent', {})}")
        print(f"æ‰¾åˆ° {result2.get('items_count', 0)} ä¸ªç›¸å…³æ–‡ä»¶")
        
        # æ˜¾ç¤ºç›¸å…³æ€§å¾—åˆ†æœ€é«˜çš„æ–‡ä»¶
        context_items = result2.get('context_items', [])
        if context_items:
            print("\nç›¸å…³æ€§æœ€é«˜çš„æ–‡ä»¶:")
            for i, item in enumerate(context_items[:3]):
                print(f"  {i+1}. {Path(item['path']).name} (å¾—åˆ†: {item['relevance_score']:.2f}, ç±»å‹: {item['type']})")
        
        # æµ‹è¯•åœºæ™¯3ï¼šé…ç½®æ–‡ä»¶æŸ¥è¯¢
        print_subsection("åœºæ™¯3ï¼šé…ç½®æ–‡ä»¶æŸ¥è¯¢")
        query3 = "configuration setup environment variables"
        result3 = await context.collect_smart(query3, limit=2000)
        
        print(f"æŸ¥è¯¢: {query3}")
        print(f"æŸ¥è¯¢å¤æ‚åº¦: {result3.get('query_intent', {}).get('complexity', 'unknown')}")
        print(f"æŠ€æœ¯æ ˆ: {result3.get('query_intent', {}).get('tech_stack', [])}")
        
        print("\nâœ… æ™ºèƒ½ä¸Šä¸‹æ–‡æ”¶é›†æµ‹è¯•é€šè¿‡")
        return True
        
    except Exception as e:
        print(f"âŒ æ™ºèƒ½ä¸Šä¸‹æ–‡æ”¶é›†æµ‹è¯•å¤±è´¥: {e}")
        return False


def test_smart_memory_management():
    """æµ‹è¯•æ™ºèƒ½è®°å¿†ç®¡ç†åŠŸèƒ½"""
    print_section("P2 é˜¶æ®µæµ‹è¯•ï¼šæ™ºèƒ½è®°å¿†ç®¡ç†")
    
    try:
        # åˆå§‹åŒ–é…ç½®å’Œå·¥å…·
        config = SoloConfig.load(Path.cwd())
        memory = MemoryTool(config)
        
        # æµ‹è¯•åœºæ™¯1ï¼šå­˜å‚¨ä¸åŒç±»å‹çš„è®°å¿†
        print_subsection("åœºæ™¯1ï¼šå­˜å‚¨ä¸åŒç±»å‹çš„è®°å¿†")
        
        # å­˜å‚¨ä»£ç æ¨¡å¼è®°å¿†
        code_pattern_id = memory.store_smart(
            content="def calculate_relevance(item, query_intent): score = 0.0; score += type_weight; return score",
            memory_type="code_pattern",
            tags=["algorithm", "relevance", "scoring"],
            context={"success": True, "reuse_count": 3}
        )
        print(f"å­˜å‚¨ä»£ç æ¨¡å¼è®°å¿†: {code_pattern_id}")
        
        # å­˜å‚¨è§£å†³æ–¹æ¡ˆè®°å¿†
        solution_id = memory.store_smart(
            content="To fix orchestrator conflict detection, add TaskAllocator and ConflictDetector classes with priority-based allocation",
            memory_type="solution",
            tags=["orchestrator", "conflict", "fix"],
            context={"success": True, "error_count": 2}
        )
        print(f"å­˜å‚¨è§£å†³æ–¹æ¡ˆè®°å¿†: {solution_id}")
        
        # å­˜å‚¨é”™è¯¯ä¿®å¤è®°å¿†
        error_fix_id = memory.store_smart(
            content="ImportError: No module named 'dataclasses' - Fixed by adding from dataclasses import dataclass",
            memory_type="error_fix",
            tags=["import", "dataclass", "python"],
            context={"error_count": 1, "success": True}
        )
        print(f"å­˜å‚¨é”™è¯¯ä¿®å¤è®°å¿†: {error_fix_id}")
        
        # æµ‹è¯•åœºæ™¯2ï¼šæ™ºèƒ½æœç´¢è®°å¿†
        print_subsection("åœºæ™¯2ï¼šæ™ºèƒ½æœç´¢è®°å¿†")
        
        # æœç´¢ç®—æ³•ç›¸å…³è®°å¿†
        algorithm_memories = memory.search_smart(
            query="algorithm relevance scoring",
            limit=5
        )
        print(f"\næœç´¢ 'algorithm relevance scoring' æ‰¾åˆ° {len(algorithm_memories)} æ¡è®°å¿†:")
        for mem in algorithm_memories:
            print(f"  - {mem['type']}: {mem['summary'][:100]}... (ä¼˜å…ˆçº§: {mem['priority']})")
        
        # æœç´¢é”™è¯¯ä¿®å¤è®°å¿†
        error_memories = memory.search_smart(
            query="import error fix",
            memory_types=["error_fix"],
            limit=3
        )
        print(f"\næœç´¢é”™è¯¯ä¿®å¤è®°å¿†æ‰¾åˆ° {len(error_memories)} æ¡:")
        for mem in error_memories:
            print(f"  - è®¿é—®æ¬¡æ•°: {mem['access_count']}, å…³é”®è¯: {mem['keywords'][:5]}")
        
        # æµ‹è¯•åœºæ™¯3ï¼šæŒ‰æ ‡ç­¾æœç´¢
        print_subsection("åœºæ™¯3ï¼šæŒ‰æ ‡ç­¾æœç´¢")
        
        orchestrator_memories = memory.search_smart(
            tags=["orchestrator", "conflict"],
            limit=5
        )
        print(f"\næŒ‰æ ‡ç­¾æœç´¢ 'orchestrator, conflict' æ‰¾åˆ° {len(orchestrator_memories)} æ¡è®°å¿†:")
        for mem in orchestrator_memories:
            print(f"  - {mem['id']}: {mem['tags']}")
        
        # æµ‹è¯•åœºæ™¯4ï¼šè®°å¿†ç»Ÿè®¡ä¿¡æ¯
        print_subsection("åœºæ™¯4ï¼šè®°å¿†ç»Ÿè®¡ä¿¡æ¯")
        
        stats = memory.get_stats()
        print(f"\nè®°å¿†ç»Ÿè®¡ä¿¡æ¯:")
        print(f"  æ€»è®°å¿†æ•°: {stats['total_items']}")
        print(f"  æ€»å¤§å°: {stats['total_size_bytes']} å­—èŠ‚")
        print(f"  å¹³å‡è®¿é—®æ¬¡æ•°: {stats['avg_access_per_item']:.2f}")
        print(f"  ç±»å‹åˆ†å¸ƒ: {stats['type_distribution']}")
        print(f"  ä¼˜å…ˆçº§åˆ†å¸ƒ: {stats['priority_distribution']}")
        
        # æµ‹è¯•åœºæ™¯5ï¼šè®°å¿†æ¸…ç†
        print_subsection("åœºæ™¯5ï¼šè®°å¿†æ¸…ç†æµ‹è¯•")
        
        # æ¸…ç†90å¤©å‰çš„è®°å¿†ï¼ˆæµ‹è¯•ç”¨ï¼Œå®é™…ä¸ä¼šæœ‰è¿™ä¹ˆæ—§çš„è®°å¿†ï¼‰
        cleaned_count = memory.cleanup(days_threshold=90)
        print(f"æ¸…ç†äº† {cleaned_count} æ¡æ—§è®°å¿†")
        
        print("\nâœ… æ™ºèƒ½è®°å¿†ç®¡ç†æµ‹è¯•é€šè¿‡")
        return True
        
    except Exception as e:
        print(f"âŒ æ™ºèƒ½è®°å¿†ç®¡ç†æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


async def test_context_memory_integration():
    """æµ‹è¯•ä¸Šä¸‹æ–‡æ”¶é›†ä¸è®°å¿†ç®¡ç†é›†æˆ"""
    print_section("P2 é˜¶æ®µæµ‹è¯•ï¼šä¸Šä¸‹æ–‡ä¸è®°å¿†é›†æˆ")
    
    try:
        # åˆå§‹åŒ–é…ç½®å’Œå·¥å…·
        config = SoloConfig.load(Path.cwd())
        index = IndexTool(config)
        memory = MemoryTool(config)
        context = ContextTool(config, index, memory)
        
        # æµ‹è¯•åœºæ™¯1ï¼šåŸºäºè®°å¿†çš„ä¸Šä¸‹æ–‡å¢å¼º
        print_subsection("åœºæ™¯1ï¼šåŸºäºè®°å¿†çš„ä¸Šä¸‹æ–‡å¢å¼º")
        
        # å…ˆå­˜å‚¨ä¸€äº›ç›¸å…³è®°å¿†
        memory.store_smart(
            content="Context collection should prioritize recent files and high-relevance content based on query intent analysis",
            memory_type="learning",
            tags=["context", "collection", "strategy"],
            context={"success": True}
        )
        
        # ç„¶åè¿›è¡Œä¸Šä¸‹æ–‡æ”¶é›†
        query = "improve context collection strategy"
        context_result = await context.collect_smart(query, limit=3000)
        
        # æœç´¢ç›¸å…³è®°å¿†
        related_memories = memory.search_smart(
            query="context collection strategy",
            limit=3
        )
        
        print(f"æŸ¥è¯¢: {query}")
        print(f"ä¸Šä¸‹æ–‡é¡¹ç›®æ•°: {context_result.get('items_count', 0)}")
        print(f"ç›¸å…³è®°å¿†æ•°: {len(related_memories)}")
        
        if related_memories:
            print("\nç›¸å…³è®°å¿†:")
            for mem in related_memories:
                print(f"  - {mem['type']}: {mem['summary'][:80]}...")
        
        # æµ‹è¯•åœºæ™¯2ï¼šä¼ ç»Ÿæ¥å£å…¼å®¹æ€§
        print_subsection("åœºæ™¯2ï¼šä¼ ç»Ÿæ¥å£å…¼å®¹æ€§æµ‹è¯•")
        
        # æµ‹è¯•ä¼ ç»Ÿ collect æ–¹æ³•
        traditional_result = await context.collect("python function implementation", limit=2000)
        
        print(f"ä¼ ç»Ÿæ¥å£ç»“æœ:")
        print(f"  æˆåŠŸ: {traditional_result.get('ok', False)}")
        print(f"  ä»¤ç‰Œæ•°: {traditional_result.get('tokens', 0)}")
        print(f"  æ™ºèƒ½åˆ†æ: {'smart_analysis' in traditional_result}")
        print(f"  é¡¹ç›®æ•°: {traditional_result.get('items_count', 0)}")
        
        # æµ‹è¯•ä¼ ç»Ÿè®°å¿†æ¥å£
        memory.store("test_key", {"data": "test_value", "timestamp": datetime.now().isoformat()})
        loaded_data = memory.load("test_key")
        print(f"\nä¼ ç»Ÿè®°å¿†æ¥å£æµ‹è¯•: {loaded_data is not None}")
        
        print("\nâœ… ä¸Šä¸‹æ–‡ä¸è®°å¿†é›†æˆæµ‹è¯•é€šè¿‡")
        return True
        
    except Exception as e:
        print(f"âŒ ä¸Šä¸‹æ–‡ä¸è®°å¿†é›†æˆæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ å¼€å§‹ P2 é˜¶æ®µæµ‹è¯•ï¼šä¸Šä¸‹æ–‡æ”¶é›†ä¸è®°å¿†ç®¡ç†å¢å¼º")
    print(f"æµ‹è¯•æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # è¿è¡Œæ‰€æœ‰æµ‹è¯•
    tests = [
        ("æ™ºèƒ½ä¸Šä¸‹æ–‡æ”¶é›†", test_smart_context_collection()),
        ("æ™ºèƒ½è®°å¿†ç®¡ç†", test_smart_memory_management()),
        ("ä¸Šä¸‹æ–‡ä¸è®°å¿†é›†æˆ", test_context_memory_integration())
    ]
    
    results = []
    for test_name, test_coro in tests:
        print(f"\nğŸ§ª è¿è¡Œæµ‹è¯•: {test_name}")
        try:
            if asyncio.iscoroutine(test_coro):
                result = await test_coro
            else:
                result = test_coro
            results.append((test_name, result))
        except Exception as e:
            print(f"âŒ æµ‹è¯• {test_name} å¼‚å¸¸: {e}")
            results.append((test_name, False))
    
    # æ±‡æ€»ç»“æœ
    print_section("P2 é˜¶æ®µæµ‹è¯•ç»“æœæ±‡æ€»")
    
    passed = 0
    total = len(results)
    
    for test_name, result in results:
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"{test_name}: {status}")
        if result:
            passed += 1
    
    print(f"\næ€»ä½“ç»“æœ: {passed}/{total} æµ‹è¯•é€šè¿‡")
    
    if passed == total:
        print("\nğŸ‰ P2 é˜¶æ®µæ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
        print("\nğŸ“‹ P2 é˜¶æ®µåŠŸèƒ½éªŒè¯å®Œæˆ:")
        print("  âœ… æ™ºèƒ½ä¸Šä¸‹æ–‡æ”¶é›† - æŸ¥è¯¢æ„å›¾åˆ†æã€æ–‡ä»¶ç±»å‹åˆ†ç±»ã€ç›¸å…³æ€§è®¡ç®—")
        print("  âœ… æ™ºèƒ½è®°å¿†ç®¡ç† - ä¼˜å…ˆçº§ç®¡ç†ã€è¯­ä¹‰æœç´¢ã€è‡ªåŠ¨æ‘˜è¦")
        print("  âœ… ä¸Šä¸‹æ–‡ä¸è®°å¿†é›†æˆ - å¢å¼ºçš„ä¸Šä¸‹æ–‡æ”¶é›†ã€ä¼ ç»Ÿæ¥å£å…¼å®¹")
        print("\nğŸš€ P2 é˜¶æ®µå¢å¼ºåŠŸèƒ½å·²å°±ç»ªï¼Œå¯ä»¥è¿›å…¥ä¸‹ä¸€é˜¶æ®µå¼€å‘ï¼")
    else:
        print(f"\nâš ï¸  {total - passed} ä¸ªæµ‹è¯•å¤±è´¥ï¼Œéœ€è¦ä¿®å¤åå†ç»§ç»­")
    
    return passed == total


if __name__ == "__main__":
    asyncio.run(main())