#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
P2 ä»»åŠ¡æµ‹è¯•ï¼šè¶…é•¿ä¸Šä¸‹æ–‡æŒä¹…ç¼“å­˜ä¸åŠ¨æ€è£å‰ª
æµ‹è¯• ContextCacheManager å’Œ DynamicContextTrimmer çš„åŠŸèƒ½
"""

import sys
import os
import time
from pathlib import Path
from datetime import datetime, timedelta

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

from solo_mcp.tools.memory import ContextCacheManager, CacheItem, Priority
from solo_mcp.tools.context import DynamicContextTrimmer, ContextItem, TrimmedContext

def test_context_cache_manager():
    """æµ‹è¯•ä¸Šä¸‹æ–‡ç¼“å­˜ç®¡ç†å™¨"""
    print("\n=== æµ‹è¯• ContextCacheManager ===")
    
    # åˆå§‹åŒ–ç¼“å­˜ç®¡ç†å™¨
    cache = ContextCacheManager(max_size=5, max_memory_mb=1)
    
    # æµ‹è¯•åŸºæœ¬ç¼“å­˜æ“ä½œ
    print("\n1. æµ‹è¯•åŸºæœ¬ç¼“å­˜æ“ä½œ")
    
    # æ·»åŠ ç¼“å­˜é¡¹
    test_data = [
        ("key1", "è¿™æ˜¯ç¬¬ä¸€ä¸ªæµ‹è¯•æ•°æ®", Priority.HIGH),
        ("key2", "è¿™æ˜¯ç¬¬äºŒä¸ªæµ‹è¯•æ•°æ®", Priority.MEDIUM),
        ("key3", "è¿™æ˜¯ç¬¬ä¸‰ä¸ªæµ‹è¯•æ•°æ®", Priority.LOW),
        ("key4", "è¿™æ˜¯ç¬¬å››ä¸ªæµ‹è¯•æ•°æ®", Priority.HIGH),
        ("key5", "è¿™æ˜¯ç¬¬äº”ä¸ªæµ‹è¯•æ•°æ®", Priority.MEDIUM)
    ]
    
    for key, data, priority in test_data:
        cache.put(key, data, priority, ttl_hours=1)
        print(f"  æ·»åŠ ç¼“å­˜: {key} (ä¼˜å…ˆçº§: {priority.name})")
    
    # æµ‹è¯•ç¼“å­˜è·å–
    print("\n2. æµ‹è¯•ç¼“å­˜è·å–")
    for key, _, _ in test_data:
        result = cache.get(key)
        print(f"  è·å– {key}: {'æˆåŠŸ' if result else 'å¤±è´¥'}")
    
    # æµ‹è¯• LRU é©±é€
    print("\n3. æµ‹è¯• LRU é©±é€æœºåˆ¶")
    cache.put("key6", "è¿™ä¼šè§¦å‘ LRU é©±é€", Priority.MEDIUM, ttl_hours=1)
    print("  æ·»åŠ  key6ï¼Œåº”è¯¥é©±é€æœ€å°‘ä½¿ç”¨çš„é¡¹")
    
    # æ£€æŸ¥ç¼“å­˜çŠ¶æ€
    stats = cache.get_stats()
    print(f"\n4. ç¼“å­˜ç»Ÿè®¡:")
    print(f"  å½“å‰å¤§å°: {stats['size']}/{stats['max_size']}")
    print(f"  å‘½ä¸­ç‡: {stats['hit_rate']:.2%}")
    print(f"  å†…å­˜ä½¿ç”¨: {stats['memory_usage_mb']:.2f}MB")
    
    # æµ‹è¯•è¿‡æœŸæ¸…ç†
    print("\n5. æµ‹è¯•è¿‡æœŸæ¸…ç†")
    cache.put("temp_key", "ä¸´æ—¶æ•°æ®", Priority.LOW, ttl_hours=0.001)  # å¾ˆçŸ­çš„ TTL
    time.sleep(0.1)  # ç­‰å¾…è¿‡æœŸ
    cache.cleanup_expired()
    temp_result = cache.get("temp_key")
    print(f"  è¿‡æœŸé¡¹æ¸…ç†: {'æˆåŠŸ' if temp_result is None else 'å¤±è´¥'}")
    
    return True

def test_dynamic_context_trimmer():
    """æµ‹è¯•åŠ¨æ€ä¸Šä¸‹æ–‡è£å‰ªå™¨"""
    print("\n=== æµ‹è¯• DynamicContextTrimmer ===")
    
    # åˆå§‹åŒ–è£å‰ªå™¨
    trimmer = DynamicContextTrimmer(max_context_size=500, target_trim_ratio=0.6)
    
    # åˆ›å»ºæµ‹è¯•ä¸Šä¸‹æ–‡é¡¹
    print("\n1. åˆ›å»ºæµ‹è¯•ä¸Šä¸‹æ–‡é¡¹")
    
    test_contexts = [
        ContextItem(
            file_path="test1.py",
            content="def important_function():\n    # è¿™æ˜¯ä¸€ä¸ªé‡è¦çš„å‡½æ•°\n    return 'critical_data'\n" * 10,
            relevance_score=0.9,
            context_type="function",
            timestamp=datetime.now()
        ),
        ContextItem(
            file_path="test2.py",
            content="# è¿™æ˜¯ä¸€äº›æ™®é€šçš„ä»£ç æ³¨é‡Š\nprint('hello world')\n" * 15,
            relevance_score=0.5,
            context_type="content",
            timestamp=datetime.now() - timedelta(hours=2)
        ),
        ContextItem(
            file_path="test3.py",
            content="class TestClass:\n    def __init__(self):\n        self.data = []\n" * 8,
            relevance_score=0.8,
            context_type="class",
            timestamp=datetime.now() - timedelta(minutes=30)
        ),
        ContextItem(
            file_path="test4.py",
            content="# ä½é‡è¦æ€§çš„æ–‡ä»¶å†…å®¹\ntemp_var = 123\n" * 20,
            relevance_score=0.2,
            context_type="content",
            timestamp=datetime.now() - timedelta(hours=5)
        )
    ]
    
    total_size = sum(len(item.content) for item in test_contexts)
    print(f"  åˆ›å»ºäº† {len(test_contexts)} ä¸ªä¸Šä¸‹æ–‡é¡¹ï¼Œæ€»å¤§å°: {total_size} å­—ç¬¦")
    
    # æµ‹è¯•ä¸åŒçš„è£å‰ªç­–ç•¥
    print("\n2. æµ‹è¯•è£å‰ªåŠŸèƒ½")
    
    # æµ‹è¯•è‡ªåŠ¨è£å‰ª
    trimmed = trimmer.trim_context(test_contexts)
    
    print(f"  åŸå§‹é¡¹ç›®æ•°: {len(trimmed.original_items)}")
    print(f"  è£å‰ªåé¡¹ç›®æ•°: {len(trimmed.trimmed_items)}")
    print(f"  è£å‰ªæ¯”ä¾‹: {trimmed.trim_ratio:.2%}")
    print(f"  ä½¿ç”¨ç­–ç•¥: {trimmed.trim_strategy}")
    print(f"  åŸå§‹å¤§å°: {trimmed.metadata.get('original_size', 0)} å­—ç¬¦")
    print(f"  è£å‰ªåå¤§å°: {trimmed.metadata.get('trimmed_size', 0)} å­—ç¬¦")
    
    # æµ‹è¯•é‡è¦æ€§åˆ†æ•°
    print("\n3. é‡è¦æ€§åˆ†æ•°åˆ†æ")
    for file_path, score in trimmed.importance_scores.items():
        print(f"  {file_path}: {score:.3f}")
    
    # æµ‹è¯•ä¸åŒç›®æ ‡å¤§å°çš„è£å‰ª
    print("\n4. æµ‹è¯•ä¸åŒç›®æ ‡å¤§å°")
    target_sizes = [200, 300, 400]
    
    for target_size in target_sizes:
        result = trimmer.trim_context(test_contexts, target_size=target_size)
        actual_size = sum(len(item.content) for item in result.trimmed_items)
        print(f"  ç›®æ ‡å¤§å° {target_size}: å®é™…å¤§å° {actual_size}, ç­–ç•¥ {result.trim_strategy}")
    
    # æµ‹è¯•è£å‰ªç»Ÿè®¡
    print("\n5. è£å‰ªç»Ÿè®¡ä¿¡æ¯")
    stats = trimmer.get_trim_stats()
    print(f"  æ€»è£å‰ªæ¬¡æ•°: {stats['total_trims']}")
    print(f"  å¹³å‡è£å‰ªæ¯”ä¾‹: {stats['avg_trim_ratio']:.2%}")
    print(f"  å†…å®¹ä¿ç•™ç‡: {stats['content_preserved_rate']:.2%}")
    print(f"  æ•ˆç‡åˆ†æ•°: {stats['efficiency_score']:.3f}")
    print(f"  ç­–ç•¥åˆ†å¸ƒ: {stats['strategy_distribution']}")
    
    # æµ‹è¯•å‚æ•°ä¼˜åŒ–
    print("\n6. æµ‹è¯•å‚æ•°ä¼˜åŒ–")
    feedback = {"user_satisfaction": 0.6}  # æ¨¡æ‹Ÿç”¨æˆ·ä¸æ»¡æ„
    old_importance_weight = trimmer.importance_weight
    trimmer.optimize_parameters(feedback)
    print(f"  é‡è¦æ€§æƒé‡è°ƒæ•´: {old_importance_weight:.2f} -> {trimmer.importance_weight:.2f}")
    
    return True

def test_integration():
    """æµ‹è¯•ç¼“å­˜å’Œè£å‰ªçš„é›†æˆæ•ˆæœ"""
    print("\n=== æµ‹è¯•é›†æˆæ•ˆæœ ===")
    
    # æ¨¡æ‹Ÿå®é™…ä½¿ç”¨åœºæ™¯
    cache = ContextCacheManager(max_size=10, max_memory_mb=2)
    trimmer = DynamicContextTrimmer(max_context_size=300, target_trim_ratio=0.5)
    
    # åˆ›å»ºå¤§é‡ä¸Šä¸‹æ–‡æ•°æ®
    large_contexts = []
    for i in range(20):
        context = ContextItem(
            file_path=f"file_{i}.py",
            content=f"# æ–‡ä»¶ {i} çš„å†…å®¹\n" + "ä»£ç è¡Œ\n" * (10 + i),
            relevance_score=0.3 + (i % 7) * 0.1,
            context_type="content",
            timestamp=datetime.now() - timedelta(minutes=i*5)
        )
        large_contexts.append(context)
    
    print(f"\n1. å¤„ç† {len(large_contexts)} ä¸ªä¸Šä¸‹æ–‡é¡¹")
    
    # æ¨¡æ‹ŸæŸ¥è¯¢å’Œç¼“å­˜æµç¨‹
    queries = ["query1", "query2", "query3", "query1", "query2"]  # é‡å¤æŸ¥è¯¢æµ‹è¯•ç¼“å­˜
    
    for i, query in enumerate(queries):
        print(f"\n  å¤„ç†æŸ¥è¯¢ {i+1}: {query}")
        
        # æ£€æŸ¥ç¼“å­˜
        cached_result = cache.get(query)
        if cached_result:
            print(f"    ç¼“å­˜å‘½ä¸­: {len(cached_result)} é¡¹")
            continue
        
        # æ¨¡æ‹Ÿä¸Šä¸‹æ–‡æ”¶é›†ï¼ˆé€‰æ‹©éƒ¨åˆ†æ•°æ®ï¼‰
        selected_contexts = large_contexts[i*3:(i+1)*4]  # é€‰æ‹©ä¸åŒçš„ä¸Šä¸‹æ–‡å­é›†
        
        # åº”ç”¨è£å‰ª
        trimmed = trimmer.trim_context(selected_contexts, target_size=200)
        
        # ç¼“å­˜ç»“æœ
        cache.put(query, trimmed.trimmed_items, Priority.MEDIUM, ttl_hours=1)
        
        print(f"    æ–°å¤„ç†: {len(selected_contexts)} -> {len(trimmed.trimmed_items)} é¡¹")
        print(f"    è£å‰ªæ¯”ä¾‹: {trimmed.trim_ratio:.2%}")
    
    # æœ€ç»ˆç»Ÿè®¡
    print("\n2. æœ€ç»ˆç»Ÿè®¡")
    cache_stats = cache.get_stats()
    trim_stats = trimmer.get_trim_stats()
    
    print(f"  ç¼“å­˜å‘½ä¸­ç‡: {cache_stats['hit_rate']:.2%}")
    print(f"  ç¼“å­˜ä½¿ç”¨ç‡: {cache_stats['size']}/{cache_stats['max_size']}")
    print(f"  å¹³å‡è£å‰ªæ¯”ä¾‹: {trim_stats['avg_trim_ratio']:.2%}")
    print(f"  å†…å®¹ä¿ç•™ç‡: {trim_stats['content_preserved_rate']:.2%}")
    
    return True

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("å¼€å§‹ P2 ä»»åŠ¡æµ‹è¯•ï¼šè¶…é•¿ä¸Šä¸‹æ–‡æŒä¹…ç¼“å­˜ä¸åŠ¨æ€è£å‰ª")
    print("=" * 60)
    
    try:
        # è¿è¡Œæ‰€æœ‰æµ‹è¯•
        tests = [
            ("ä¸Šä¸‹æ–‡ç¼“å­˜ç®¡ç†å™¨", test_context_cache_manager),
            ("åŠ¨æ€ä¸Šä¸‹æ–‡è£å‰ªå™¨", test_dynamic_context_trimmer),
            ("é›†æˆæ•ˆæœ", test_integration)
        ]
        
        results = []
        for test_name, test_func in tests:
            print(f"\n{'='*20} {test_name} {'='*20}")
            try:
                result = test_func()
                results.append((test_name, result, None))
                print(f"âœ… {test_name} æµ‹è¯•é€šè¿‡")
            except Exception as e:
                results.append((test_name, False, str(e)))
                print(f"âŒ {test_name} æµ‹è¯•å¤±è´¥: {e}")
        
        # æ±‡æ€»ç»“æœ
        print("\n" + "="*60)
        print("æµ‹è¯•ç»“æœæ±‡æ€»:")
        
        passed = 0
        for test_name, success, error in results:
            status = "âœ… é€šè¿‡" if success else f"âŒ å¤±è´¥: {error}"
            print(f"  {test_name}: {status}")
            if success:
                passed += 1
        
        print(f"\næ€»ä½“ç»“æœ: {passed}/{len(tests)} ä¸ªæµ‹è¯•é€šè¿‡")
        
        if passed == len(tests):
            print("\nğŸ‰ P2 ä»»åŠ¡å®ç°æˆåŠŸï¼")
            print("âœ¨ è¶…é•¿ä¸Šä¸‹æ–‡æŒä¹…ç¼“å­˜ä¸åŠ¨æ€è£å‰ªåŠŸèƒ½å·²å°±ç»ª")
            return True
        else:
            print("\nâš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œéœ€è¦è¿›ä¸€æ­¥è°ƒè¯•")
            return False
            
    except Exception as e:
        print(f"\nğŸ’¥ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)