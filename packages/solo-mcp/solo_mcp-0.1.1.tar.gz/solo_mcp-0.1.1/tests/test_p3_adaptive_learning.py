#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
P3 é˜¶æ®µæµ‹è¯•è„šæœ¬ï¼šè‡ªé€‚åº”å­¦ä¹ ä¸ä¼˜åŒ–åŠŸèƒ½éªŒè¯

æµ‹è¯•å†…å®¹ï¼š
1. LearningEngine ç”¨æˆ·è¡Œä¸ºåˆ†æå’Œæ¨¡å¼è¯†åˆ«
2. AdaptiveOptimizer åŠ¨æ€å‚æ•°è°ƒæ•´å’Œæ€§èƒ½ä¼˜åŒ–
3. PerformanceMonitor å®æ—¶ç›‘æ§å’Œç“¶é¢ˆæ£€æµ‹
4. é›†æˆå·¥å…·çš„æ™ºèƒ½ä¼˜åŒ–åŠŸèƒ½
5. ç«¯åˆ°ç«¯è‡ªé€‚åº”å­¦ä¹ æµç¨‹
"""

import asyncio
import json
import time
from pathlib import Path
from datetime import datetime, timedelta

# æ·»åŠ é¡¹ç›®è·¯å¾„
import sys
sys.path.append(str(Path(__file__).parent))

from solo_mcp.config import SoloConfig
from solo_mcp.tools.learning import LearningEngine, UserActionType, LearningPattern
from solo_mcp.tools.adaptive import AdaptiveOptimizer, OptimizationType
from solo_mcp.tools.orchestrator import OrchestratorTool
from solo_mcp.tools.context import ContextTool
from solo_mcp.tools.memory import MemoryTool


def test_learning_engine():
    """æµ‹è¯•å­¦ä¹ å¼•æ“åŠŸèƒ½"""
    print("\n=== æµ‹è¯• LearningEngine åŠŸèƒ½ ===")
    
    # åˆå§‹åŒ–é…ç½®å’Œå­¦ä¹ å¼•æ“
    config = SoloConfig.load(Path.cwd())
    learning_engine = LearningEngine(config, None)
    
    print("1. æµ‹è¯•ç”¨æˆ·è¡Œä¸ºè®°å½•...")
    
    # æ¨¡æ‹Ÿç”¨æˆ·è¡Œä¸ºåºåˆ—
    behaviors = [
        (UserActionType.CONTEXT_COLLECTION, "å¦‚ä½•å®ç°å¼‚æ­¥ç¼–ç¨‹", {"language": "python"}, 0.5, True),
        (UserActionType.MEMORY_STORE, "async_patterns", {"type": "code_pattern"}, 0.2, True),
        (UserActionType.TASK_ALLOCATION, "åˆ›å»ºå¼‚æ­¥å‡½æ•°", {"role": "backend"}, 1.2, True),
        (UserActionType.CONTEXT_COLLECTION, "Python asyncio æœ€ä½³å®è·µ", {"language": "python"}, 0.8, True),
        (UserActionType.MEMORY_SEARCH, "async", {"results": 5}, 0.3, True),
        (UserActionType.ERROR_HANDLING, "è¯­æ³•é”™è¯¯", {"error_type": "SyntaxError"}, 2.0, False),
        (UserActionType.CONTEXT_COLLECTION, "å¦‚ä½•å¤„ç†å¼‚æ­¥å¼‚å¸¸", {"language": "python"}, 0.6, True),
        (UserActionType.TASK_ALLOCATION, "é”™è¯¯å¤„ç†ä¼˜åŒ–", {"role": "backend"}, 0.9, True),
    ]
    
    # è®°å½•ç”¨æˆ·è¡Œä¸º
    for action_type, query, context, response_time, success in behaviors:
        learning_engine.record_user_action(
            action_type=action_type,
            query=query,
            context=context,
            response_time=response_time,
            success=success,
            error_message=None if success else "æ¨¡æ‹Ÿé”™è¯¯"
        )
        time.sleep(0.1)  # æ¨¡æ‹Ÿæ—¶é—´é—´éš”
    
    print(f"   âœ“ è®°å½•äº† {len(behaviors)} ä¸ªç”¨æˆ·è¡Œä¸º")
    
    print("\n2. æµ‹è¯•æ¨¡å¼è¯†åˆ«...")
    
    # åˆ†æç”¨æˆ·æ¨¡å¼
    patterns = learning_engine.analyze_user_patterns()
    print(f"   âœ“ è¯†åˆ«åˆ° {len(patterns)} ä¸ªç”¨æˆ·æ¨¡å¼")
    
    for pattern in patterns[:3]:  # æ˜¾ç¤ºå‰3ä¸ªæ¨¡å¼
        print(f"     - {pattern.pattern_type.value}: {pattern.description}")
        print(f"       ç½®ä¿¡åº¦: {pattern.confidence:.2f}, é¢‘ç‡: {pattern.frequency}")
    
    print("\n3. æµ‹è¯•æ€§èƒ½æŒ‡æ ‡è®°å½•...")
    
    # è®°å½•æ€§èƒ½æŒ‡æ ‡
    for i in range(5):
        learning_engine.record_performance_metrics(
            response_time=0.5 + i * 0.1,
            memory_usage=0.3 + i * 0.05,
            cpu_usage=0.2 + i * 0.03,
            success_rate=0.95 - i * 0.02,
            error_count=i,
            throughput=10.0 - i,
            context_size=1000 + i * 100,
            memory_hits=8 - i,
            cache_efficiency=0.9 - i * 0.02
        )
    
    print("   âœ“ è®°å½•äº† 5 ç»„æ€§èƒ½æŒ‡æ ‡")
    
    print("\n4. æµ‹è¯•ä¼˜åŒ–å»ºè®®ç”Ÿæˆ...")
    
    recommendations = learning_engine.get_optimization_recommendations()
    print(f"   âœ“ ç”Ÿæˆäº† {len(recommendations)} ä¸ªä¼˜åŒ–å»ºè®®")
    
    for rec in recommendations[:2]:  # æ˜¾ç¤ºå‰2ä¸ªå»ºè®®
        print(f"     - {rec['type']}: {rec['description']}")
        print(f"       ä¼˜å…ˆçº§: {rec['priority']}, å½±å“: {rec['impact']}")
    
    # è·å–å­¦ä¹ ç»Ÿè®¡
    stats = learning_engine.get_learning_stats()
    print(f"\n5. å­¦ä¹ ç»Ÿè®¡ä¿¡æ¯:")
    print(f"   - æ€»è¡Œä¸ºæ•°: {stats['total_actions']}")
    print(f"   - æˆåŠŸç‡: {stats['success_rate']:.2%}")
    print(f"   - å¹³å‡å“åº”æ—¶é—´: {stats['avg_response_time']:.3f}s")
    print(f"   - è¯†åˆ«æ¨¡å¼æ•°: {stats['patterns_identified']}")
    
    print("\nâœ… LearningEngine æµ‹è¯•å®Œæˆ")
    return learning_engine


def test_adaptive_optimizer(learning_engine):
    """æµ‹è¯•è‡ªé€‚åº”ä¼˜åŒ–å™¨åŠŸèƒ½"""
    print("\n=== æµ‹è¯• AdaptiveOptimizer åŠŸèƒ½ ===")
    
    # åˆå§‹åŒ–è‡ªé€‚åº”ä¼˜åŒ–å™¨
    config = SoloConfig.load(Path.cwd())
    optimizer = AdaptiveOptimizer(config)
    optimizer.set_learning_engine(learning_engine)
    
    print("1. æµ‹è¯•å‚æ•°ä¼˜åŒ–...")
    
    # æµ‹è¯•å•ä¸ªå‚æ•°ä¼˜åŒ–
    test_params = [
        ("context_search_limit", "context_relevance", 0.7),
        ("memory_search_limit", "memory_usage", 0.6),
        ("response_timeout", "response_time", 1.2),
        ("max_context_size", "memory_usage", 0.8)
    ]
    
    optimized_count = 0
    for param_name, target_metric, current_perf in test_params:
        success = optimizer.optimize_parameter(param_name, target_metric, current_perf)
        if success:
            print(f"   âœ“ {param_name} ä¼˜åŒ–æˆåŠŸ")
            optimized_count += 1
        else:
            print(f"   âš  {param_name} ä¼˜åŒ–è·³è¿‡")
    
    print(f"   æ€»è®¡ä¼˜åŒ–äº† {optimized_count} ä¸ªå‚æ•°")
    
    print("\n2. æµ‹è¯•è‡ªåŠ¨ä¼˜åŒ–...")
    
    # æ¨¡æ‹Ÿæ€§èƒ½é—®é¢˜å¹¶è§¦å‘è‡ªåŠ¨ä¼˜åŒ–
    optimizer.performance_monitor.record_metrics({
        "response_time": 3.0,  # è¶…è¿‡é˜ˆå€¼
        "memory_usage": 0.9,   # è¶…è¿‡é˜ˆå€¼
        "success_rate": 0.8    # ä½äºé˜ˆå€¼
    })
    
    # è§¦å‘è‡ªåŠ¨ä¼˜åŒ–
    auto_optimized = optimizer.trigger_optimization_if_needed()
    if auto_optimized:
        print(f"   âœ“ è‡ªåŠ¨ä¼˜åŒ–å·²è§¦å‘")
    else:
        print(f"   âš  è‡ªåŠ¨ä¼˜åŒ–æœªè§¦å‘ï¼ˆå¯èƒ½éœ€è¦æ›´å¤šæ•°æ®ç‚¹ï¼‰")
    
    print("\n3. æµ‹è¯•æ€§èƒ½ç›‘æ§...")
    
    # è·å–å½“å‰æ€§èƒ½çŠ¶æ€
    current_perf = optimizer.performance_monitor.get_current_performance()
    print(f"   âœ“ å½“å‰æ€§èƒ½çŠ¶æ€:")
    print(f"     - å“åº”æ—¶é—´: {current_perf['response_time']:.3f}s")
    print(f"     - å†…å­˜ä½¿ç”¨: {current_perf['memory_usage']:.1%}")
    print(f"     - æˆåŠŸç‡: {current_perf['success_rate']:.1%}")
    
    # æ£€æµ‹æ€§èƒ½é—®é¢˜
    issues = optimizer.performance_monitor.detect_performance_issues()
    print(f"   âœ“ æ£€æµ‹åˆ° {len(issues)} ä¸ªæ€§èƒ½é—®é¢˜")
    
    for issue in issues[:2]:  # æ˜¾ç¤ºå‰2ä¸ªé—®é¢˜
        print(f"     - {issue['type']}: {issue['description']}")
        print(f"       ä¸¥é‡ç¨‹åº¦: {issue['severity']}")
    
    print("\n4. æµ‹è¯•æ‰‹åŠ¨ä¼˜åŒ–...")
    
    # æµ‹è¯•æ‰‹åŠ¨ä¼˜åŒ–å‚æ•°
    manual_params = [
        ("context_search_limit", 15.0),
        ("memory_search_limit", 8.0),
        ("response_timeout", 45.0)
    ]
    
    manual_count = 0
    for param_name, target_value in manual_params:
        success = optimizer.manual_optimize(param_name, target_value)
        if success:
            print(f"   âœ“ æ‰‹åŠ¨ä¼˜åŒ– {param_name} = {target_value}")
            manual_count += 1
        else:
            print(f"   âš  æ‰‹åŠ¨ä¼˜åŒ– {param_name} å¤±è´¥")
    
    print(f"   æ€»è®¡æ‰‹åŠ¨ä¼˜åŒ–äº† {manual_count} ä¸ªå‚æ•°")
    
    # è·å–ä¼˜åŒ–çŠ¶æ€
    opt_status = optimizer.get_optimization_status()
    print(f"\n5. ä¼˜åŒ–çŠ¶æ€ä¿¡æ¯:")
    print(f"   - æ€»ä¼˜åŒ–æ¬¡æ•°: {opt_status['total_optimizations']}")
    print(f"   - æœ€è¿‘ä¼˜åŒ–æ¬¡æ•°: {opt_status['recent_optimizations']}")
    print(f"   - å½“å‰ç­–ç•¥: {opt_status['current_strategy']}")
    print(f"   - ä¼˜åŒ–å¯ç”¨: {opt_status['optimization_enabled']}")
    print(f"   - å½“å‰å‚æ•°æ•°: {len(opt_status['current_parameters'])}")
    print(f"   - æ£€æµ‹åˆ°é—®é¢˜æ•°: {len(opt_status['performance_issues'])}")
    
    print("\nâœ… AdaptiveOptimizer æµ‹è¯•å®Œæˆ")
    return optimizer


async def test_integrated_tools(learning_engine, optimizer):
    """æµ‹è¯•é›†æˆå·¥å…·çš„æ™ºèƒ½ä¼˜åŒ–åŠŸèƒ½"""
    print("\n=== æµ‹è¯•é›†æˆå·¥å…·æ™ºèƒ½ä¼˜åŒ–åŠŸèƒ½ ===")
    
    config = SoloConfig.load(Path.cwd())
    
    print("1. æµ‹è¯•æ™ºèƒ½ä»»åŠ¡åˆ†é… (OrchestratorTool)...")
    
    # åˆå§‹åŒ–ç¼–æ’å·¥å…·
    orchestrator = OrchestratorTool(config)
    
    # æ¨¡æ‹Ÿä»»åŠ¡åˆ†é…åœºæ™¯
    goal = "å¼€å‘ä¸€ä¸ªç”¨æˆ·è®¤è¯ç³»ç»Ÿï¼ŒåŒ…æ‹¬æ³¨å†Œã€ç™»å½•ã€æƒé™ç®¡ç†åŠŸèƒ½"
    history = [
        "ç”¨æˆ·æå‡ºéœ€æ±‚ï¼šéœ€è¦ä¸€ä¸ªå®‰å…¨çš„è®¤è¯ç³»ç»Ÿ",
        "åˆ†æéœ€æ±‚ï¼šåŒ…æ‹¬å‰ç«¯ç•Œé¢ã€åç«¯APIã€æ•°æ®åº“è®¾è®¡",
        "æŠ€æœ¯é€‰å‹ï¼šReact + Node.js + PostgreSQL"
    ]
    
    result = await orchestrator.run_round(goal, history)
    print(f"   âœ“ æ™ºèƒ½ä»»åŠ¡åˆ†é…å®Œæˆ")
    print(f"     åˆ†é…ä»»åŠ¡æ•°: {len(result.get('tasks', []))}")
    print(f"     æ£€æµ‹å†²çªæ•°: {len(result.get('conflicts', []))}")
    print(f"     ç”ŸæˆåŠ¨ä½œæ•°: {len(result.get('actions', []))}")
    
    # æ˜¾ç¤ºéƒ¨åˆ†ä»»åŠ¡
    tasks = result.get('tasks', [])
    for i, task in enumerate(tasks[:2]):
        print(f"     ä»»åŠ¡ {i+1}: {task.get('description', 'N/A')}")
        print(f"       åˆ†é…è§’è‰²: {task.get('assigned_role', 'N/A')}")
        print(f"       ä¼˜å…ˆçº§: {task.get('priority', 'N/A')}")
    
    print("\n2. æµ‹è¯•æ™ºèƒ½ä¸Šä¸‹æ–‡æ”¶é›† (ContextTool)...")
    
    # åˆå§‹åŒ–ä¸Šä¸‹æ–‡å·¥å…·
    context_tool = ContextTool(config)
    
    # æµ‹è¯•æ™ºèƒ½ä¸Šä¸‹æ–‡æ”¶é›†
    query = "å¦‚ä½•åœ¨ React ä¸­å®ç°ç”¨æˆ·è®¤è¯çŠ¶æ€ç®¡ç†"
    context_result = await context_tool.collect_smart(query, limit=2000)
    
    print(f"   âœ“ æ™ºèƒ½ä¸Šä¸‹æ–‡æ”¶é›†å®Œæˆ")
    print(f"     æ”¶é›†å†…å®¹é•¿åº¦: {len(context_result)}")
    print(f"     åŒ…å«æ–‡ä»¶æ•°: {context_result.count('æ–‡ä»¶:') if context_result else 0}")
    
    # æ˜¾ç¤ºéƒ¨åˆ†ä¸Šä¸‹æ–‡
    if context_result:
        preview = context_result[:200] + "..." if len(context_result) > 200 else context_result
        print(f"     å†…å®¹é¢„è§ˆ: {preview}")
    
    print("\n3. æµ‹è¯•æ™ºèƒ½è®°å¿†ç®¡ç† (MemoryTool)...")
    
    # åˆå§‹åŒ–è®°å¿†å·¥å…·
    memory_tool = MemoryTool(config)
    
    # æµ‹è¯•æ™ºèƒ½è®°å¿†å­˜å‚¨
    test_memories = [
        ("react_auth_pattern", "React è®¤è¯çŠ¶æ€ç®¡ç†æœ€ä½³å®è·µ", "code_context", "high", ["react", "auth", "state"]),
        ("jwt_implementation", "JWT ä»¤ç‰Œå®ç°å’ŒéªŒè¯æµç¨‹", "solution", "high", ["jwt", "security", "backend"]),
        ("user_session_mgmt", "ç”¨æˆ·ä¼šè¯ç®¡ç†ç­–ç•¥", "workflow", "medium", ["session", "security", "frontend"])
    ]
    
    for key, content, mem_type, priority, tags in test_memories:
        success = memory_tool.store(key, content, mem_type, priority, tags)
        if success:
            print(f"   âœ“ å­˜å‚¨è®°å¿†: {key}")
        else:
            print(f"   âš  å­˜å‚¨å¤±è´¥: {key}")
    
    # æµ‹è¯•æ™ºèƒ½è®°å¿†æœç´¢
    search_results = memory_tool.search_smart(
        query="React ç”¨æˆ·è®¤è¯",
        memory_types=["code_context", "solution"],
        priorities=["high"],
        tags=["react", "auth"],
        limit=5
    )
    
    print(f"   âœ“ æ™ºèƒ½æœç´¢å®Œæˆï¼Œæ‰¾åˆ° {len(search_results)} ä¸ªç›¸å…³è®°å¿†")
    
    for result in search_results[:2]:
        print(f"     - {result['key']}: {result['type']} ({result['priority']})")
        print(f"       ç›¸å…³æ€§: {result.get('relevance_score', 0):.2f}")
    
    print("\n4. æµ‹è¯•å·¥å…·é—´ååŒä¼˜åŒ–...")
    
    # è·å–å„å·¥å…·çš„ä¼˜åŒ–çŠ¶æ€
    orchestrator_stats = orchestrator.get_optimization_status()
    context_stats = context_tool.get_optimization_recommendations()
    memory_stats = memory_tool.get_memory_stats()
    
    print(f"   âœ“ ç¼–æ’å·¥å…·ä¼˜åŒ–çŠ¶æ€:")
    print(f"     - æ‰§è¡Œè½®æ¬¡: {orchestrator_stats.get('total_rounds', 0)}")
    print(f"     - æˆåŠŸç‡: {orchestrator_stats.get('success_rate', 0):.2%}")
    print(f"     - å¹³å‡å“åº”æ—¶é—´: {orchestrator_stats.get('avg_response_time', 0):.3f}s")
    
    print(f"   âœ“ ä¸Šä¸‹æ–‡å·¥å…·ä¼˜åŒ–å»ºè®®: {len(context_stats)}")
    
    print(f"   âœ“ è®°å¿†å·¥å…·ç»Ÿè®¡:")
    memory_op_stats = memory_stats.get('operation_stats', {})
    print(f"     - æ€»å­˜å‚¨: {memory_op_stats.get('total_stores', 0)}")
    print(f"     - æ€»åŠ è½½: {memory_op_stats.get('total_loads', 0)}")
    success_rates = memory_stats.get('success_rates', {})
    print(f"     - å­˜å‚¨æˆåŠŸç‡: {success_rates.get('store', 0):.2%}")
    print(f"     - åŠ è½½æˆåŠŸç‡: {success_rates.get('load', 0):.2%}")
    
    print("\nâœ… é›†æˆå·¥å…·æ™ºèƒ½ä¼˜åŒ–æµ‹è¯•å®Œæˆ")


async def test_end_to_end_adaptive_learning():
    """æµ‹è¯•ç«¯åˆ°ç«¯è‡ªé€‚åº”å­¦ä¹ æµç¨‹"""
    print("\n=== æµ‹è¯•ç«¯åˆ°ç«¯è‡ªé€‚åº”å­¦ä¹ æµç¨‹ ===")
    
    config = SoloConfig.load(Path.cwd())
    
    print("1. åˆå§‹åŒ–å®Œæ•´ç³»ç»Ÿ...")
    
    # åˆå§‹åŒ–æ‰€æœ‰ç»„ä»¶
    learning_engine = LearningEngine(config, None)
    optimizer = AdaptiveOptimizer(config)
    optimizer.set_learning_engine(learning_engine)
    orchestrator = OrchestratorTool(config)
    context_tool = ContextTool(config)
    memory_tool = MemoryTool(config)
    
    print("   âœ“ æ‰€æœ‰ç»„ä»¶åˆå§‹åŒ–å®Œæˆ")
    
    print("\n2. æ¨¡æ‹Ÿç”¨æˆ·å·¥ä½œæµç¨‹...")
    
    # æ¨¡æ‹Ÿä¸€ä¸ªå®Œæ•´çš„å¼€å‘å·¥ä½œæµç¨‹
    workflow_steps = [
        ("éœ€æ±‚åˆ†æ", "åˆ†æç”¨æˆ·è®¤è¯ç³»ç»Ÿéœ€æ±‚"),
        ("æŠ€æœ¯é€‰å‹", "é€‰æ‹©åˆé€‚çš„æŠ€æœ¯æ ˆ"),
        ("æ¶æ„è®¾è®¡", "è®¾è®¡ç³»ç»Ÿæ¶æ„"),
        ("æ•°æ®åº“è®¾è®¡", "è®¾è®¡ç”¨æˆ·è¡¨å’Œæƒé™è¡¨"),
        ("API è®¾è®¡", "è®¾è®¡è®¤è¯ç›¸å…³ API"),
        ("å‰ç«¯å®ç°", "å®ç°ç™»å½•æ³¨å†Œç•Œé¢"),
        ("åç«¯å®ç°", "å®ç°è®¤è¯é€»è¾‘"),
        ("æµ‹è¯•éªŒè¯", "è¿›è¡ŒåŠŸèƒ½æµ‹è¯•")
    ]
    
    for step_name, step_desc in workflow_steps:
        print(f"   æ‰§è¡Œæ­¥éª¤: {step_name}")
        
        # 1. æ”¶é›†ä¸Šä¸‹æ–‡
        start_time = time.time()
        context = await context_tool.collect_smart(step_desc, limit=1000)
        context_time = time.time() - start_time
        
        # 2. æœç´¢ç›¸å…³è®°å¿†
        start_time = time.time()
        memories = memory_tool.search_smart(step_desc, limit=3)
        memory_time = time.time() - start_time
        
        # 3. ä»»åŠ¡åˆ†é…
        start_time = time.time()
        task_result = await orchestrator.run_round(step_desc, [context])
        task_time = time.time() - start_time
        
        # 4. å­˜å‚¨æ–°çŸ¥è¯†
        memory_key = f"workflow_{step_name.lower().replace(' ', '_')}"
        memory_tool.store(
            key=memory_key,
            value={
                "step": step_name,
                "description": step_desc,
                "context_length": len(context) if context else 0,
                "memories_found": len(memories),
                "tasks_generated": len(task_result.get('tasks', [])),
                "timestamp": datetime.now().isoformat()
            },
            memory_type="workflow",
            priority="medium",
            tags=["workflow", "auth_system", step_name.lower()]
        )
        
        # è®°å½•æ€§èƒ½æŒ‡æ ‡
        total_time = context_time + memory_time + task_time
        learning_engine.record_performance_metrics(
            response_time=total_time,
            memory_usage=0.4,
            cpu_usage=0.3,
            success_rate=1.0,
            error_count=0,
            throughput=1.0 / max(total_time, 0.001),
            context_size=len(context) if context else 0,
            memory_hits=len(memories),
            cache_efficiency=0.8
        )
        
        time.sleep(0.2)  # æ¨¡æ‹Ÿå¤„ç†é—´éš”
    
    print(f"   âœ“ å®Œæˆ {len(workflow_steps)} ä¸ªå·¥ä½œæµç¨‹æ­¥éª¤")
    
    print("\n3. åˆ†æå­¦ä¹ æˆæœ...")
    
    # åˆ†æç”¨æˆ·æ¨¡å¼
    patterns = learning_engine.analyze_user_patterns()
    print(f"   âœ“ è¯†åˆ«åˆ° {len(patterns)} ä¸ªå·¥ä½œæ¨¡å¼")
    
    # ç”Ÿæˆä¼˜åŒ–å»ºè®®
    recommendations = learning_engine.get_optimization_recommendations()
    print(f"   âœ“ ç”Ÿæˆ {len(recommendations)} ä¸ªä¼˜åŒ–å»ºè®®")
    
    # æ‰§è¡Œè‡ªåŠ¨ä¼˜åŒ–
    optimization_results = optimizer.optimize_automatically()
    print(f"   âœ“ æ‰§è¡Œ {len(optimization_results)} é¡¹è‡ªåŠ¨ä¼˜åŒ–")
    
    print("\n4. ç³»ç»Ÿæ•´ä½“æ€§èƒ½è¯„ä¼°...")
    
    # è·å–ç»¼åˆç»Ÿè®¡
    learning_stats = learning_engine.get_learning_stats()
    optimization_status = optimizer.get_optimization_status()
    memory_stats = memory_tool.get_memory_stats()
    
    print(f"   âœ“ å­¦ä¹ å¼•æ“ç»Ÿè®¡:")
    print(f"     - æ€»è¡Œä¸ºè®°å½•: {learning_stats['total_actions']}")
    print(f"     - ç³»ç»ŸæˆåŠŸç‡: {learning_stats['success_rate']:.2%}")
    print(f"     - å¹³å‡å“åº”æ—¶é—´: {learning_stats['avg_response_time']:.3f}s")
    print(f"     - è¯†åˆ«æ¨¡å¼æ•°: {learning_stats['patterns_identified']}")
    
    print(f"   âœ“ ä¼˜åŒ–å™¨çŠ¶æ€:")
    print(f"     - æ€»ä¼˜åŒ–æ¬¡æ•°: {optimization_status['total_optimizations']}")
    print(f"     - ä¼˜åŒ–æˆåŠŸç‡: {optimization_status['successful_optimizations'] / max(optimization_status['total_optimizations'], 1):.2%}")
    print(f"     - å¹³å‡æ€§èƒ½æ”¹è¿›: {optimization_status['average_improvement']:.2%}")
    
    print(f"   âœ“ è®°å¿†ç³»ç»Ÿç»Ÿè®¡:")
    smart_stats = memory_stats['smart_memory_stats']
    print(f"     - å­˜å‚¨è®°å¿†æ•°: {smart_stats['total_memories']}")
    print(f"     - ç´¢å¼•å…³é”®è¯: {smart_stats['index_keywords']}")
    print(f"     - ç´¢å¼•æ ‡ç­¾: {smart_stats['index_tags']}")
    
    print("\n5. æ¸…ç†èµ„æº...")
    
    # æ¸…ç†èµ„æº
    optimizer.cleanup()
    memory_tool.cleanup()
    
    print("   âœ“ èµ„æºæ¸…ç†å®Œæˆ")
    
    print("\nâœ… ç«¯åˆ°ç«¯è‡ªé€‚åº”å­¦ä¹ æµç¨‹æµ‹è¯•å®Œæˆ")


async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ å¼€å§‹ P3 é˜¶æ®µè‡ªé€‚åº”å­¦ä¹ ä¸ä¼˜åŒ–åŠŸèƒ½æµ‹è¯•")
    print("=" * 60)
    
    try:
        # æµ‹è¯•å­¦ä¹ å¼•æ“
        learning_engine = test_learning_engine()
        
        # æµ‹è¯•è‡ªé€‚åº”ä¼˜åŒ–å™¨
        optimizer = test_adaptive_optimizer(learning_engine)
        
        # æµ‹è¯•é›†æˆå·¥å…·
        await test_integrated_tools(learning_engine, optimizer)
        
        # æµ‹è¯•ç«¯åˆ°ç«¯æµç¨‹
        await test_end_to_end_adaptive_learning()
        
        print("\n" + "=" * 60)
        print("ğŸ‰ P3 é˜¶æ®µæ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
        print("\nâœ… è‡ªé€‚åº”å­¦ä¹ ä¸ä¼˜åŒ–åŠŸèƒ½éªŒè¯æˆåŠŸ")
        print("\nä¸»è¦æˆæœ:")
        print("  â€¢ LearningEngine: ç”¨æˆ·è¡Œä¸ºåˆ†æå’Œæ¨¡å¼è¯†åˆ« âœ“")
        print("  â€¢ AdaptiveOptimizer: åŠ¨æ€å‚æ•°è°ƒæ•´å’Œæ€§èƒ½ä¼˜åŒ– âœ“")
        print("  â€¢ PerformanceMonitor: å®æ—¶ç›‘æ§å’Œç“¶é¢ˆæ£€æµ‹ âœ“")
        print("  â€¢ é›†æˆå·¥å…·: æ™ºèƒ½ä»»åŠ¡åˆ†é…ã€ä¸Šä¸‹æ–‡æ”¶é›†ã€è®°å¿†ç®¡ç† âœ“")
        print("  â€¢ ç«¯åˆ°ç«¯æµç¨‹: å®Œæ•´çš„è‡ªé€‚åº”å­¦ä¹ å·¥ä½œæµ âœ“")
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    return True


if __name__ == "__main__":
    # è¿è¡Œæµ‹è¯•
    success = asyncio.run(main())
    
    if success:
        print("\nğŸ¯ P3 é˜¶æ®µå¼€å‘å®Œæˆï¼ŒSolo MCP ç°å·²å…·å¤‡å¼ºå¤§çš„è‡ªé€‚åº”å­¦ä¹ ä¸ä¼˜åŒ–èƒ½åŠ›ï¼")
    else:
        print("\nâš ï¸  æµ‹è¯•æœªå®Œå…¨é€šè¿‡ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯å¹¶ä¿®å¤é—®é¢˜ã€‚")