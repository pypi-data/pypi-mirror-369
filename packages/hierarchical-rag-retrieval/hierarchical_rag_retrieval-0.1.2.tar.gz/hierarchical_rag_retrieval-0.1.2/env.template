# =============================
# Hierarchical RAG 環境變數模板（帶詳細說明）
# 請將本檔案複製為 .env，並依需求填入值
# 未填值者，系統會使用內建預設值
# 布林值可接受：true/false/1/0/yes/no/y/n/on/off（不分大小寫）
# 多值（如 CORS_ORIGINS）使用逗號分隔
# =============================

# -------- 基本（必填） --------
# OpenAI API 金鑰（用於 Chat 模型與查詢提取/生成）。
# 缺少此值時，演示應用的 LLM 相關功能將無法運作。
OPENAI_API_KEY=

# -------- LLM 參數（可選） --------
# 指定使用的 Chat 模型（例如：gpt-4o-mini、gpt-4o、gpt-4.1 等）。
# 不設定時使用套件預設模型。
OPENAI_MODEL=

# 溫度（0.0~1.0）：控制隨機性，越低越保守、越高越發散；不填則用套件預設。
OPENAI_TEMPERATURE=

# Top-p（0.0~1.0）：機率截斷採樣；與溫度搭配使用，不填則用套件預設。
OPENAI_TOP_P=

# 最大輸出 Token：依模型上限合理設置；超過可能報錯。
# 不填使用系統預設 8196（僅作為上限參考）。
OPENAI_MAX_TOKENS=

# -------- Embedding 模型（可選） --------
# 預設：intfloat/multilingual-e5-large（多語系表現良好）。
# 可改為任一 SentenceTransformers 支援模型。
EMBEDDING_MODEL_NAME=

# -------- 檢索參數（可選） --------
# 文本分塊大小（字元數）：較大保留更多上下文、較小提升精度。
CHUNK_SIZE=

# 分塊重疊大小（字元數）：避免重要資訊被截斷；視 chunk 大小調整。
CHUNK_OVERLAP=

# 最多處理的分塊數：限制長查詢的切分數量以控制成本。
MAX_CHUNKS=

# 超過該候選數量時，進一步排序/篩選（包含可選的 Rerank 流程）。
MAX_RESULTS=

# 二次排序或重排後取前 K 筆（在大量候選時生效）。
TOP_K=

# -------- Rerank（重排序）開關與設定（可選） --------
# 是否在管線中啟用 Rerank（僅當檢索結果數量 > MAX_RESULTS 時生效）。
# 預設 false（關閉）。
RERANKER_ENABLE_IN_PIPELINE=

# 是否使用 Cross-Encoder 進行配對打分（啟用時延遲增加但精度較高）。
# 預設 false（使用 embedding 餘弦相似度）。
RERANKER_USE_CROSS_ENCODER=

# Cross-Encoder 模型名稱（預設：cross-encoder/ms-marco-MiniLM-L-6-v2）。
# 可改為如：cross-encoder/ms-marco-MiniLM-L-12-v2 等。
RERANKER_MODEL_NAME=

# 備註：
# - 啟用 Cross-Encoder 時會自動偵測運算裝置（CUDA/MPS/CPU）。
# - 若硬體不支援 GPU，將於 CPU 上執行，請留意延遲。

# -------- API 與 CORS（可選） --------
# 允許的跨域來源，逗號分隔；預設為 *（全部允許）。
# 例：http://localhost:3000,https://your.domain
CORS_ORIGINS=

# API 服務標題（顯示於 Swagger UI 等）。
API_TITLE=

# -------- 其他說明 --------
# - 未設置之欄位會採用內建預設值，足以啟動與運行。
# - 若要快速體驗，至少需要設定 OPENAI_API_KEY。
# - 不同 LLM 供應商或版本，參數意義可能略有差異，請依實際需求調整。
