Metadata-Version: 2.4
Name: hierarchical-rag-retrieval
Version: 0.1.2
Summary: AI-Powered Legal Document Retrieval Engine based on Hierarchical Clustering & RAG
Home-page: https://github.com/arthur422tp/hierarchical
Author: arthur422tp
Author-email: arthur422tp <arthur422tp@gmail.com>
License: MIT
Project-URL: Homepage, https://github.com/arthur422tp/hierarchical
Project-URL: Documentation, https://github.com/arthur422tp/hierarchical#readme
Project-URL: Repository, https://github.com/arthur422tp/hierarchical
Project-URL: Bug Tracker, https://github.com/arthur422tp/hierarchical/issues
Project-URL: arXiv Paper, https://arxiv.org/abs/2506.13607
Keywords: rag,retrieval,hierarchical,clustering,legal,nlp,ai,machine-learning
Classifier: Development Status :: 3 - Alpha
Classifier: Intended Audience :: Developers
Classifier: Intended Audience :: Science/Research
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Classifier: Topic :: Text Processing :: Linguistic
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Operating System :: OS Independent
Requires-Python: >=3.8
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: sentence-transformers>=2.2.0
Requires-Dist: faiss-cpu>=1.7.0
Requires-Dist: torch>=2.0.0
Requires-Dist: numpy>=2.3.0
Requires-Dist: scipy>=1.16.0
Requires-Dist: fastcluster>=1.3.0
Requires-Dist: scikit-learn>=1.3.0
Requires-Dist: langchain>=0.3.26
Requires-Dist: langchain-openai>=0.0.2
Requires-Dist: langchain_community>=0.0.10
Requires-Dist: python-dotenv>=1.0.0
Requires-Dist: pandas>=1.5.0
Provides-Extra: dev
Requires-Dist: pytest>=6.0; extra == "dev"
Requires-Dist: black; extra == "dev"
Requires-Dist: flake8; extra == "dev"
Requires-Dist: isort; extra == "dev"
Provides-Extra: app
Requires-Dist: fastapi>=0.104.0; extra == "app"
Requires-Dist: uvicorn>=0.24.0; extra == "app"
Requires-Dist: python-multipart>=0.0.6; extra == "app"
Requires-Dist: pydantic>=2.4.0; extra == "app"
Dynamic: author
Dynamic: home-page
Dynamic: license-file
Dynamic: requires-python

# Legal Document Retrieval System Based on Hierarchical Clustering
## éšå±¤å¼èšé¡æ³•è¦æ–‡æœ¬æª¢ç´¢ç³»çµ±

<div align="center">

![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)
![License](https://img.shields.io/badge/License-MIT-green.svg)
![FastAPI](https://img.shields.io/badge/FastAPI-0.104+-red.svg)
![Docker](https://img.shields.io/badge/Docker-Ready-blue.svg)

**åŸºæ–¼éšå±¤å¼èšé¡èˆ‡ RAG çš„æ³•è¦æ–‡æœ¬æ™ºæ…§æª¢ç´¢å¼•æ“**

[ğŸ“– å¿«é€Ÿé–‹å§‹](#ğŸš€-å¿«é€Ÿé–‹å§‹) â€¢ [ğŸ“š ä½¿ç”¨æŒ‡å—](#ğŸ“š-è©³ç´°ä½¿ç”¨æŒ‡å—) â€¢ [ğŸ”§ API åƒè€ƒ](#ğŸ”¬-api-åƒè€ƒ) â€¢ [ğŸ“„ arXiv è«–æ–‡](https://arxiv.org/abs/2506.13607)

</div>

## ğŸ“– ç³»çµ±ä»‹ç´¹

æœ¬ç³»çµ±æ˜¯ä¸€å€‹çµåˆ AI æ³•å¾‹åŠ©æ‰‹èˆ‡æ³•è¦æŸ¥è©¢åŠŸèƒ½çš„æ™ºæ…§æª¢ç´¢å¼•æ“ï¼Œæ ¸å¿ƒæŠ€è¡“ç‚ºéšå±¤å¼èšé¡ï¼ˆHierarchical Clusteringï¼‰èˆ‡é¤˜å¼¦ç›¸ä¼¼åº¦ï¼ˆCosine Similarityï¼‰ï¼Œä¸¦é€é OpenAI çš„ Retrieval-Augmented Generationï¼ˆRAGï¼‰æŠ€è¡“é€²è¡Œç­”æ¡ˆç”Ÿæˆã€‚é©ç”¨æ–¼æ™ºæ…§å¾‹æ‰€ã€æ³•å¾‹èŠå¤©æ©Ÿå™¨äººã€å­¸è¡“ç ”ç©¶æˆ–å¤šèªè¨€æ³•æ¢ç´¢å¼•å ´æ™¯ï¼Œèƒ½æœ‰æ•ˆæä¾›æº–ç¢ºã€å¯è§£é‡‹çš„æ³•è¦æŸ¥è©¢å›è¦†ã€‚

### ğŸ¯ æ ¸å¿ƒç‰¹è‰²

- **ğŸŒ³ éšå±¤å¼æª¢ç´¢æ¨¹**ï¼šè‡ªå‹•å»ºæ§‹èªæ„å±¤æ¬¡ç´¢å¼•çµæ§‹
- **ğŸ” é›™é‡æª¢ç´¢æ¨¡å¼**ï¼šæ”¯æ´ç›´æ¥æª¢ç´¢èˆ‡æŸ¥è©¢æå–å…©ç¨®æ–¹å¼
- **ğŸ§  RAG æŠ€è¡“æ•´åˆ**ï¼šçµåˆ OpenAI GPT é€²è¡Œæ™ºèƒ½ç­”æ¡ˆç”Ÿæˆ
- **âš¡ é«˜æ•ˆèƒ½æª¢ç´¢**ï¼šç„¡é ˆæ‰‹å‹•è¨­å®š k å€¼ï¼Œè‡ªå‹•ç¯©é¸ç›¸é—œæ–‡æœ¬
- **ğŸ¨ æ¨¡çµ„åŒ–è¨­è¨ˆ**ï¼šæ˜“æ–¼æ•´åˆåˆ°ç¾æœ‰å°ˆæ¡ˆä¸­
- **ğŸŒ å…¨ç«¯è§£æ±ºæ–¹æ¡ˆ**ï¼šå…§å»ºå‰ç«¯ UI + REST API
- **ğŸ³ Docker æ”¯æ´**ï¼šæ”¯æ´å®¹å™¨åŒ–éƒ¨ç½²ï¼Œä¸€éµå•Ÿå‹•

## ğŸ› ï¸ æŠ€è¡“æ¶æ§‹

| Component | Tech Used |
|----------|------------|
| Frontend | HTML / JavaScript / Tailwind CSS |
| Backend | FastAPI |
| Embedding Model | `intfloat/multilingual-e5-large` |
| Retrieval Tree | Hierarchical Clustering + Cosine Similarity |
| LLM API | OpenAI GPT (ChatGPT API) |
| Containerization | Docker & Docker Compose |

### æ ¸å¿ƒçµ„ä»¶æ¶æ§‹

```
hierarchical-rag-retrieval/
â”œâ”€â”€ retrieval/          # æª¢ç´¢æ ¸å¿ƒæ¨¡çµ„
â”‚   â”œâ”€â”€ RAGTree_function.py      # éšå±¤å¼æª¢ç´¢æ¨¹
â”‚   â”œâ”€â”€ multi_level_search.py    # å¤šå±¤ç´¢å¼•æª¢ç´¢
â”‚   â””â”€â”€ generated_function.py    # æŸ¥è©¢æå–åŠŸèƒ½
â”œâ”€â”€ utils/              # å·¥å…·æ¨¡çµ„
â”‚   â”œâ”€â”€ word_embedding.py        # è©åµŒå…¥è™•ç†
â”‚   â”œâ”€â”€ word_chunking.py         # æ–‡æœ¬åˆ†å¡Š
â”‚   â””â”€â”€ query_retrieval.py       # FAISS æª¢ç´¢
â”œâ”€â”€ data_processing/    # è³‡æ–™è™•ç†æ¨¡çµ„
â”‚   â””â”€â”€ data_dealer.py           # è³‡æ–™æ ¼å¼è™•ç†
â””â”€â”€ app/                # æ¼”ç¤ºæ‡‰ç”¨
    â”œâ”€â”€ main.py                  # FastAPI ä¸»ç¨‹å¼
    â””â”€â”€ static/index.html        # å‰ç«¯ä»‹é¢
```

## ğŸš€ å¿«é€Ÿé–‹å§‹

### ğŸ“¦ å¥—ä»¶å®‰è£

```bash
pip install hierarchical-rag-retrieval
```

### ğŸ¯ åŸºæœ¬ä½¿ç”¨ç¯„ä¾‹

```python
from src.retrieval import create_ahc_tree, tree_search
from src.utils import WordEmbedding

# 1. åˆå§‹åŒ–è©åµŒå…¥æ¨¡å‹
embedding_model = WordEmbedding()
model = embedding_model.load_model()

# 2. æº–å‚™æ‚¨çš„æ–‡æœ¬è³‡æ–™
texts = [
    "æ°‘æ³•ç¸½å‰‡è¦å®šè‡ªç„¶äººä¹‹æ¬Šåˆ©èƒ½åŠ›å§‹æ–¼å‡ºç”Ÿçµ‚æ–¼æ­»äº¡",
    "åœŸåœ°æ³•è¦å®šåœŸåœ°æ‰€æœ‰æ¬Šä¹‹ç§»è½‰æ‡‰è¾¦ç†ç™»è¨˜",
    "éƒ½å¸‚è¨ˆç•«æ³•è¦å®šéƒ½å¸‚è¨ˆç•«å€åŸŸå…§åœŸåœ°ä½¿ç”¨åˆ†å€",
    # ... æ›´å¤šæ–‡æœ¬
]

# 3. ç”Ÿæˆæ–‡æœ¬å‘é‡
vectors = model.encode(texts)

# 4. å»ºç«‹éšå±¤å¼æª¢ç´¢æ¨¹
tree_root = create_ahc_tree(vectors, texts)

# 5. é€²è¡Œæª¢ç´¢
query = "åœŸåœ°æ‰€æœ‰æ¬Šç§»è½‰éœ€è¦ä»€éº¼ç¨‹åºï¼Ÿ"
results = tree_search(
    tree_root, 
    query, 
    model, 
    chunk_size=100, 
    chunk_overlap=20
)

# 6. æŸ¥çœ‹çµæœ
for i, result in enumerate(results, 1):
    print(f"{i}. {result}")
```

### ğŸ”§ ç’°å¢ƒè¨­ç½®ï¼ˆæ¼”ç¤ºæ‡‰ç”¨ï¼‰

#### å‰ç½®æ¢ä»¶

- Python 3.8+ æˆ– Docker ç’°å¢ƒ
- OpenAI API é‡‘é‘°

#### æ–¹æ³•ä¸€ï¼šå‚³çµ±éƒ¨ç½²

```bash
# å®‰è£ä¾è³´
pip install -r requirements.txt

# è¨­ç½®ç’°å¢ƒè®Šæ•¸
echo "OPENAI_API_KEY=your_openai_api_key" > .env

# å•Ÿå‹•æ‡‰ç”¨
cd app && python main.py
```

#### æ–¹æ³•äºŒï¼šDocker éƒ¨ç½² (æ¨è–¦)

```bash
# è¨­ç½®ç’°å¢ƒè®Šæ•¸
echo "OPENAI_API_KEY=your_openai_api_key" > .env

# å•Ÿå‹•æœå‹™
docker-compose up -d

# æŸ¥çœ‹æ—¥èªŒ
docker-compose logs -f
```

æ‡‰ç”¨å•Ÿå‹•å¾Œï¼Œç€è¦½å™¨è¨ªå• http://localhost:8000 ä½¿ç”¨ç³»çµ±ã€‚

## ğŸ“š è©³ç´°ä½¿ç”¨æŒ‡å—

### 1. éšå±¤å¼æª¢ç´¢æ¨¹ (RAGTree)

éšå±¤å¼æª¢ç´¢æ¨¹æ˜¯æœ¬ç³»çµ±çš„æ ¸å¿ƒåŠŸèƒ½ï¼Œé€šéèšé¡ç®—æ³•è‡ªå‹•çµ„ç¹”æ–‡æœ¬å‘é‡ã€‚

```python
from src.retrieval import create_ahc_tree, tree_search, save_tree, load_tree

# å»ºç«‹æª¢ç´¢æ¨¹
tree_root = create_ahc_tree(vectors, texts)

# å„²å­˜æª¢ç´¢æ¨¹ï¼ˆå¯é‡è¤‡ä½¿ç”¨ï¼‰
save_tree(tree_root, "my_retrieval_tree.pkl")

# è¼‰å…¥å·²å„²å­˜çš„æª¢ç´¢æ¨¹
tree_root = load_tree("my_retrieval_tree.pkl")

# é€²è¡Œæª¢ç´¢
results = tree_search(
    root=tree_root,
    query="æ‚¨çš„æŸ¥è©¢å•é¡Œ",
    model=embedding_model.load_model(),
    chunk_size=100,
    chunk_overlap=20,
    max_chunks=10
)
```

**åƒæ•¸èªªæ˜ï¼š**
- `chunk_size`: æ–‡æœ¬åˆ†å¡Šå¤§å°ï¼Œè¼ƒå¤§çš„å€¼ä¿ç•™æ›´å¤šä¸Šä¸‹æ–‡
- `chunk_overlap`: åˆ†å¡Šé‡ç–Šå¤§å°ï¼Œé¿å…é‡è¦è³‡è¨Šè¢«æˆªæ–·
- `max_chunks`: æœ€å¤§åˆ†å¡Šæ•¸é‡ï¼Œæ§åˆ¶è™•ç†æ•ˆç‡

### 2. å¤šå±¤ç´¢å¼•æª¢ç´¢(ç›®å‰å°šæœªå®Œæˆï¼Œä»¥ä¸‹ç‚ºé è¨ˆæƒ…å½¢ï½œNot done yet)

é‡å°å¤§å‹æ–‡æœ¬åº«å„ªåŒ–çš„å¤šå±¤ç´¢å¼•ç³»çµ±ã€‚

```python
from src.retrieval import (
    build_multi_level_index_from_files, 
    multi_level_tree_search,
    multi_level_extraction_tree_search
)

# å¾æª”æ¡ˆå»ºç«‹å¤šå±¤ç´¢å¼•
index = build_multi_level_index_from_files(
    embeddings_path="embeddings.pkl",
    texts_path="texts.pkl"
)

# ç›´æ¥æª¢ç´¢
results = multi_level_tree_search(
    index=index,
    query="æŸ¥è©¢å•é¡Œ",
    model=model,
    chunk_size=100,
    chunk_overlap=20
)

# ä½¿ç”¨æŸ¥è©¢æå–çš„æª¢ç´¢ï¼ˆé©åˆè¤‡é›œå•é¡Œï¼‰
results = multi_level_extraction_tree_search(
    index=index,
    query="è¤‡é›œçš„æ³•å¾‹å•é¡Œæè¿°...",
    model=model,
    chunk_size=100,
    chunk_overlap=20,
    llm=openai_llm  # OpenAI èªè¨€æ¨¡å‹
)
```

### 3. æŸ¥è©¢æå–èˆ‡å„ªåŒ–

å°æ–¼è¤‡é›œæˆ–å†—é•·çš„æŸ¥è©¢ï¼Œç³»çµ±å¯ä»¥è‡ªå‹•æå–æ ¸å¿ƒå•é¡Œã€‚

```python
from src.retrieval import extraction_tree_search
from langchain_openai import ChatOpenAI

# è¨­å®š OpenAI æ¨¡å‹
llm = ChatOpenAI(
    model="gpt-3.5-turbo",
    api_key="your-openai-api-key"
)

# ä½¿ç”¨æŸ¥è©¢æå–é€²è¡Œæª¢ç´¢
complex_query = """
æˆ‘æƒ³äº†è§£é—œæ–¼åœŸåœ°è²·è³£çš„æ³•å¾‹è¦å®šï¼Œç‰¹åˆ¥æ˜¯åœ¨éƒ½å¸‚è¨ˆç•«å€åŸŸå…§ï¼Œ
å¦‚æœæˆ‘è¦è³¼è²·ä¸€å¡ŠåœŸåœ°ç”¨æ–¼å•†æ¥­ç”¨é€”ï¼Œéœ€è¦æ³¨æ„å“ªäº›æ³•å¾‹æ¢æ–‡ï¼Ÿ
å¦å¤–ï¼ŒåœŸåœ°æ‰€æœ‰æ¬Šçš„ç§»è½‰ç¨‹åºæ˜¯ä»€éº¼ï¼Ÿ
"""

results = extraction_tree_search(
    root=tree_root,
    query=complex_query,
    model=model,
    chunk_size=100,
    chunk_overlap=20,
    llm=llm
)
```

### 4. è‡ªå®šç¾©æ–‡æœ¬è™•ç†

```python
from src.utils import WordEmbedding, RagChunking
from src.data_processing import DataDealer
import pickle

# è™•ç†è‡ªå®šç¾©æ–‡æœ¬è³‡æ–™
dealer = DataDealer()

# æº–å‚™æ–‡æœ¬è³‡æ–™
custom_texts = [
    "æ‚¨çš„ç¬¬ä¸€å€‹æ–‡æª”å…§å®¹...",
    "æ‚¨çš„ç¬¬äºŒå€‹æ–‡æª”å…§å®¹...",
    # ... æ›´å¤šæ–‡æœ¬
]

# ç”ŸæˆåµŒå…¥å‘é‡
embedding_model = WordEmbedding()
model = embedding_model.load_model()
vectors = model.encode(custom_texts)

# å„²å­˜è™•ç†å¾Œçš„è³‡æ–™
with open('custom_texts.pkl', 'wb') as f:
    pickle.dump(custom_texts, f)
with open('custom_embeddings.pkl', 'wb') as f:
    pickle.dump(vectors, f)

# æ–‡æœ¬åˆ†å¡Šè™•ç†
chunker = RagChunking("é•·æ–‡æœ¬å…§å®¹...")
chunks = chunker.text_chunking(chunk_size=200, chunk_overlap=50)
```

## ğŸ¨ é€²éšç”¨æ³•ï¼ˆéä¸»è¦åŠŸèƒ½ï¼Œæœ‰äº›å·²ç¶“å»¢æ£„ï¼‰

### 1. è‡ªå®šç¾©é‡æ’åº(éœ€è‡ªè¡Œå°å…¥cross-encoder model)

```python
from src.retrieval import rerank_texts

# å°æª¢ç´¢çµæœé€²è¡Œé‡æ–°æ’åº
query = "æŸ¥è©¢å•é¡Œ"
passages = ["æ–‡æª”1", "æ–‡æª”2", "æ–‡æª”3"]
reranked_passages = rerank_texts(query, passages, model)
```

### 2. æ‰¹æ¬¡è™•ç†

```python
def batch_search(queries, tree_root, model):
    """æ‰¹æ¬¡è™•ç†å¤šå€‹æŸ¥è©¢"""
    all_results = {}
    for query in queries:
        results = tree_search(tree_root, query, model, 100, 20)
        all_results[query] = results
    return all_results

queries = [
    "åœŸåœ°æ³•ç›¸é—œå•é¡Œ",
    "æ°‘æ³•ç¸½å‰‡è¦å®š", 
    "éƒ½å¸‚è¨ˆç•«æ³•æ¢æ–‡"
]

batch_results = batch_search(queries, tree_root, model)
```

### 3. çµæœå¾Œè™•ç†

```python
def process_results(results, max_results=5):
    """è™•ç†å’Œéæ¿¾æª¢ç´¢çµæœ"""
    # å»é‡
    unique_results = list(set(results))
    
    # é•·åº¦éæ¿¾
    filtered_results = [r for r in unique_results if len(r.strip()) > 20]
    
    # é™åˆ¶æ•¸é‡
    return filtered_results[:max_results]

processed_results = process_results(results)
```

## ğŸ“ æ›´æ–°é™„è¨»ï¼ˆæœ€è¿‘è®Šæ›´ï¼‰

- å¤–éƒ¨åŒ–åƒæ•¸ï¼šç¾åœ¨å¯é€éç’°å¢ƒè®Šæ•¸èª¿æ•´ï¼Œä¸éœ€æ”¹ç¢¼ã€‚
  - LLMï¼š`OPENAI_API_KEY`ã€`OPENAI_MODEL`ã€`OPENAI_TEMPERATURE`ã€`OPENAI_TOP_P`ã€`OPENAI_MAX_TOKENS`
  - Embeddingï¼š`EMBEDDING_MODEL_NAME`
  - æª¢ç´¢ï¼š`CHUNK_SIZE`ã€`CHUNK_OVERLAP`ã€`MAX_CHUNKS`ã€`MAX_RESULTS`ã€`TOP_K`
  - Rerankï¼š`RERANKER_ENABLE_IN_PIPELINE`ï¼ˆé è¨­ falseï¼‰ã€`RERANKER_USE_CROSS_ENCODER`ï¼ˆé è¨­ falseï¼‰ã€`RERANKER_MODEL_NAME`
  - APIï¼š`CORS_ORIGINS`ã€`API_TITLE`

- Rerank ç®¡ç·šé–‹é—œï¼š
  - ç•¶ `RERANKER_ENABLE_IN_PIPELINE=true` ä¸”æª¢ç´¢çµæœæ•¸é‡ > `MAX_RESULTS` æ™‚ï¼Œç³»çµ±æœƒè‡ªå‹•å°å€™é¸çµæœé€²è¡Œé‡æ’åºã€‚
  - è‹¥åŒæ™‚è¨­å®š `RERANKER_USE_CROSS_ENCODER=true`ï¼Œæœƒæ”¹ç”¨ Cross-Encoder é€²è¡Œé…å°æ‰“åˆ†é‡æ’ï¼ˆå¯é€é `RERANKER_MODEL_NAME` æŒ‡å®šæ¨¡å‹ï¼‰ã€‚

- .env ç¯„ä¾‹ï¼š

```bash
OPENAI_API_KEY=sk-xxxx
OPENAI_MODEL=gpt-4o-mini
OPENAI_TEMPERATURE=0.2
OPENAI_TOP_P=0.9
OPENAI_MAX_TOKENS=4096
EMBEDDING_MODEL_NAME=intfloat/multilingual-e5-large
CHUNK_SIZE=150
CHUNK_OVERLAP=50
MAX_CHUNKS=12
MAX_RESULTS=100
TOP_K=15
RERANKER_ENABLE_IN_PIPELINE=true
RERANKER_USE_CROSS_ENCODER=true
RERANKER_MODEL_NAME=cross-encoder/ms-marco-MiniLM-L-6-v2
CORS_ORIGINS=http://localhost:3000,https://your.domain
API_TITLE=Hierarchical RAG API
```

## ğŸ”§ é…ç½®åƒæ•¸

### è©åµŒå…¥æ¨¡å‹é…ç½®

```python
# é è¨­ä½¿ç”¨ intfloat/multilingual-e5-large
# æ‚¨ä¹Ÿå¯ä»¥ä½¿ç”¨å…¶ä»– Sentence Transformers æ¨¡å‹

from sentence_transformers import SentenceTransformer

# è‡ªå®šç¾©æ¨¡å‹
custom_model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')

# åœ¨æª¢ç´¢ä¸­ä½¿ç”¨
results = tree_search(tree_root, query, custom_model, 100, 20)
```

### ç³»çµ±åƒæ•¸èª¿æ•´

```python
# é‡å°ä¸åŒå ´æ™¯çš„åƒæ•¸å»ºè­°

# ç²¾ç¢ºæª¢ç´¢ï¼ˆè¼ƒæ…¢ä½†æ›´æº–ç¢ºï¼‰
results = tree_search(
    tree_root, query, model,
    chunk_size=50,      # è¼ƒå°çš„åˆ†å¡Š
    chunk_overlap=10,   # è¼ƒå°çš„é‡ç–Š
    max_chunks=5        # è¼ƒå°‘çš„åˆ†å¡Šæ•¸
)

# å¿«é€Ÿæª¢ç´¢ï¼ˆè¼ƒå¿«ä½†å¯èƒ½éºæ¼ç´°ç¯€ï¼‰
results = tree_search(
    tree_root, query, model,
    chunk_size=200,     # è¼ƒå¤§çš„åˆ†å¡Š
    chunk_overlap=40,   # è¼ƒå¤§çš„é‡ç–Š
    max_chunks=15       # è¼ƒå¤šçš„åˆ†å¡Šæ•¸
)
```

## ğŸ“Š æ•ˆèƒ½å„ªåŒ–å»ºè­°

### 1. è¨˜æ†¶é«”ç®¡ç†

```python
# å°æ–¼å¤§å‹æ–‡æœ¬åº«ï¼Œå»ºè­°åˆ†æ‰¹è™•ç†
def process_large_corpus(texts, batch_size=1000):
    trees = []
    for i in range(0, len(texts), batch_size):
        batch = texts[i:i+batch_size]
        batch_vectors = model.encode(batch)
        tree = create_ahc_tree(batch_vectors, batch)
        trees.append(tree)
    return trees
```

### 2. å¿«å–æ©Ÿåˆ¶

```python
import os

# æª¢æŸ¥æ˜¯å¦å·²æœ‰å»ºç«‹å¥½çš„æª¢ç´¢æ¨¹
tree_file = "retrieval_tree.pkl"
if os.path.exists(tree_file):
    tree_root = load_tree(tree_file)
else:
    tree_root = create_ahc_tree(vectors, texts)
    save_tree(tree_root, tree_file)
```

## ğŸ” å¯¦éš›æ‡‰ç”¨æ¡ˆä¾‹

### æ³•å¾‹æ–‡ä»¶æª¢ç´¢

```python
# æ³•å¾‹æ¢æ–‡æª¢ç´¢ç³»çµ±
legal_texts = [
    "æ°‘æ³•ç¬¬ä¸€æ¢ï¼šæ°‘äº‹ï¼Œæ³•å¾‹æ‰€æœªè¦å®šè€…ï¼Œä¾ç¿’æ…£...",
    "åˆ‘æ³•ç¬¬åæ¢ï¼šç¨±ä»¥ä¸Šã€ä»¥ä¸‹ã€ä»¥å…§ã€ä»¥å¤–è€…...",
    # ... æ›´å¤šæ³•æ¢
]

# å»ºç«‹æ³•å¾‹æª¢ç´¢ç³»çµ±
legal_vectors = model.encode(legal_texts)
legal_tree = create_ahc_tree(legal_vectors, legal_texts)

# æŸ¥è©¢æ³•å¾‹å•é¡Œ
legal_query = "é—œæ–¼å¥‘ç´„çš„æ³•å¾‹æ•ˆåŠ›è¦å®š"
legal_results = tree_search(legal_tree, legal_query, model, 100, 20)
```

### å­¸è¡“è«–æ–‡æª¢ç´¢

```python
# å­¸è¡“æ–‡ç»æª¢ç´¢
papers = [
    "æœ¬ç ”ç©¶æ¢è¨æ©Ÿå™¨å­¸ç¿’åœ¨è‡ªç„¶èªè¨€è™•ç†ä¸­çš„æ‡‰ç”¨...",
    "æ·±åº¦å­¸ç¿’æ¨¡å‹åœ¨åœ–åƒè­˜åˆ¥é ˜åŸŸçš„æœ€æ–°é€²å±•...",
    # ... æ›´å¤šè«–æ–‡æ‘˜è¦
]

academic_vectors = model.encode(papers)
academic_tree = create_ahc_tree(academic_vectors, papers)

research_query = "transformeræ¨¡å‹åœ¨æ–‡æœ¬åˆ†é¡çš„æ•ˆæœ"
academic_results = tree_search(academic_tree, research_query, model, 150, 30)
```

## ğŸ”¬ API åƒè€ƒ

### Web æ‡‰ç”¨ API

- `GET /`: ä¸»é é¢
- `GET /available-texts`: ç²å–å¯ç”¨çš„æ–‡æœ¬åˆ—è¡¨
- `POST /query`: æäº¤æŸ¥è©¢è«‹æ±‚
  - è«‹æ±‚é«”ï¼š
    ```json
    {
        "query": "æ‚¨çš„å•é¡Œ",
        "use_extraction": true/false,
        "text_name": "æ–‡æœ¬åç¨±",
        "prompt_type": "task_oriented" | "cot"
    }
    ```
  - éŸ¿æ‡‰ï¼š
    ```json
    {
        "answer": "ç³»çµ±å›ç­”",
        "retrieved_docs": ["æª¢ç´¢åˆ°çš„æ–‡æª”1", "æª¢ç´¢åˆ°çš„æ–‡æª”2", ...]
    }
    ```

### Python API

#### æ ¸å¿ƒæª¢ç´¢å‡½æ•¸

```python
# ä¸»è¦æª¢ç´¢å‡½æ•¸
from src.retrieval import create_ahc_tree, tree_search, save_tree, load_tree

# å¤šå±¤æª¢ç´¢å‡½æ•¸
from src.retrieval import (
    build_multi_level_index_from_files,
    multi_level_tree_search,
    multi_level_extraction_tree_search
)

# æŸ¥è©¢æå–å‡½æ•¸
from src.retrieval import extraction_tree_search

# å·¥å…·å‡½æ•¸
from src.utils import WordEmbedding, RagChunking
from src.data_processing import DataDealer
```

## ğŸ› å¸¸è¦‹å•é¡Œèˆ‡è§£æ±ºæ–¹æ¡ˆ

### Q: æª¢ç´¢çµæœä¸å¤ ç²¾ç¢ºï¼Ÿ
**A:** å˜—è©¦èª¿æ•´åƒæ•¸ï¼š
- æ¸›å°‘ `chunk_size` æé«˜ç²¾åº¦
- å¢åŠ  `max_chunks` ç²å¾—æ›´å¤šå€™é¸çµæœ
- ä½¿ç”¨æŸ¥è©¢æå–åŠŸèƒ½è™•ç†è¤‡é›œå•é¡Œ

### Q: è™•ç†é€Ÿåº¦è¼ƒæ…¢ï¼Ÿ
**A:** å„ªåŒ–å»ºè­°ï¼š
- å¢åŠ  `chunk_size` æ¸›å°‘åˆ†å¡Šæ•¸é‡
- æ¸›å°‘ `max_chunks` é™åˆ¶è™•ç†ç¯„åœ
- ä½¿ç”¨å¤šå±¤ç´¢å¼•ä»£æ›¿å–®ä¸€æª¢ç´¢æ¨¹

### Q: è¨˜æ†¶é«”ä½¿ç”¨éå¤šï¼Ÿ
**A:** è¨˜æ†¶é«”ç®¡ç†ï¼š
- åˆ†æ‰¹è™•ç†å¤§å‹æ–‡æœ¬åº«
- å®šæœŸæ¸…ç†ä¸éœ€è¦çš„è®Šæ•¸
- ä½¿ç”¨ç”Ÿæˆå™¨è€Œéåˆ—è¡¨å­˜å„²å¤§é‡è³‡æ–™

### Q: å¦‚ä½•è™•ç†ä¸åŒèªè¨€çš„æ–‡æœ¬ï¼Ÿ
**A:** å¤šèªè¨€æ”¯æ´ï¼š
- ä½¿ç”¨å¤šèªè¨€åµŒå…¥æ¨¡å‹ï¼ˆå¦‚é è¨­çš„ multilingual-e5-largeï¼‰
- ç¢ºä¿æŸ¥è©¢èªè¨€èˆ‡æ–‡æœ¬èªè¨€ä¸€è‡´
- è€ƒæ…®ä½¿ç”¨èªè¨€ç‰¹å®šçš„åˆ†è©ç­–ç•¥

## ğŸ“„ ç³»çµ±åŠŸèƒ½èªªæ˜

### æª¢ç´¢æµç¨‹

æœ¬ç³»çµ±æä¾›å…©ç¨®æª¢ç´¢æ¨¡å¼ï¼š

1. **ç›´æ¥æª¢ç´¢** - é©åˆç°¡å–®æ˜ç¢ºçš„å•é¡Œ
   - å°‡ç”¨æˆ¶è¼¸å…¥ç›´æ¥å‘é‡åŒ–
   - é€šéæª¢ç´¢æ¨¹å°‹æ‰¾ç›¸ä¼¼æ–‡æœ¬ç‰‡æ®µ
   - ä½¿ç”¨èªè¨€æ¨¡å‹ç”Ÿæˆç­”æ¡ˆ

2. **æŸ¥è©¢æå–æª¢ç´¢** - é©åˆè¤‡é›œæˆ–å†—é•·å•é¡Œ
   - å…ˆä½¿ç”¨èªè¨€æ¨¡å‹æå–æ ¸å¿ƒæ³•å¾‹å•é¡Œå’Œæ¦‚å¿µ
   - å°‡æå–å¾Œçš„é—œéµè¦é»å‘é‡åŒ–
   - é€šéæª¢ç´¢æ¨¹æŸ¥æ‰¾ç›¸é—œç‰‡æ®µ
   - ä½¿ç”¨èªè¨€æ¨¡å‹é‡å°æå–è¦é»ç”Ÿæˆç²¾ç¢ºç­”æ¡ˆ

### å›ç­”æ–¹å¼èªªæ˜

#### ä»»å‹™å°å‘ï¼ˆTask-Orientedï¼‰
- ç‰¹é»ï¼šç°¡æ½”ç›´æ¥ï¼Œå¿«é€Ÿæä¾›ç­”æ¡ˆ
- é©ç”¨ï¼šéœ€è¦æ˜ç¢ºæ³•æ¢è§£é‡‹æˆ–æ“ä½œæŒ‡å¼•çš„å•é¡Œ

#### æ€ç¶­éˆï¼ˆChain of Thought, CoTï¼‰
- ç‰¹é»ï¼šè©³ç´°åˆ†æï¼Œæä¾›æ¨ç†éç¨‹
- é©ç”¨ï¼šè¤‡é›œæ³•å¾‹é‚è¼¯åˆ†ææˆ–éœ€è¦å¤šæ­¥æ¨è«–çš„å•é¡Œ

## ğŸ“¦ éƒ¨ç½²èˆ‡ç™¼å¸ƒ

### PyPI å®‰è£

```bash
pip install hierarchical-rag-retrieval
```

### å¾ GitHub å®‰è£é–‹ç™¼ç‰ˆæœ¬

```bash
pip install git+https://github.com/arthur422tp/hierarchical.git
```

### æœ¬æ©Ÿé–‹ç™¼å®‰è£

```bash
# å…‹éš†å°ˆæ¡ˆ
git clone https://github.com/arthur422tp/hierarchical.git
cd hierarchical

# å®‰è£é–‹ç™¼ä¾è³´
pip install -e .[dev]
```

## ğŸ“š æ›´å¤šè³‡æº

- **GitHub Repository**: https://github.com/arthur422tp/hierarchical
- **arXiv è«–æ–‡**: https://arxiv.org/abs/2506.13607
- **PyPI å¥—ä»¶**: https://pypi.org/project/hierarchical-rag-retrieval/
- **Issue å›å ±**: https://github.com/arthur422tp/hierarchical/issues

## ğŸ¤ è²¢ç»èˆ‡æ”¯æ´

æ­¡è¿æäº¤ Issue å’Œ Pull Requestï¼å¦‚æœæ‚¨åœ¨ä½¿ç”¨éç¨‹ä¸­é‡åˆ°ä»»ä½•å•é¡Œï¼Œæˆ–æœ‰æ”¹é€²å»ºè­°ï¼Œè«‹éš¨æ™‚è¯ç¹«æˆ‘å€‘ã€‚

### é–‹ç™¼ç’°å¢ƒè¨­ç½®

```bash
# å…‹éš†å°ˆæ¡ˆ
git clone https://github.com/arthur422tp/hierarchical.git
cd hierarchical

# å»ºç«‹è™›æ“¬ç’°å¢ƒ
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# å®‰è£é–‹ç™¼ä¾è³´
pip install -e .[dev,app]
```

## ğŸ“œ License

æœ¬å°ˆæ¡ˆæ¡ç”¨ MIT æˆæ¬Šæ¢æ¬¾ - è©³è¦‹ [LICENSE](LICENSE) æª”æ¡ˆã€‚

## ğŸ“ è¯ç¹«æ–¹å¼

- ä½œè€…ï¼šarthur422tp
- Emailï¼šarthur422tp@gmail.com
- GitHubï¼šhttps://github.com/arthur422tp

---

**ç¥æ‚¨ä½¿ç”¨æ„‰å¿«ï¼å¦‚æœé€™å€‹ç³»çµ±å°æ‚¨çš„å°ˆæ¡ˆæœ‰å¹«åŠ©ï¼Œè«‹è€ƒæ…®çµ¦æˆ‘å€‘ä¸€å€‹ â­ Starï¼**


