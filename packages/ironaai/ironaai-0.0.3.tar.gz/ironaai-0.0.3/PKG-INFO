Metadata-Version: 2.1
Name: ironaai
Version: 0.0.3
Summary: IronaAI Python SDK
Author: Irona AI
Author-email: support@irona.ai
Requires-Python: >=3.9,<4.0
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Requires-Dist: langchain-core (>=0.3.59,<0.4.0)
Requires-Dist: litellm (>=1.62.1,<2.0.0)
Requires-Dist: numpydoc (>=1.8.0,<2.0.0)
Requires-Dist: openai (>=1.70.0,<2.0.0)
Requires-Dist: pydantic (>=2.10.6,<3.0.0)
Requires-Dist: pytest (>=8.3.5,<9.0.0)
Requires-Dist: python-dotenv (>=0.19.0,<0.20.0)
Requires-Dist: requests (>=2.26.0,<3.0.0)
Requires-Dist: setuptools (>=75.8.2,<76.0.0)
Description-Content-Type: text/markdown



### API vs SDK
* Client side LLM invocation.
  - Our API endpoint of model-router, only recommends the model to use.
  - The sdk invokes the "recommended model" for the given prompt, gets the response back.

SDK also provides the following features which API endpoint doesn't via a common interface.
##### Features:
- Model routing functionality using the IronaAI API endpoints
- [] Support for async & sync requests of LLM-invocation.
- Function calling,
- Tool binding using LiteLLM's function calling capabilities
- Error handling and retries
- Support for streaming, 
- and JSON mode (i.e. structured output)
- [] Detailed latency tracking and reporting - TBD
- [] Creation of preference IDs - TBD


* Retry logic (invocation or model-router)
* Unified Interface
* Tool binding



Export keys for provider you will use:

```
IRONAAI_API_KEY = "OUR_IRONAI_API_KEY"
OPENAI_API_KEY = "YOUR_OPENAI_API_KEY"
ANTHROPIC_API_KEY = "YOUR_ANTHROPIC_API_KEY"
```

To use this client, you would initialize it like this:

```
client = IronaAI(
    model_list=["openai/gpt-3.5-turbo", "openai/gpt-4", "anthropic/claude-2"],
)
```

You can then use it for completions, function calling, and tool binding:


```
# Regular completion
response = client.completions.create(
    messages=[{"role": "user", "content": "Hello, how are you?"}],
    model_list=["openai/gpt-3.5-turbo", "openai/gpt-4", "anthropic/claude-2"],)

# Function calling
def get_current_weather(location: str, unit: str = "fahrenheit"):
    """Get the current weather in a given location"""
    # Implementation here
    return f"The weather in {location} is 72Â°F."

tools = [
    {
        "name": "get_current_weather",
        "description": "Get the current weather in a given location",
        "parameters": {
            "type": "object",
            "properties": {
                "location": {"type": "string"},
                "unit": {"type": "string", "enum": ["celsius", "fahrenheit"]},
            },
            "required": ["location"],
        },
    }
]

messages = [{"role": "user", "content": "What's the weather like in San Francisco?"}]

# Call the model
response = client.completions.create( messages=messages, tools=tools, tool_choice="auto",)

```


### Install Instructions

```
poetry install .
```

### Push this to PyPi

```
poetry build
poetry publish
```


Then users can simply install the package using pip:

```
pip install ironaai
```


