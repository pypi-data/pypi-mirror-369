name: Feature Branch Tests

on:
  push:
    branches:
      - 'feature/**'

jobs:
  contract-tests:
    name: "Contract Tests (Python ${{ matrix.python-version }}, ${{ matrix.engine == 'anthropic' && 'Claude' || 'OpenAI' }})"
    runs-on: ubuntu-latest
    # Skip if this push is part of an open PR
    if: github.event_name == 'push' && !contains(github.event.head_commit.message, '[skip ci]')
    strategy:
      matrix:
        python-version: ["3.10", "3.11", "3.12"]
        engine: ["openai", "anthropic"]
      fail-fast: false  # Continue testing other combinations if one fails

    steps:
    - name: Check for open PRs
      id: check-prs
      uses: actions/github-script@v7
      with:
        script: |
          const { data: prs } = await github.rest.pulls.list({
            owner: context.repo.owner,
            repo: context.repo.repo,
            head: context.repo.owner + ':' + context.ref.replace('refs/heads/', ''),
            state: 'open'
          });

          if (prs.length > 0) {
            console.log('Found open PRs for this branch, skipping feature tests');
            core.setOutput('has-open-pr', 'true');
          } else {
            console.log('No open PRs found, running feature tests');
            core.setOutput('has-open-pr', 'false');
          }

    - name: Checkout repository
      if: steps.check-prs.outputs.has-open-pr != 'true'
      uses: actions/checkout@v4

    - name: Set up Python ${{ matrix.python-version }}
      if: steps.check-prs.outputs.has-open-pr != 'true'
      uses: actions/setup-python@v5
      with:
        python-version: ${{ matrix.python-version }}

    - name: Cache pip packages
      if: steps.check-prs.outputs.has-open-pr != 'true'
      uses: actions/cache@v4
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ matrix.python-version }}-${{ hashFiles('pyproject.toml') }}
        restore-keys: |
          ${{ runner.os }}-pip-${{ matrix.python-version }}-
          ${{ runner.os }}-pip-

    - name: Install dependencies
      if: steps.check-prs.outputs.has-open-pr != 'true'
      run: |
        python -m pip install --upgrade pip
        pip install pytest pytest-cov pytest-html pydantic
        if [ -f requirements.txt ]; then pip install -r requirements.txt --index-url https://test.pypi.org/simple/ --extra-index-url https://pypi.org/simple/; fi
        pip install ".[dev]"  # Install dev dependencies including linting tools

    - name: Run behavioral contract tests
      if: steps.check-prs.outputs.has-open-pr != 'true'
      run: |
        echo "🧪 Running behavioral contract validation tests..."
        pytest tests/test_contract_validation.py -v --tb=short \
          --junitxml=test-results-contract.xml \
          --html=test-report-contract.html \
          --self-contained-html
        echo "✅ Contract validation tests completed"

    - name: Run multi-engine compatibility tests
      if: steps.check-prs.outputs.has-open-pr != 'true'
      run: |
        echo "🔄 Running multi-engine compatibility tests..."
        pytest tests/test_multi_engine.py -v --tb=short \
          --junitxml=test-results-engine.xml \
          --html=test-report-engine.html \
          --self-contained-html
        echo "✅ Multi-engine tests completed"

    - name: Run engine-specific validation
      if: steps.check-prs.outputs.has-open-pr != 'true'
      run: |
        echo "🔍 Running engine-specific tests for ${{ matrix.engine }}..."
        if [ "${{ matrix.engine }}" = "anthropic" ]; then
          pytest tests/test_generators.py::test_generate_requirements_anthropic -v
          pytest tests/test_generators.py::test_generate_env_example_anthropic -v
          echo "✅ Claude/Anthropic engine validation passed"
        else
          pytest tests/test_generators.py::test_generate_requirements -v
          pytest tests/test_generators.py::test_generate_env_example -v
          echo "✅ OpenAI engine validation passed"
        fi

    - name: Generate comprehensive test report
      if: steps.check-prs.outputs.has-open-pr != 'true'
      run: |
        echo "📊 Generating comprehensive test report..."
        pytest tests/ -v \
          --tb=short \
          --junitxml=test-results-all.xml \
          --html=test-report-all.html \
          --self-contained-html \
          --cov=oas_cli \
          --cov-report=html \
          --cov-report=xml \
          --cov-report=term-missing

    - name: Upload test artifacts
      if: steps.check-prs.outputs.has-open-pr != 'true'
      uses: actions/upload-artifact@v4
      with:
        name: test-results-${{ matrix.python-version }}-${{ matrix.engine }}
        path: |
          test-results-*.xml
          test-report-*.html
          htmlcov/
          coverage.xml
        retention-days: 7

    - name: Post test summary
      if: always() && steps.check-prs.outputs.has-open-pr != 'true'
      run: |
        echo "### ✅ Python ${{ matrix.python-version }} + ${{ matrix.engine == 'anthropic' && 'Claude' || 'OpenAI' }}" >> $GITHUB_STEP_SUMMARY
        echo "All behavioral contract tests passed" >> $GITHUB_STEP_SUMMARY

    - name: Skip message
      if: steps.check-prs.outputs.has-open-pr == 'true'
      run: |
        echo "⏭️ Skipping feature tests - this push is part of an open PR"
        echo "PR workflow will handle testing instead"

  code-quality:
    name: "Code Quality Checks"
    runs-on: ubuntu-latest
    # Skip if this push is part of an open PR
    if: github.event_name == 'push' && !contains(github.event.head_commit.message, '[skip ci]')
    steps:
    - name: Check for open PRs
      id: check-prs
      uses: actions/github-script@v7
      with:
        script: |
          const { data: prs } = await github.rest.pulls.list({
            owner: context.repo.owner,
            repo: context.repo.repo,
            head: context.repo.owner + ':' + context.ref.replace('refs/heads/', ''),
            state: 'open'
          });

          if (prs.length > 0) {
            console.log('Found open PRs for this branch, skipping code quality checks');
            core.setOutput('has-open-pr', 'true');
          } else {
            console.log('No open PRs found, running code quality checks');
            core.setOutput('has-open-pr', 'false');
          }

    - uses: actions/checkout@v4
      if: steps.check-prs.outputs.has-open-pr != 'true'

    - name: Set up Python 3.11
      if: steps.check-prs.outputs.has-open-pr != 'true'
      uses: actions/setup-python@v5
      with:
        python-version: 3.11

    - name: Install linting tools
      if: steps.check-prs.outputs.has-open-pr != 'true'
      run: |
        python -m pip install --upgrade pip
        pip install ".[dev]"


    - name: Run ruff
      if: steps.check-prs.outputs.has-open-pr != 'true'
      run: |
        echo "🔍 Running ruff checks..."
        ruff check . --exclude test_output/
        echo "✅ Ruff checks passed"

    - name: Run mypy
      if: steps.check-prs.outputs.has-open-pr != 'true'
      run: |
        echo "🔍 Running mypy type checks..."
        mypy oas_cli tests || true  # Allow mypy to fail for now
        echo "✅ Type checking completed"

    - name: Skip message
      if: steps.check-prs.outputs.has-open-pr == 'true'
      run: |
        echo "⏭️ Skipping code quality checks - this push is part of an open PR"
        echo "PR workflow will handle code quality checks instead"

  test-summary:
    name: "Test Summary"
    needs: [contract-tests, code-quality]
    runs-on: ubuntu-latest
    if: always()

    steps:
    - name: Check overall results
      run: |
        if [[ "${{ needs.contract-tests.result }}" == "success" && "${{ needs.code-quality.result }}" == "success" ]]; then
          echo "✅ All tests and quality checks passed!"
          echo "🎉 Open Agent Stack behavioral contract validation successful"
          echo "📊 Tested across Python 3.10, 3.11, 3.12"
          echo "🔄 Validated both OpenAI and Claude engine support"
          echo "🛡️ Behavioral contracts working correctly"
          echo "✨ Code quality standards met"
        elif [[ "${{ needs.contract-tests.result }}" == "skipped" && "${{ needs.code-quality.result }}" == "skipped" ]]; then
          echo "⏭️ Tests skipped - this push is part of an open PR"
          echo "PR workflow will handle testing instead"
        else
          echo "❌ Some tests or quality checks failed"
          echo "Please check the results above"
          exit 1
        fi

    - name: Post comprehensive summary
      run: |
        echo "## Open Agent Stack Test Summary" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        if [[ "${{ needs.contract-tests.result }}" == "skipped" && "${{ needs.code-quality.result }}" == "skipped" ]]; then
          echo "### ⏭️ Tests Skipped" >> $GITHUB_STEP_SUMMARY
          echo "This push is part of an open PR. PR workflow will handle testing instead." >> $GITHUB_STEP_SUMMARY
        else
          echo "### 📊 Test Matrix Results" >> $GITHUB_STEP_SUMMARY
          echo "- **Python Versions Tested:** 3.10, 3.11, 3.12" >> $GITHUB_STEP_SUMMARY
          echo "- **Engines Validated:** OpenAI, Claude/Anthropic" >> $GITHUB_STEP_SUMMARY
          echo "- **Total Combinations:** 6 (3 Python × 2 Engines)" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### 🧪 Test Suite Coverage" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "#### Behavioral Contract Tests (9 tests)" >> $GITHUB_STEP_SUMMARY
          echo "- ✅ Temperature control enforcement (0.1-0.5 range)" >> $GITHUB_STEP_SUMMARY
          echo "- ✅ Required fields validation" >> $GITHUB_STEP_SUMMARY
          echo "- ✅ Type safety checks" >> $GITHUB_STEP_SUMMARY
          echo "- ✅ Confidence bounds (0.0-1.0)" >> $GITHUB_STEP_SUMMARY
          echo "- ✅ JSON parsing robustness" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "#### Multi-Engine Compatibility Tests (11 tests)" >> $GITHUB_STEP_SUMMARY
          echo "- ✅ OpenAI/Claude API integration" >> $GITHUB_STEP_SUMMARY
          echo "- ✅ Response parsing consistency" >> $GITHUB_STEP_SUMMARY
          echo "- ✅ Error handling validation" >> $GITHUB_STEP_SUMMARY
          echo "- ✅ Mock-based testing (zero API costs)" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "#### Code Generation Tests (10+ tests)" >> $GITHUB_STEP_SUMMARY
          echo "- ✅ Agent file generation" >> $GITHUB_STEP_SUMMARY
          echo "- ✅ Requirements.txt creation" >> $GITHUB_STEP_SUMMARY
          echo "- ✅ Environment configuration" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### 🛡️ Contract Validation Features" >> $GITHUB_STEP_SUMMARY
          echo "The behavioral contracts ensure:" >> $GITHUB_STEP_SUMMARY
          echo "- Consistent security-focused temperature settings" >> $GITHUB_STEP_SUMMARY
          echo "- Mandatory risk assessment and recommendations" >> $GITHUB_STEP_SUMMARY
          echo "- Validated confidence levels for all responses" >> $GITHUB_STEP_SUMMARY
          echo "- Safe content generation with harmful content checks" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### 📁 Generated Reports" >> $GITHUB_STEP_SUMMARY
          echo "- Contract Test Reports: \`test-report-contract.html\`" >> $GITHUB_STEP_SUMMARY
          echo "- Engine Test Reports: \`test-report-engine.html\`" >> $GITHUB_STEP_SUMMARY
          echo "- Coverage Reports: \`htmlcov/index.html\`" >> $GITHUB_STEP_SUMMARY
        fi
