import os
import sys
import json
import argparse
import asyncio
import platform
from typing import Any, Dict, List, Tuple
from contextlib import AsyncExitStack
from getpass import getpass
import re
import time
import httpx
import pandas as pd
from bs4 import BeautifulSoup
import glob
import html

try:
    import qrcode
except ImportError:
    qrcode = None

from mcp import ClientSession, StdioServerParameters
from mcp.client.stdio import stdio_client

try:
	from openai import OpenAI
except ImportError:
	print("Please install dependencies with: pip install -r requirements.txt", file=sys.stderr)
	raise


class ConnectedServer:
	def __init__(self, name: str, session: ClientSession, tools: List[Any]):
		self.name = name
		self.session = session
		self.tools = tools


async def open_all_servers(servers_cfg: List[Dict[str, Any]]) -> Tuple[List[ConnectedServer], AsyncExitStack]:
	stack = AsyncExitStack()
	await stack.__aenter__()
	connected: List[ConnectedServer] = []
	for server_cfg in servers_cfg:
		name = server_cfg["name"]
		params = StdioServerParameters(
			command=server_cfg["command"],
			args=server_cfg.get("args", []),
			env=server_cfg.get("env", None),
		)
		read, write = await stack.enter_async_context(stdio_client(params))
		session: ClientSession = await stack.enter_async_context(ClientSession(read, write))
		await session.initialize()
		tools_resp = await session.list_tools()
		tools = tools_resp.tools if hasattr(tools_resp, 'tools') else tools_resp
		connected.append(ConnectedServer(name=name, session=session, tools=tools))
	return connected, stack


def extract_tool_fields(raw_tool: Any) -> Tuple[str, str, Dict[str, Any]]:
	name: str | None = None
	description: str | None = None
	parameters: Dict[str, Any] | None = None
	
	# dict-form
	if isinstance(raw_tool, dict):
		name = raw_tool.get("name") or raw_tool.get("tool")
		description = raw_tool.get("description")
		parameters = (
			raw_tool.get("input_schema")
			or raw_tool.get("inputSchema")
			or raw_tool.get("parameters")
		)
	# object-form (åŒ…æ‹¬ mcp.types.Tool)
	else:
		if hasattr(raw_tool, "name") and isinstance(getattr(raw_tool, "name"), str):
			name = getattr(raw_tool, "name")
		elif hasattr(raw_tool, "tool") and isinstance(getattr(raw_tool, "tool"), str):
			name = getattr(raw_tool, "tool")
		if hasattr(raw_tool, "description"):
			description = getattr(raw_tool, "description")
		# æ£€æŸ¥ inputSchema å±žæ€§
		if hasattr(raw_tool, "inputSchema"):
			parameters = getattr(raw_tool, "inputSchema")
		else:
			for attr in ("input_schema", "inputSchema", "parameters", "schema"):
				if hasattr(raw_tool, attr):
					candidate = getattr(raw_tool, attr)
					if isinstance(candidate, dict):
						parameters = candidate
	# tuple/list-form best-effort
	if name is None and isinstance(raw_tool, (list, tuple)):
		if len(raw_tool) >= 1 and isinstance(raw_tool[0], str):
			name = raw_tool[0]
		if len(raw_tool) >= 2 and isinstance(raw_tool[1], dict) and parameters is None:
			parameters = raw_tool[1]
		if len(raw_tool) >= 3 and isinstance(raw_tool[2], str) and description is None:
			description = raw_tool[2]
	
	if parameters is None:
		parameters = {"type": "object", "properties": {}}
	
	final_name = name or "tool"
	return final_name, (description or f"MCP tool {final_name}"), parameters


def builtin_tools() -> List[Dict[str, Any]]:
	return [
		{
			"type": "function",
			"function": {
				"name": "fsx.list_dir",
				"description": "åˆ—å‡ºç›®å½•ä¸‹çš„æ–‡ä»¶ï¼ˆè‡ªåŠ¨è§£æž ~ ç›¸å¯¹è·¯å¾„ç­‰ï¼Œå—å®‰å…¨ç™½åå•é™åˆ¶ï¼‰",
				"parameters": {
					"type": "object",
					"properties": {
						"path": {"type": "string", "description": "ç›®å½•è·¯å¾„ï¼Œå¯ç”¨ ~ã€ç›¸å¯¹è·¯å¾„æˆ–ç»å¯¹è·¯å¾„"}
					},
					"required": ["path"],
					"additionalProperties": False
				}
			}
		},
		{
			"type": "function",
			"function": {
				"name": "fsx.glob",
				"description": "æŒ‰ glob æ¨¡å¼åŒ¹é…æ–‡ä»¶ï¼Œè¿”å›žåŒ¹é…åˆ—è¡¨ï¼ˆå—å®‰å…¨ç™½åå•é™åˆ¶ï¼‰",
				"parameters": {
					"type": "object",
					"properties": {
						"pattern": {"type": "string", "description": "å¦‚ ~/Desktop/*.txt æˆ– ç›¸å¯¹è·¯å¾„æ¨¡å¼"},
						"limit": {"type": "number", "description": "æœ€å¤šè¿”å›žæ¡ç›®æ•°ï¼Œé»˜è®¤200"}
					},
					"required": ["pattern"],
					"additionalProperties": False
				}
			}
		},
		{
			"type": "function",
			"function": {
				"name": "fsx.read_text",
				"description": "è¯»å–æ–‡æœ¬æ–‡ä»¶ï¼ˆå—å®‰å…¨ç™½åå•é™åˆ¶ï¼‰",
				"parameters": {
					"type": "object",
					"properties": {
						"path": {"type": "string"},
						"maxBytes": {"type": "number", "description": "æœ€å¤§è¯»å–å­—èŠ‚æ•°ï¼Œé»˜è®¤1048576"},
						"encoding": {"type": "string", "description": "æŒ‡å®šç¼–ç ï¼Œé»˜è®¤è‡ªåŠ¨"}
					},
					"required": ["path"],
					"additionalProperties": False
				}
			}
		},
		{
			"type": "function",
			"function": {
				"name": "fsx.search",
				"description": "åœ¨ç›®å½•ä¸­æœç´¢æ–‡æœ¬ï¼Œè¿”å›žåŒ¹é…æ–‡ä»¶ä¸Žè¡Œï¼ˆå—å®‰å…¨ç™½åå•é™åˆ¶ï¼‰",
				"parameters": {
					"type": "object",
					"properties": {
						"root": {"type": "string", "description": "æœç´¢æ ¹ç›®å½•"},
						"query": {"type": "string"},
						"regex": {"type": "boolean", "description": "æ˜¯å¦æŒ‰æ­£åˆ™åŒ¹é…ï¼Œé»˜è®¤false"},
						"limit": {"type": "number", "description": "æœ€å¤šè¿”å›žå¤šå°‘æ¡åŒ¹é…ï¼Œé»˜è®¤200"}
					},
					"required": ["root", "query"],
					"additionalProperties": False
				}
			}
		},
		{
			"type": "function",
			"function": {
				"name": "web.search",
				"description": "åŸºç¡€ç½‘é¡µæœç´¢ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼Œå»ºè®®ä¼˜å…ˆä½¿ç”¨websearch.searchï¼‰",
				"parameters": {
					"type": "object",
					"properties": {
						"query": {"type": "string", "description": "æœç´¢å…³é”®è¯"},
						"engine": {"type": "string", "description": "æœç´¢å¼•æ“Žï¼šduckduckgo/google", "default": "duckduckgo"},
						"count": {"type": "number", "description": "ç»“æžœæ•°é‡ï¼Œé»˜è®¤5", "default": 5}
					},
					"required": ["query"],
					"additionalProperties": False
				}
			}
		},
		{
			"type": "function",
			"function": {
				"name": "web.search_serper",
				"description": "ä½¿ç”¨Serper APIè¿›è¡ŒGoogleæœç´¢ï¼ˆéœ€è¦API Keyï¼‰",
				"parameters": {
					"type": "object",
					"properties": {
						"query": {"type": "string"},
						"api_key": {"type": "string", "description": "Serper API Key"}
					},
					"required": ["query", "api_key"],
					"additionalProperties": False
				}
			}
		},
		{
			"type": "function",
			"function": {
				"name": "web.scrape_images",
				"description": "ä¸‹è½½ç½‘é¡µä¸­çš„æ‰€æœ‰å›¾ç‰‡åˆ°æŒ‡å®šç›®å½•ï¼Œå¹¶æŒ‰æ—¥æœŸé‡å‘½å",
				"parameters": {
					"type": "object",
					"properties": {
						"url": {"type": "string"},
						"dest": {"type": "string", "description": "ä¿å­˜ç›®å½•"}
					},
					"required": ["url", "dest"],
					"additionalProperties": False
				}
			}
		},
		{
			"type": "function",
			"function": {
				"name": "fsx.organize_by_type",
				"description": "å°†ç›®å½•ä¸‹æ–‡ä»¶æŒ‰æ‰©å±•åæ•´ç†åˆ°å­æ–‡ä»¶å¤¹",
				"parameters": {
					"type": "object",
					"properties": {"path": {"type": "string"}},
					"required": ["path"],
					"additionalProperties": False
				}
			}
		},
		{
			"type": "function",
			"function": {
				"name": "data.csv_merge",
				"description": "åˆå¹¶å¤šä¸ª CSV ä¸­çš„æŒ‡å®šåˆ—ä¸ºä¸€ä¸ªè¡¨æ ¼",
				"parameters": {
					"type": "object",
					"properties": {
						"pattern": {"type": "string", "description": "glob æ¨¡å¼ï¼Œå¦‚ ~/data/*.csv"},
						"columns": {"type": "array", "items": {"type": "string"}}
					},
					"required": ["pattern"],
					"additionalProperties": False
				}
			}
		},
		{
			"type": "function",
			"function": {
				"name": "data.excel_summary",
				"description": "åˆ†æž Excel é”€å”®æ•°æ®ï¼Œè¾“å‡ºå…³é”®æ±‡æ€»",
				"parameters": {
					"type": "object",
					"properties": {"path": {"type": "string"}, "sheet": {"type": "string"}},
					"required": ["path"],
					"additionalProperties": False
				}
			}
		},
		{
			"type": "function",
			"function": {
				"name": "code.quick_inspect",
				"description": "å¿«é€Ÿæ‰«æç›®å½•ä¸­çš„ä»£ç æ–‡ä»¶ï¼Œç»™å‡ºè¯­è¨€ã€æ¨¡å—ä¸Žä¾èµ–åˆæ­¥æŠ¥å‘Š",
				"parameters": {
					"type": "object",
					"properties": {"path": {"type": "string"}},
					"required": ["path"],
					"additionalProperties": False
				}
			}
		}
	]


def build_openai_tools(servers: List[ConnectedServer]) -> List[Dict[str, Any]]:
	openai_tools: List[Dict[str, Any]] = []
	for s in servers:
		for raw in s.tools:
			tool_name, description, parameters = extract_tool_fields(raw)
			openai_tools.append(
				{
					"type": "function",
					"function": {
						"name": f"{s.name}.{tool_name}",
						"description": description,
						"parameters": parameters,
					},
				}
			)
	# Append builtin synthetic tools
	openai_tools.extend(builtin_tools())
	return openai_tools


def make_invoker(servers: List[ConnectedServer]):
	index: Dict[str, Tuple[ClientSession, str]] = {}
	for s in servers:
		for raw in s.tools:
			tool_name, _, _ = extract_tool_fields(raw)
			full_name = f"{s.name}.{tool_name}"
			index[full_name] = (s.session, tool_name)
	
	async def invoke(full_name: str, args: Dict[str, Any]) -> Any:
		if full_name not in index:
			raise RuntimeError(f"Tool not found: {full_name}")
		session, tool = index[full_name]
		try:
			result = await session.call_tool(tool, arguments=args or {})
			return result
		except Exception as e:
			# å¦‚æžœç¬¬ä¸€æ¬¡è°ƒç”¨å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨ input æ ¼å¼
			try:
				result = await session.call_tool(tool, arguments={"input": args or {}})
				return result
			except Exception as e2:
				# å¦‚æžœä¸¤ç§æ ¼å¼éƒ½å¤±è´¥ï¼Œè¿”å›žé”™è¯¯ä¿¡æ¯
				return {"error": f"å·¥å…·è°ƒç”¨å¤±è´¥: {str(e2)}", "tool": full_name, "args": args}

	return invoke


def to_json_safe(obj: Any) -> Any:
	# Already serializable primitives
	if obj is None or isinstance(obj, (bool, int, float, str)):
		return obj
	# MCP CallToolResult objects
	if hasattr(obj, "content"):
		content = obj.content
		if hasattr(content, "text"):
			return content.text
		else:
			return str(content)
	# Pydantic v2 models
	if hasattr(obj, "model_dump_json"):
		try:
			return json.loads(obj.model_dump_json())
		except Exception:
			pass
	if hasattr(obj, "model_dump"):
		try:
			return to_json_safe(obj.model_dump())
		except Exception:
			pass
	# Common dict/list
	if isinstance(obj, dict):
		return {k: to_json_safe(v) for k, v in obj.items()}
	if isinstance(obj, (list, tuple)):
		return [to_json_safe(v) for v in obj]
	# Fallbacks
	if hasattr(obj, "dict"):
		try:
			return to_json_safe(obj.dict())
		except Exception:
			pass
	if hasattr(obj, "__dict__"):
		try:
			return to_json_safe(vars(obj))
		except Exception:
			pass
	return repr(obj)


def safe_parse_json(s: str) -> Dict[str, Any]:
	if not s:
		return {}
	try:
		return json.loads(s)
	except Exception:
		return {}


def render_markdown(text: str) -> str:
	"""æ¸²æŸ“ Markdown æ ¼å¼æ–‡æœ¬ä¸ºå¸¦é¢œè‰²çš„ç»ˆç«¯è¾“å‡º"""
	if not text:
		return ""
	
	# é¢œè‰²ä»£ç 
	colors = {
		'bold': '\033[1m',
		'red': '\033[91m',
		'green': '\033[92m',
		'yellow': '\033[93m',
		'blue': '\033[94m',
		'magenta': '\033[95m',
		'cyan': '\033[96m',
		'gray': '\033[90m',
		'reset': '\033[0m',
		'bg_blue': '\033[44m',
		'bg_green': '\033[42m',
		'bg_yellow': '\033[43m',
		'bg_red': '\033[41m'
	}
	
	# å¤„ç†æ ‡é¢˜
	text = re.sub(r'^### (.*?)$', rf'{colors["bold"]}{colors["cyan"]}### \1{colors["reset"]}', text, flags=re.MULTILINE)
	text = re.sub(r'^## (.*?)$', rf'{colors["bold"]}{colors["blue"]}## \1{colors["reset"]}', text, flags=re.MULTILINE)
	text = re.sub(r'^# (.*?)$', rf'{colors["bold"]}{colors["magenta"]}# \1{colors["reset"]}', text, flags=re.MULTILINE)
	
	# å¤„ç†ç²—ä½“
	text = re.sub(r'\*\*(.*?)\*\*', rf'{colors["bold"]}\1{colors["reset"]}', text)
	text = re.sub(r'__(.*?)__', rf'{colors["bold"]}\1{colors["reset"]}', text)
	
	# å¤„ç†æ–œä½“
	text = re.sub(r'\*(.*?)\*', rf'{colors["cyan"]}\1{colors["reset"]}', text)
	text = re.sub(r'_(.*?)_', rf'{colors["cyan"]}\1{colors["reset"]}', text)
	
	# å¤„ç†ä»£ç å—
	text = re.sub(r'```(\w+)?\n(.*?)```', rf'{colors["bg_blue"]}\2{colors["reset"]}', text, flags=re.DOTALL)
	text = re.sub(r'`([^`]+)`', rf'{colors["bg_green"]}\1{colors["reset"]}', text)
	
	# å¤„ç†é“¾æŽ¥
	text = re.sub(r'\[([^\]]+)\]\(([^)]+)\)', rf'{colors["blue"]}\1{colors["reset"]} ({colors["cyan"]}\2{colors["reset"]})', text)
	
	# å¤„ç†åˆ—è¡¨
	text = re.sub(r'^(\s*)[-*+] (.*?)$', rf'\1{colors["yellow"]}â€¢{colors["reset"]} \2', text, flags=re.MULTILINE)
	text = re.sub(r'^(\s*)(\d+)\. (.*?)$', rf'\1{colors["yellow"]}\2.{colors["reset"]} \3', text, flags=re.MULTILINE)
	
	# å¤„ç†å¼•ç”¨
	text = re.sub(r'^> (.*?)$', rf'{colors["gray"]}> \1{colors["reset"]}', text, flags=re.MULTILINE)
	
	# å¤„ç†è¡¨æ ¼åˆ†éš”çº¿
	text = re.sub(r'^\|[-|:]+\|$', rf'{colors["gray"]}\0{colors["reset"]}', text, flags=re.MULTILINE)
	
	# å¤„ç†è¡¨æ ¼è¡Œ
	text = re.sub(r'^\|(.*?)\|$', rf'{colors["gray"]}|\1|{colors["reset"]}', text, flags=re.MULTILINE)
	
	# å¤„ç†æ°´å¹³çº¿
	text = re.sub(r'^---$', rf'{colors["gray"]}{"â”€" * 50}{colors["reset"]}', text, flags=re.MULTILINE)
	text = re.sub(r'^___$', rf'{colors["gray"]}{"â”€" * 50}{colors["reset"]}', text, flags=re.MULTILINE)
	
	return text


def format_table(data: List[Dict[str, Any]], title: str = "") -> str:
	"""æ ¼å¼åŒ–æ•°æ®ä¸º Markdown è¡¨æ ¼"""
	if not data:
		return ""
	
	# èŽ·å–æ‰€æœ‰åˆ—
	columns = list(data[0].keys()) if data else []
	
	# æž„å»ºè¡¨æ ¼
	table = []
	if title:
		table.append(f"## {title}")
		table.append("")
	
	# è¡¨å¤´
	header = "| " + " | ".join(columns) + " |"
	table.append(header)
	
	# åˆ†éš”çº¿
	separator = "| " + " | ".join(["---"] * len(columns)) + " |"
	table.append(separator)
	
	# æ•°æ®è¡Œ
	for row in data:
		row_str = "| " + " | ".join(str(row.get(col, "")) for col in columns) + " |"
		table.append(row_str)
	
	return "\n".join(table)


def format_list(items: List[str], title: str = "", style: str = "bullet") -> str:
	"""æ ¼å¼åŒ–åˆ—è¡¨"""
	if not items:
		return ""
	
	result = []
	if title:
		result.append(f"## {title}")
		result.append("")
	
	if style == "bullet":
		for item in items:
			result.append(f"- {item}")
	elif style == "number":
		for i, item in enumerate(items, 1):
			result.append(f"{i}. {item}")
	
	return "\n".join(result)


def format_code_block(code: str, language: str = "") -> str:
	"""æ ¼å¼åŒ–ä»£ç å—"""
	if language:
		return f"```{language}\n{code}\n```"
	else:
		return f"```\n{code}\n```"


def show_logo() -> None:
	"""æ˜¾ç¤º Mo MCP çš„ ASCII è‰ºæœ¯ LOGO"""
	colors = {
		'bold': '\033[1m',
		'red': '\033[91m',
		'green': '\033[92m',
		'yellow': '\033[93m',
		'blue': '\033[94m',
		'magenta': '\033[95m',
		'cyan': '\033[96m',
		'white': '\033[97m',
		'reset': '\033[0m'
	}
	
	# èŽ·å–ç³»ç»Ÿä¿¡æ¯
	system_info = get_system_info()
	
	logo = f"""
{colors['bold']}{colors['cyan']}
 __       __                  __       __   ______   _______  
/  \     /  |                /  \     /  | /      \ /       \ 
$$  \   /$$ |  ______        $$  \   /$$ |/$$$$$$  |$$$$$$$  |
$$$  \ /$$$ | /      \       $$$  \ /$$$ |$$ |  $$/ $$ |__$$ |
$$$$  /$$$$ |/$$$$$$  |      $$$$  /$$$$ |$$ |      $$    $$/ 
$$ $$ $$/$$ |$$ |  $$ |      $$ $$ $$/$$ |$$ |   __ $$$$$$$/  
$$ |$$$/ $$ |$$ \__$$ |      $$ |$$$/ $$ |$$ \__/  |$$ |      
$$ | $/  $$ |$$    $$/       $$ | $/  $$ |$$    $$/ $$ |      
$$/      $$/  $$$$$$/        $$/      $$/  $$$$$$/  $$/       
{colors['reset']}
{colors['bold']}{colors['blue']}â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—{colors['reset']}
{colors['bold']}{colors['blue']}â•‘                    ðŸš€ æ™ºèƒ½å‘½ä»¤è¡ŒåŠ©æ‰‹ - åŸºäºŽé€šä¹‰åƒé—®                      â•‘{colors['reset']}
{colors['bold']}{colors['blue']}â•‘                    ðŸ”§ æ”¯æŒ MCP åè®®çš„å¤šå·¥å…·é›†æˆå¹³å°                      â•‘{colors['reset']}
{colors['bold']}{colors['blue']}â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•{colors['reset']}

{colors['yellow']}âœ¨ ç‰¹æ€§ï¼š{colors['reset']} è‡ªç„¶è¯­è¨€äº¤äº’ | å¤šå·¥å…·æ”¯æŒ | è¿žç»­å¯¹è¯ | Markdown æ¸²æŸ“
{colors['green']}ðŸ”§ å·¥å…·ï¼š{colors['reset']} æ–‡ä»¶ç³»ç»Ÿ | ç½‘ç»œæœç´¢ | æ•°æ®åˆ†æž | ä»£ç æ£€æŸ¥
{colors['magenta']}ðŸ’¡ æç¤ºï¼š{colors['reset']} è¾“å…¥ /help æŸ¥çœ‹æ‰€æœ‰å¯ç”¨å‘½ä»¤

{colors['cyan']}{'â”€' * 70}{colors['reset']}
{colors['bold']}{colors['blue']}ðŸ–¥ï¸  ç³»ç»Ÿï¼š{colors['reset']} {system_info['icon']} {system_info['name']} {system_info['release']} ({system_info['machine']})
{colors['cyan']}{'â”€' * 70}{colors['reset']}
"""
	
	print(logo)


def get_system_info() -> Dict[str, str]:
	"""èŽ·å–ç³»ç»Ÿä¿¡æ¯"""
	system = platform.system().lower()
	release = platform.release()
	machine = platform.machine()
	
	# ç³»ç»Ÿå›¾æ ‡æ˜ å°„
	system_icons = {
		'darwin': 'ðŸŽ',      # macOS
		'windows': 'ðŸªŸ',     # Windows
		'linux': 'ðŸ§',       # Linux
	}
	
	# ç³»ç»Ÿåç§°æ˜ å°„
	system_names = {
		'darwin': 'macOS',
		'windows': 'Windows',
		'linux': 'Linux',
	}
	
	return {
		'icon': system_icons.get(system, 'ðŸ’»'),
		'name': system_names.get(system, system.title()),
		'release': release,
		'machine': machine,
		'raw_system': system
	}


def expand_path(p: str) -> str:
	if os.name == 'nt' and p.startswith('~'):
		user_profile = os.environ.get('USERPROFILE', '')
		if user_profile:
			p = p.replace('~', user_profile, 1)
		else:
			username = os.environ.get('USERNAME', '')
			if username:
				p = p.replace('~', f'C:\\Users\\{username}', 1)
	else:
		p = os.path.expanduser(p)
	
	if not os.path.isabs(p):
		p = os.path.abspath(os.path.join(os.getcwd(), p))
	return os.path.realpath(p)


def get_allowed_roots_from_config(config: Dict[str, Any]) -> List[str]:
	roots: List[str] = []
	for srv in config.get("servers", []):
		args = srv.get("args", [])
		for a in args:
			if isinstance(a, str) and (a.startswith("/") or a.startswith("~") or a.startswith("C:\\")):
				expanded_path = expand_path(a)
				roots.append(expanded_path)
	
	# å¦‚æžœæ²¡æœ‰é…ç½®è·¯å¾„ï¼Œä½¿ç”¨å½“å‰å·¥ä½œç›®å½•
	if not roots:
		roots.append(os.getcwd())
	
	return sorted(set(roots))


def is_path_allowed(path: str, allowed_roots: List[str]) -> bool:
	rp = os.path.realpath(path)
	for root in allowed_roots:
		try:
			if os.path.commonpath([rp, root]) == root:
				return True
		except Exception:
			continue
	return False

def resolve_under_roots(path: str, allowed_roots: List[str]) -> Tuple[str, bool, str | None]:
	rp = expand_path(path)
	if is_path_allowed(rp, allowed_roots):
		return rp, True, None
	if not os.path.isabs(path) and allowed_roots:
		candidate = os.path.realpath(os.path.join(allowed_roots[0], path))
		return candidate, is_path_allowed(candidate, allowed_roots), None if is_path_allowed(candidate, allowed_roots) else allowed_roots[0]
	if os.path.isabs(path) and allowed_roots:
		suggestion = os.path.realpath(os.path.join(allowed_roots[0], os.path.basename(path)))
		return rp, False, suggestion
	return rp, False, None


def write_api_key_to_config(config_path: str, api_key: str) -> None:
	# ç¡®ä¿ç›®å½•å­˜åœ¨
	dir_path = os.path.dirname(config_path)
	if dir_path and not os.path.exists(dir_path):
		os.makedirs(dir_path, exist_ok=True)
	# è¯»å–æˆ–åˆ›å»ºé…ç½®
	try:
		with open(config_path, "r", encoding="utf-8") as f:
			data = json.load(f)
	except FileNotFoundError:
		data = {}
	model = data.get("model") or {}
	model["apiKey"] = api_key
	data["model"] = model
	with open(config_path, "w", encoding="utf-8") as f:
		json.dump(data, f, ensure_ascii=False, indent=1)


def create_qr_code_ascii(text: str, size: int = 1) -> str:
	"""åˆ›å»ºASCIIå­—ç¬¦äºŒç»´ç """
	if qrcode is None:
		return "âŒ äºŒç»´ç åŠŸèƒ½æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install qrcode[pil]"
	
	qr = qrcode.QRCode(
		version=1,
		error_correction=qrcode.constants.ERROR_CORRECT_L,
		box_size=size,
		border=2,
	)
	qr.add_data(text)
	qr.make(fit=True)
	
	# èŽ·å–äºŒç»´ç çŸ©é˜µ
	matrix = qr.get_matrix()
	
	# è½¬æ¢ä¸ºASCIIå­—ç¬¦
	ascii_qr = ""
	for row in matrix:
		for cell in row:
			ascii_qr += "â–ˆâ–ˆ" if cell else "  "
		ascii_qr += "\n"
	
	return ascii_qr


def show_recharge_qr() -> None:
	"""æ˜¾ç¤ºé€šä¹‰åƒé—®å……å€¼äºŒç»´ç """
	recharge_url = "https://billing-cost.console.aliyun.com/fortune/fund-management/recharge"
	
	colors = {
		'bold': '\033[1m',
		'blue': '\033[94m',
		'cyan': '\033[96m',
		'green': '\033[92m',
		'yellow': '\033[93m',
		'red': '\033[91m',
		'magenta': '\033[95m',
		'reset': '\033[0m'
	}
	
	print(f"\n{colors['bold']}{colors['blue']}=== é€šä¹‰åƒé—®ä½™é¢å……å€¼ ==={colors['reset']}")
	print(f"{colors['yellow']}ðŸ“± è¯·ä½¿ç”¨æ‰‹æœºæ‰«æä¸‹æ–¹äºŒç»´ç è¿›è¡Œå……å€¼{colors['reset']}")
	print(f"{colors['cyan']}ðŸ’³ å……å€¼åœ°å€: {recharge_url}{colors['reset']}")
	print()
	
	# ç”Ÿæˆå¹¶æ˜¾ç¤ºäºŒç»´ç 
	qr_code = create_qr_code_ascii(recharge_url, size=1)
	print(qr_code)
	
	print(f"{colors['green']}âœ… æ‰«æäºŒç»´ç åŽï¼Œè¯·åœ¨æµè§ˆå™¨ä¸­å®Œæˆå……å€¼æ“ä½œ{colors['reset']}")
	print(f"{colors['yellow']}ðŸ’¡ å……å€¼å®ŒæˆåŽï¼Œæ‚¨å°±å¯ä»¥æ­£å¸¸ä½¿ç”¨é€šä¹‰åƒé—®APIäº†{colors['reset']}")


def show_customer_service_qr() -> None:
	"""æ˜¾ç¤ºå®¢æœè”ç³»äºŒç»´ç """
	cs_url = "https://cs.andyjin.website"
	
	colors = {
		'bold': '\033[1m',
		'blue': '\033[94m',
		'cyan': '\033[96m',
		'green': '\033[92m',
		'yellow': '\033[93m',
		'red': '\033[91m',
		'magenta': '\033[95m',
		'reset': '\033[0m'
	}
	
	print(f"\n{colors['bold']}{colors['blue']}=== å®¢æœæ”¯æŒ ==={colors['reset']}")
	print(f"{colors['yellow']}ðŸ“± è¯·ä½¿ç”¨æ‰‹æœºæ‰«æä¸‹æ–¹äºŒç»´ç è”ç³»å®¢æœ{colors['reset']}")
	print(f"{colors['cyan']}ðŸ’¬ å®¢æœåœ°å€: {cs_url}{colors['reset']}")
	print()
	
	# ç”Ÿæˆå¹¶æ˜¾ç¤ºäºŒç»´ç 
	qr_code = create_qr_code_ascii(cs_url, size=1)
	print(qr_code)
	
	print(f"{colors['green']}âœ… æ‰«æäºŒç»´ç åŽï¼Œæ‚¨å¯ä»¥é€šè¿‡å®¢æœèŽ·å¾—æŠ€æœ¯æ”¯æŒ{colors['reset']}")
	print(f"{colors['yellow']}ðŸ’¡ é‡åˆ°é—®é¢˜ï¼Ÿå®¢æœä¼šä¸ºæ‚¨æä¾›ä¸“ä¸šå¸®åŠ©{colors['reset']}")
	print(f"{colors['magenta']}ðŸ“§ æ”¯æŒé—®é¢˜åé¦ˆã€åŠŸèƒ½å»ºè®®ã€ä½¿ç”¨æŒ‡å¯¼ç­‰{colors['reset']}")


def write_model_to_config(config_path: str, model_name: str) -> None:
	try:
		with open(config_path, "r", encoding="utf-8") as f:
			data = json.load(f)
	except FileNotFoundError:
		data = {}
	model = data.get("model") or {}
	model["model"] = model_name
	data["model"] = model
	with open(config_path, "w", encoding="utf-8") as f:
		json.dump(data, f, ensure_ascii=False, indent=1)


def interactive_api_key_setup(config_path: str, current_key: str | None) -> str:
	print("API å¯†é’¥é…ç½®é€‰é¡¹ï¼š")
	print("1) ä»…æœ¬æ¬¡ä½¿ç”¨ï¼ˆä¸ä¿å­˜åˆ°æ–‡ä»¶ï¼‰")
	print(f"2) ä¿å­˜åˆ°é…ç½®æ–‡ä»¶ï¼š{config_path}")
	print("3) å–æ¶ˆ")
	while True:
		choice = input("è¯·é€‰æ‹© [1/2/3]: ").strip()
		if choice not in {"1", "2", "3"}:
			continue
		if choice == "3":
			print("å·²å–æ¶ˆã€‚")
			sys.exit(1)
		api_key = getpass("è¯·è¾“å…¥ DashScope API Keyï¼ˆè¾“å…¥ä¸å¯è§ï¼‰ï¼š").strip()
		if not api_key:
			print("å¯†é’¥ä¸èƒ½ä¸ºç©ºã€‚")
			continue
		if choice == "2":
			write_api_key_to_config(config_path, api_key)
			print("å·²å†™å…¥é…ç½®æ–‡ä»¶ã€‚")
		return api_key

async def handle_builtin_tool(name: str, args: Dict[str, Any], allowed_roots: List[str]) -> Any:
	if name == "fsx.list_dir":
		raw = args.get("path", "")
		path, allowed, suggestion = resolve_under_roots(raw, allowed_roots)
		if not allowed:
			return {"error": f"è¶Šè¿‡å…è®¸ç›®å½•: {path}", "suggestion": suggestion, "allowedRoots": allowed_roots}
		if not os.path.isdir(path):
			return {"error": f"è·¯å¾„ä¸æ˜¯ç›®å½•: {path}"}
		items = []
		try:
			for entry in os.scandir(path):
				items.append({
					"name": entry.name,
					"type": "dir" if entry.is_dir() else "file",
					"size": entry.stat().st_size if entry.is_file() else None
				})
			return {"path": path, "items": items}
		except Exception as e:
			return {"error": str(e), "path": path}
	elif name == "fsx.glob":
		pattern = args.get("pattern", "")
		limit = int(args.get("limit", 200))
		# æ”¯æŒç›¸å¯¹æˆ–ç»å¯¹æ¨¡å¼
		# è‹¥æ¨¡å¼æœªå«è·¯å¾„åˆ†éš”ï¼Œé»˜è®¤åŸºäºŽç¬¬ä¸€ä¸ª root
		paths: List[str] = []
		if os.path.isabs(os.path.expanduser(pattern)):
			paths = glob.glob(expand_path(pattern))
		elif allowed_roots:
			paths = []
			for root in allowed_roots:
				paths.extend(glob.glob(os.path.join(root, pattern)))
		else:
			paths = glob.glob(expand_path(pattern))
		# è¿‡æ»¤è¶Šæƒ
		paths = [os.path.realpath(p) for p in paths if is_path_allowed(p, allowed_roots)]
		paths = sorted(set(paths))[:limit]
		return {"matches": paths}
	elif name == "fsx.read_text":
		raw = args.get("path", "")
		max_bytes = int(args.get("maxBytes", 1048576))
		encoding = args.get("encoding")
		path, allowed, suggestion = resolve_under_roots(raw, allowed_roots)
		if not allowed:
			return {"error": f"è¶Šè¿‡å…è®¸ç›®å½•: {path}", "suggestion": suggestion, "allowedRoots": allowed_roots}
		if not os.path.isfile(path):
			return {"error": f"ä¸æ˜¯æ–‡ä»¶: {path}"}
		try:
			with open(path, "rb") as f:
				data = f.read(max_bytes)
			try:
				text = data.decode(encoding or "utf-8", errors="replace")
			except Exception:
				text = data.decode("latin-1", errors="replace")
			return {"path": path, "text": text, "truncated": os.path.getsize(path) > len(data)}
		except Exception as e:
			return {"error": str(e), "path": path}
	elif name == "fsx.search":
		root_raw = args.get("root", "")
		query = args.get("query", "")
		use_regex = bool(args.get("regex", False))
		limit = int(args.get("limit", 200))
		root, allowed, suggestion = resolve_under_roots(root_raw, allowed_roots)
		if not allowed:
			return {"error": f"è¶Šè¿‡å…è®¸ç›®å½•: {root}", "suggestion": suggestion, "allowedRoots": allowed_roots}
		if not os.path.isdir(root):
			return {"error": f"è·¯å¾„ä¸æ˜¯ç›®å½•: {root}"}
		matches = []
		pattern = re.compile(query) if use_regex else None
		for dirpath, _, filenames in os.walk(root):
			for fn in filenames:
				fp = os.path.join(dirpath, fn)
				if not is_path_allowed(fp, allowed_roots):
					continue
				try:
					# è·³è¿‡è¿‡å¤§æ–‡ä»¶
					if os.path.getsize(fp) > 2 * 1024 * 1024:
						continue
					with open(fp, "rb") as f:
						data = f.read()
					text = data.decode("utf-8", errors="ignore")
					for i, line in enumerate(text.splitlines(), 1):
						ok = bool(pattern.search(line)) if pattern else (query in line)
						if ok:
							matches.append({"path": fp, "line": i, "text": line.strip()})
							if len(matches) >= limit:
								return {"matches": matches, "truncated": True}
				except Exception:
					continue
		return {"matches": matches, "truncated": False}
	elif name == "fsx.organize_by_type":
		root_raw = args.get("path", "")
		root, allowed, suggestion = resolve_under_roots(root_raw, allowed_roots)
		if not allowed:
			return {"error": f"è¶Šè¿‡å…è®¸ç›®å½•: {root}", "suggestion": suggestion, "allowedRoots": allowed_roots}
		if not os.path.isdir(root):
			return {"error": f"è·¯å¾„ä¸æ˜¯ç›®å½•: {root}"}
		moved = []
		for entry in os.scandir(root):
			if entry.is_file():
				ext = os.path.splitext(entry.name)[1].lstrip(".") or "unknown"
				dst_dir = os.path.join(root, ext)
				os.makedirs(dst_dir, exist_ok=True)
				src = os.path.join(root, entry.name)
				dst = os.path.join(dst_dir, entry.name)
				os.replace(src, dst)
				moved.append({"from": src, "to": dst})
		return {"moved": moved}
	elif name == "web.search":
		q = args.get("query", "").strip()
		engine = args.get("engine", "duckduckgo").lower()
		count = min(int(args.get("count", 5)), 10)
		
		if not q:
			return {"error": "query ä¸ºç©º"}
		
		try:
			if engine == "duckduckgo":
				# DuckDuckGo æœç´¢
				url = f"https://duckduckgo.com/html/?q={httpx.QueryParams({'q': q})['q']}"
				async with httpx.AsyncClient(timeout=15) as client:
					resp = await client.get(url, headers={
						"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
					})
					soup = BeautifulSoup(resp.text, "lxml")
					results = []
					for a in soup.select("a.result__a")[:count]:
						title = a.get_text(strip=True)
						url = a.get("href")
						if title and url:
							results.append({"title": title, "url": url})
					return {"results": results, "engine": "duckduckgo", "query": q}
			
			elif engine == "google":
				# ä½¿ç”¨ Serper API è¿›è¡Œ Google æœç´¢ï¼ˆå…è´¹é¢åº¦ï¼‰
				serper_key = os.getenv("SERPER_API_KEY")
				if not serper_key:
					return {"error": "Googleæœç´¢éœ€è¦SERPER_API_KEYçŽ¯å¢ƒå˜é‡", "suggestion": "è¯·è®¾ç½®SERPER_API_KEYæˆ–ä½¿ç”¨duckduckgoå¼•æ“Ž"}
				
				url = "https://google.serper.dev/search"
				async with httpx.AsyncClient(timeout=15) as client:
					resp = await client.post(url, json={"q": q, "num": count}, headers={"X-API-KEY": serper_key})
					data = resp.json()
					results = []
					for item in data.get("organic", [])[:count]:
						results.append({
							"title": item.get("title", ""),
							"url": item.get("link", ""),
							"snippet": item.get("snippet", "")
						})
					return {"results": results, "engine": "google", "query": q}
			
			else:
				return {"error": f"ä¸æ”¯æŒçš„æœç´¢å¼•æ“Ž: {engine}", "supported": ["duckduckgo", "google"]}
				
		except Exception as e:
			return {"error": f"æœç´¢å¤±è´¥: {str(e)}", "suggestion": "è¯·æ£€æŸ¥ç½‘ç»œè¿žæŽ¥æˆ–ç¨åŽé‡è¯•"}
	
	elif name == "web.search_serper":
		q = args.get("query", "").strip()
		api_key = args.get("api_key", "").strip()
		
		if not q:
			return {"error": "query ä¸ºç©º"}
		if not api_key:
			return {"error": "api_key ä¸ºç©º"}
		
		try:
			url = "https://google.serper.dev/search"
			async with httpx.AsyncClient(timeout=15) as client:
				resp = await client.post(url, json={"q": q, "num": 5}, headers={"X-API-KEY": api_key})
				if resp.status_code != 200:
					return {"error": f"APIè¯·æ±‚å¤±è´¥: {resp.status_code}", "response": resp.text}
				
				data = resp.json()
				results = []
				for item in data.get("organic", []):
					results.append({
						"title": item.get("title", ""),
						"url": item.get("link", ""),
						"snippet": item.get("snippet", "")
					})
				return {"results": results, "engine": "google", "query": q}
				
		except Exception as e:
			return {"error": f"Serperæœç´¢å¤±è´¥: {str(e)}", "suggestion": "è¯·æ£€æŸ¥API Keyå’Œç½‘ç»œè¿žæŽ¥"}
	elif name == "web.scrape_images":
		url = args.get("url", "")
		dest_raw = args.get("dest", "")
		dest, allowed, suggestion = resolve_under_roots(dest_raw, allowed_roots)
		if not allowed:
			return {"error": f"è¶Šè¿‡å…è®¸ç›®å½•: {dest}", "suggestion": suggestion, "allowedRoots": allowed_roots}
		if not url or not dest:
			return {"error": "url/dest ä¸èƒ½ä¸ºç©º"}
		os.makedirs(dest, exist_ok=True)
		async with httpx.AsyncClient(timeout=20) as client:
			resp = await client.get(url, headers={"User-Agent": "Mozilla/5.0"})
			soup = BeautifulSoup(resp.text, "lxml")
			imgs = [img.get("src") for img in soup.find_all("img") if img.get("src")]
			downloaded = []
			for i, src in enumerate(imgs, 1):
				try:
					abs_url = src if src.startswith("http") else httpx.URL(url).join(src)
					fn = time.strftime("%Y%m%d_%H%M%S") + f"_{i:03d}.jpg"
					fp = os.path.join(dest, fn)
					binr = await client.get(str(abs_url))
					with open(fp, "wb") as f:
						f.write(binr.content)
					downloaded.append({"url": str(abs_url), "path": fp})
				except Exception as e:
					pass
			return {"downloaded": downloaded}
	elif name == "data.csv_merge":
		pattern_raw = args.get("pattern", "")
		# æ”¯æŒç›¸å¯¹æ¨¡å¼ï¼Œæ˜ å°„åˆ°æ‰€æœ‰å…è®¸æ ¹
		files: List[str] = []
		if os.path.isabs(os.path.expanduser(pattern_raw)):
			for p in glob.glob(expand_path(pattern_raw)):
				if is_path_allowed(p, allowed_roots):
					files.append(p)
		else:
			for root in allowed_roots:
				files.extend(glob.glob(os.path.join(root, pattern_raw)))
		files = [os.path.realpath(p) for p in files if is_path_allowed(p, allowed_roots)]
		columns = args.get("columns")
		frames = []
		for fp in files:
			try:
				df = pd.read_csv(fp)
				if columns:
					df = df[[c for c in columns if c in df.columns]]
				frames.append(df)
			except Exception:
				pass
		if not frames:
			return {"error": "æœªæ‰¾åˆ°å¯è¯»çš„ CSV"}
		out = pd.concat(frames, ignore_index=True)
		return {"columns": list(out.columns), "rows": min(len(out), 10), "preview": out.head(10).to_dict(orient="records")}
	elif name == "data.excel_summary":
		raw = args.get("path", "")
		path, allowed, suggestion = resolve_under_roots(raw, allowed_roots)
		if not allowed:
			return {"error": f"è¶Šè¿‡å…è®¸ç›®å½•: {path}", "suggestion": suggestion, "allowedRoots": allowed_roots}
		sheet = args.get("sheet")
		if not os.path.exists(path):
			return {"error": "æ–‡ä»¶ä¸å­˜åœ¨"}
		df = pd.read_excel(path, sheet_name=sheet) if sheet else pd.read_excel(path)
		summary = {"shape": df.shape, "columns": list(df.columns)}
		num_cols = df.select_dtypes(include=["number"]).columns.tolist()
		if num_cols:
			stats = df[num_cols].describe().to_dict()
			summary["describe"] = stats
		return summary
	elif name == "code.quick_inspect":
		raw = args.get("path", "")
		root, allowed, suggestion = resolve_under_roots(raw, allowed_roots)
		if not allowed:
			return {"error": f"è¶Šè¿‡å…è®¸ç›®å½•: {root}", "suggestion": suggestion, "allowedRoots": allowed_roots}
		if not os.path.isdir(root):
			return {"error": f"è·¯å¾„ä¸æ˜¯ç›®å½•: {root}"}
		report = {"languages": {}, "files": 0, "modules": []}
		for dirpath, _, filenames in os.walk(root):
			for fn in filenames:
				ext = os.path.splitext(fn)[1].lower()
				report["languages"][ext] = report["languages"].get(ext, 0) + 1
				report["files"] += 1
				if ext in {".py", ".js", ".ts", ".java", ".go"}:
					report["modules"].append(os.path.join(dirpath, fn))
		return report
	return {"error": f"Unknown builtin tool: {name}"}


async def run_once(user_query: str, config: Dict[str, Any], api_key: str, verbose: bool = False, conversation_history: List[Dict[str, Any]] = None) -> List[Dict[str, Any]]:
	servers_cfg = config.get("servers", [])
	if not servers_cfg:
		raise RuntimeError("No MCP servers configured. See README for config format.")

	connected = []
	stack: AsyncExitStack
	connected, stack = await open_all_servers(servers_cfg)
	try:
		openai_tools = build_openai_tools(connected)
		invoke = make_invoker(connected)
		allowed_roots = get_allowed_roots_from_config(config)

		client = OpenAI(
			api_key=api_key,
			base_url=(config.get("model", {}).get("baseURL") or "https://dashscope.aliyuncs.com/compatible-mode/v1"),
		)
		model_name = config.get("model", {}).get("model", "qwen-plus")
		max_steps = int(config.get("limits", {}).get("maxSteps", 6))

		# æž„å»ºå¯¹è¯åŽ†å²
		messages: List[Dict[str, Any]] = [
			{
				"role": "system",
				"content": "ä½ æ˜¯ä¸€ä¸ªå¯ä»¥è°ƒç”¨å·¥å…·çš„æ™ºèƒ½ä½“ã€‚éœ€è¦å¤–éƒ¨èƒ½åŠ›ï¼ˆæ–‡ä»¶/å‘½ä»¤/æœç´¢ç­‰ï¼‰æ—¶å†è°ƒç”¨å·¥å…·ï¼›æ ¹æ®å·¥å…·ç»“æžœè¾“å‡ºç®€æ´ä¸­æ–‡ç­”æ¡ˆã€‚\n\nå¯ç”¨çš„å·¥å…·åŒ…æ‹¬ï¼š\n- websearch.search: å¤šå¼•æ“Žæœç´¢ï¼ˆæŽ¨èï¼‰ï¼Œå‚æ•°ï¼šqueryï¼ˆå¿…éœ€ï¼‰ã€limitï¼ˆå¯é€‰ï¼‰ã€enginesï¼ˆå¯é€‰ï¼Œæ•°ç»„ï¼‰\n- web.search: åŸºç¡€æœç´¢ï¼ˆå¤‡ç”¨ï¼‰\n- fsx.list_dir: åˆ—å‡ºç›®å½•æ–‡ä»¶\n- fsx.glob: æ–‡ä»¶æ¨¡å¼åŒ¹é…\n- fsx.read_text: è¯»å–æ–‡æœ¬æ–‡ä»¶\n- fsx.search: æœç´¢æ–‡ä»¶å†…å®¹\n- data.csv_merge: åˆå¹¶CSVæ–‡ä»¶\n- data.excel_summary: Excelæ•°æ®åˆ†æž\n- code.quick_inspect: ä»£ç æ£€æŸ¥\n\næœç´¢ä¼˜åŒ–å»ºè®®ï¼š\n1. å¿«é€Ÿæœç´¢ï¼šä½¿ç”¨ websearch.search å¹¶æŒ‡å®š engines=['bing']ï¼ˆæœ€å¿«ï¼‰\n2. å…¨é¢æœç´¢ï¼šä½¿ç”¨ websearch.search å¹¶æŒ‡å®š engines=['bing', 'duckduckgo']ï¼ˆå¹³è¡¡é€Ÿåº¦å’Œç»“æžœï¼‰\n3. ä¸­æ–‡æœç´¢ï¼šä½¿ç”¨ websearch.search å¹¶æŒ‡å®š engines=['baidu', 'csdn']ï¼ˆä¸­æ–‡å†…å®¹æ›´ä¸°å¯Œï¼‰",
			}
		]
		
		# æ·»åŠ å¯¹è¯åŽ†å²
		if conversation_history:
			messages.extend(conversation_history)
		
		# æ·»åŠ å½“å‰ç”¨æˆ·é—®é¢˜
		messages.append({"role": "user", "content": user_query})

		for step in range(max_steps):
			resp = client.chat.completions.create(
				model=model_name,
				messages=messages,
				tools=openai_tools,
			)
			choice = resp.choices[0]
			msg = choice.message

			if getattr(msg, "tool_calls", None):
				# Echo assistant tool_calls into the transcript as required by spec
				messages.append({
					"role": "assistant",
					"content": msg.content,
					"tool_calls": [
						{
							"id": tc.id,
							"type": tc.type,
							"function": {"name": tc.function.name, "arguments": tc.function.arguments},
						}
						for tc in msg.tool_calls
					],
				})

				for tc in msg.tool_calls:
					name = tc.function.name
					args = safe_parse_json(tc.function.arguments)
					if verbose:
						print(f"[tool] calling {name} with {args}")
					try:
						if name.startswith("fsx.") or name.startswith("web.") or name.startswith("data.") or name.startswith("code."):
							result = await handle_builtin_tool(name, args, allowed_roots)
						else:
							result = await invoke(name, args)
					except RuntimeError as e:
						if "Tool not found" in str(e):
							result = {"error": f"å·¥å…·æœªæ‰¾åˆ°: {name}", "available_tools": [t["function"]["name"] for t in openai_tools]}
						else:
							raise
					except Exception as e:
						if verbose:
							print(f"[error] å·¥å…·è°ƒç”¨å¤±è´¥: {name} - {e}")
						result = {"error": f"å·¥å…·è°ƒç”¨å¤±è´¥: {str(e)}", "tool": name, "args": args}
					serializable = to_json_safe(result)
					messages.append(
						{
							"role": "tool",
							"tool_call_id": tc.id,
							"name": name,
							"content": json.dumps(serializable, ensure_ascii=False),
						}
					)
				continue

			# Final answer
			if msg.content:
				# æ¸²æŸ“ Markdown æ ¼å¼
				rendered_content = render_markdown(msg.content)
				print(rendered_content)
				# æ·»åŠ åŠ©æ‰‹å›žå¤åˆ°å¯¹è¯åŽ†å²
				messages.append({
					"role": "assistant",
					"content": msg.content
				})
				break
	finally:
		await stack.aclose()
	
	# è¿”å›žæ›´æ–°åŽçš„å¯¹è¯åŽ†å²ï¼ˆæŽ’é™¤ç³»ç»Ÿæ¶ˆæ¯ï¼‰
	return [msg for msg in messages if msg["role"] != "system"]


async def conversation_loop(config_path: str, config: Dict[str, Any], api_key: str, verbose: bool = False) -> None:
	conversation_history: List[Dict[str, Any]] = []
	
	# æ˜¾ç¤º LOGO
	show_logo()
	print()  # ç©ºè¡Œ
	
	# ä½¿ç”¨é¢œè‰²ç¾ŽåŒ–ç•Œé¢
	colors = {
		'bold': '\033[1m',
		'blue': '\033[94m',
		'cyan': '\033[96m',
		'green': '\033[92m',
		'yellow': '\033[93m',
		'magenta': '\033[95m',
		'reset': '\033[0m'
	}
	
	print(f"{colors['bold']}{colors['blue']}=== MCP AI CLI è¿žç»­å¯¹è¯æ¨¡å¼ ==={colors['reset']}")
	print(f"{colors['cyan']}ç›´æŽ¥è¾“å…¥é—®é¢˜å¼€å§‹å¯¹è¯ï¼Œæ”¯æŒä»¥ä¸‹ç‰¹æ®Šå‘½ä»¤ï¼š{colors['reset']}")
	print(f"  {colors['yellow']}/help{colors['reset']}     - æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯")
	print(f"  {colors['yellow']}/config{colors['reset']}   - é…ç½®é€‰é¡¹")
	print(f"  {colors['yellow']}/clear{colors['reset']}    - æ¸…ç©ºå¯¹è¯åŽ†å²")
	print(f"  {colors['yellow']}/cs{colors['reset']}       - è”ç³»å®¢æœæ”¯æŒ")
	print(f"  {colors['yellow']}/quit{colors['reset']}     - é€€å‡ºç¨‹åº")
	print(f"  {colors['yellow']}Ctrl+C{colors['reset']}    - é€€å‡ºç¨‹åº")
	print()
	
	while True:
		try:
			# æ˜¾ç¤ºå¯¹è¯æç¤º
			user_input = input("> ").strip()
			
			if not user_input:
				continue
			
			# å¤„ç†ç‰¹æ®Šå‘½ä»¤
			if user_input.startswith("/"):
				command = user_input.lower()
				if command == "/help":
					help_text = """
## ç‰¹æ®Šå‘½ä»¤è¯´æ˜Ž

### åŸºç¡€å‘½ä»¤
- **/help**     - æ˜¾ç¤ºæ­¤å¸®åŠ©ä¿¡æ¯
- **/config**   - è¿›å…¥é…ç½®èœå•
- **/clear**    - æ¸…ç©ºå¯¹è¯åŽ†å²
- **/cs**       - è”ç³»å®¢æœèŽ·å¾—æ”¯æŒ
- **/quit**     - é€€å‡ºç¨‹åº

### ä½¿ç”¨æŠ€å·§
- ç›´æŽ¥è¾“å…¥é—®é¢˜å³å¯å¼€å§‹å¯¹è¯
- æ”¯æŒ **Markdown** æ ¼å¼è¾“å‡º
- æ”¯æŒè¿žç»­å¯¹è¯ï¼ŒAI ä¼šè®°ä½ä¸Šä¸‹æ–‡
- ä½¿ç”¨ `Ctrl+C` å¯éšæ—¶é€€å‡º
- é‡åˆ°é—®é¢˜ï¼Ÿä½¿ç”¨ `/cs` è”ç³»å®¢æœ
"""
					print(render_markdown(help_text))
					continue
				elif command == "/config":
					await config_menu(config_path, config, api_key)
					continue
				elif command == "/clear":
					conversation_history.clear()
					print(f"{colors['green']}âœ“ å¯¹è¯åŽ†å²å·²æ¸…ç©ºï¼{colors['reset']}")
					continue
				elif command == "/cs":
					show_customer_service_qr()
					continue
				elif command == "/quit":
					print(f"{colors['cyan']}ðŸ‘‹ å†è§ï¼{colors['reset']}")
					return
				else:
					print(f"æœªçŸ¥å‘½ä»¤: {user_input}ï¼Œè¾“å…¥ /help æŸ¥çœ‹å¸®åŠ©")
					continue
			
			# æ­£å¸¸å¯¹è¯
			print("AI: ", end="", flush=True)
			conversation_history = await run_once(user_input, config, api_key=api_key, verbose=verbose, conversation_history=conversation_history)
			print()  # æ¢è¡Œ
			
		except (EOFError, KeyboardInterrupt):
			print("\n\nå†è§ï¼")
			return


async def config_menu(config_path: str, config: Dict[str, Any], api_key: str) -> None:
	"""é…ç½®èœå•ï¼Œä»Žå¯¹è¯æ¨¡å¼ä¸­è°ƒç”¨"""
	colors = {
		'bold': '\033[1m',
		'blue': '\033[94m',
		'cyan': '\033[96m',
		'green': '\033[92m',
		'yellow': '\033[93m',
		'magenta': '\033[95m',
		'reset': '\033[0m'
	}
	
	while True:
		print(f"\n{colors['bold']}{colors['blue']}=== é…ç½®èœå• ==={colors['reset']}")
		print(f"1) {colors['cyan']}é…ç½®é€šä¹‰åƒé—® API Key{colors['reset']}")
		print(f"2) {colors['cyan']}åˆ‡æ¢æ¨¡åž‹ï¼ˆmodelï¼‰{colors['reset']}")
		print(f"3) {colors['cyan']}æŸ¥çœ‹å½“å‰é…ç½®æ¦‚è§ˆ{colors['reset']}")
		print(f"4) {colors['cyan']}é…ç½®æ–‡ä»¶ç³»ç»Ÿè·¯å¾„{colors['reset']}")
		print(f"5) {colors['magenta']}ðŸ’³ é€šä¹‰åƒé—®ä½™é¢å……å€¼{colors['reset']}")
		print(f"6) {colors['yellow']}è¿”å›žå¯¹è¯æ¨¡å¼{colors['reset']}")
		choice = input(f"{colors['green']}è¯·é€‰æ‹© [1-6]: {colors['reset']}").strip()
		
		if choice == "1":
			api_key = interactive_api_key_setup(config_path, api_key)
		elif choice == "2":
			new_model = input("è¯·è¾“å…¥æ¨¡åž‹åï¼ˆå¦‚ qwen-plus æˆ– qwen2.5-72b-instructï¼‰ï¼š").strip()
			if not new_model:
				continue
			print("æ˜¯å¦ä¿å­˜åˆ°é…ç½®æ–‡ä»¶ï¼Ÿ y/N")
			if input().strip().lower() == "y":
				write_model_to_config(config_path, new_model)
				config = load_config(config_path)
				print("å·²ä¿å­˜ã€‚")
			else:
				config.setdefault("model", {})["model"] = new_model
		elif choice == "3":
			model = (config.get("model") or {}).get("model", "qwen-plus")
			base_url = (config.get("model") or {}).get("baseURL", "(é»˜è®¤)")
			servers = config.get("servers", [])
			print(f"æ¨¡åž‹: {model}")
			print(f"BaseURL: {base_url}")
			print(f"API Key: {'å·²é…ç½®' if api_key else 'æœªé…ç½®'}")
			print(f"MCP æœåŠ¡å™¨æ•°: {len(servers)} -> {[s.get('name') for s in servers]}")
		elif choice == "4":
			print("å½“å‰å…è®¸çš„æ–‡ä»¶ç³»ç»Ÿè·¯å¾„:")
			allowed_roots = get_allowed_roots_from_config(config)
			for i, root in enumerate(allowed_roots):
				print(f"  {i+1}. {root}")
			
			# æ ¹æ®ç³»ç»Ÿæ˜¾ç¤ºä¸åŒçš„è·¯å¾„é€‰é¡¹
			system_info = get_system_info()
			if system_info['raw_system'] == 'windows':
				print("\nè·¯å¾„é…ç½®é€‰é¡¹ (Windows):")
				print("1) ä½¿ç”¨ç”¨æˆ·ä¸»ç›®å½• (%USERPROFILE%)")
				print("2) ä½¿ç”¨å½“å‰å·¥ä½œç›®å½•")
				print("3) è‡ªå®šä¹‰è·¯å¾„")
				print("4) è¿”å›ž")
				
				path_choice = input("è¯·é€‰æ‹© [1-4]: ").strip()
				if path_choice == "1":
					new_path = "~"  # åœ¨ Windows ä¸Š ~ ä¼šè¢«è‡ªåŠ¨è½¬æ¢ä¸º %USERPROFILE%
				elif path_choice == "2":
					new_path = os.getcwd()
				elif path_choice == "3":
					new_path = input("è¯·è¾“å…¥è·¯å¾„ï¼ˆæ”¯æŒ ~ã€%USERPROFILE% å’Œç›¸å¯¹è·¯å¾„ï¼‰: ").strip()
					if not new_path:
						continue
				else:
					continue
			else:
				print("\nè·¯å¾„é…ç½®é€‰é¡¹:")
				print("1) ä½¿ç”¨ç”¨æˆ·ä¸»ç›®å½• (~)")
				print("2) ä½¿ç”¨å½“å‰å·¥ä½œç›®å½•")
				print("3) è‡ªå®šä¹‰è·¯å¾„")
				print("4) è¿”å›ž")
				
				path_choice = input("è¯·é€‰æ‹© [1-4]: ").strip()
				if path_choice == "1":
					new_path = "~"
				elif path_choice == "2":
					new_path = os.getcwd()
				elif path_choice == "3":
					new_path = input("è¯·è¾“å…¥è·¯å¾„ï¼ˆæ”¯æŒ ~ å’Œç›¸å¯¹è·¯å¾„ï¼‰: ").strip()
					if not new_path:
						continue
				else:
					continue
			
			# æ›´æ–°é…ç½®æ–‡ä»¶
			for server in config.get("servers", []):
				if server.get("name") == "fs":
					server["args"] = ["@modelcontextprotocol/server-filesystem", new_path]
					break
			
			# ä¿å­˜åˆ°é…ç½®æ–‡ä»¶
			config_path = os.path.expanduser("~/.mcp/config.json")
			with open(config_path, "w", encoding="utf-8") as f:
				json.dump(config, f, ensure_ascii=False, indent=2)
			
			print(f"æ–‡ä»¶ç³»ç»Ÿè·¯å¾„å·²æ›´æ–°ä¸º: {new_path}")
			print("é‡å¯ç¨‹åºåŽç”Ÿæ•ˆ")
			
		elif choice == "5":
			show_recharge_qr()
		elif choice == "6":
			print("è¿”å›žå¯¹è¯æ¨¡å¼...")
			break
		else:
			continue


async def repl(config: Dict[str, Any], api_key: str, verbose: bool = False) -> None:
	print("MCP AI CLI (Qwen). Type Ctrl+C to exit.")
	while True:
		try:
			query = input("> ").strip()
			if not query:
				continue
			await run_once(query, config, api_key=api_key, verbose=verbose)
		except (EOFError, KeyboardInterrupt):
			print()
			return


def load_config(path: str) -> Dict[str, Any]:
	with open(path, "r", encoding="utf-8") as f:
		return json.load(f)


def main():
	parser = argparse.ArgumentParser(description="Natural language to MCP tool caller (Qwen)")
	parser.add_argument("query", nargs=argparse.REMAINDER, help="Single-turn query to run. If empty, enter interactive menu.")
	parser.add_argument("--config", dest="config", default=os.getenv("MCP_CONFIG_PATH") or os.path.expanduser("~/.mcp/config.json"), help="Path to config JSON")
	parser.add_argument("--api-key", dest="api_key", default=None, help="DashScope API key for Qwen (overrides env/config)")
	parser.add_argument("--setup", dest="setup", action="store_true", help="Interactive API key setup before running")
	parser.add_argument("--verbose", dest="verbose", action="store_true", help="Verbose tool call logs")
	args = parser.parse_args()

	config = load_config(args.config)
	query_text = " ".join(args.query).strip()

	api_key = (
		args.api_key
		or config.get("model", {}).get("apiKey")
		or os.getenv("DASHSCOPE_API_KEY")
	)

	if args.setup or (not api_key and not query_text):
		api_key = interactive_api_key_setup(args.config, api_key)

	if query_text:
		if not api_key:
			print("Error: DashScope API key not provided.", file=sys.stderr)
			sys.exit(1)
		# æ˜¾ç¤º LOGO
		show_logo()
		print()  # ç©ºè¡Œ
		asyncio.run(run_once(query_text, config, api_key=api_key, verbose=args.verbose))
	else:
		asyncio.run(conversation_loop(args.config, config, api_key=api_key or "", verbose=args.verbose))


if __name__ == "__main__":
	main() 