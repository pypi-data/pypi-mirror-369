"""
Unified MCP Configuration Synchronization Manager

Core design principles:
1. mcp.json is the single source of truth
2. All configuration changes go through mcp.json, automatically sync to global_agent_store
3. Agent operations only manage their own space + mcp.json, Store operations only manage mcp.json
4. Automatic sync mechanism handles mcp.json â†’ global_agent_store synchronization

Data space support:
- File monitoring based on orchestrator.mcp_config.json_path
- Support independent synchronization for different data spaces
"""

import asyncio
import logging
import os
import time
from pathlib import Path
from typing import Dict, Set, Optional, Any
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler

logger = logging.getLogger(__name__)


class MCPFileHandler(FileSystemEventHandler):
    """MCP configuration file change handler"""
    
    def __init__(self, sync_manager):
        self.sync_manager = sync_manager
        self.mcp_filename = os.path.basename(sync_manager.mcp_json_path)
        
    def on_modified(self, event):
        """File modification event handling"""
        if event.is_directory:
            return

        # Only monitor target mcp.json file
        if os.path.basename(event.src_path) == self.mcp_filename:
            logger.debug(f"MCP config file modified: {event.src_path}")
            # Safely execute async method in correct event loop
            try:
                loop = asyncio.get_event_loop()
                if loop.is_running():
                    # If event loop is running, use call_soon_threadsafe
                    loop.call_soon_threadsafe(
                        lambda: asyncio.create_task(self.sync_manager.on_file_changed())
                    )
                else:
                    # å¦‚æœäº‹ä»¶å¾ªç¯æœªè¿è¡Œï¼Œç›´æ¥åˆ›å»ºä»»åŠ¡
                    asyncio.create_task(self.sync_manager.on_file_changed())
            except RuntimeError:
                # å¦‚æœæ²¡æœ‰äº‹ä»¶å¾ªç¯ï¼Œè®°å½•è­¦å‘Š
                logger.warning("No event loop available for file change notification")


class UnifiedMCPSyncManager:
    """ç»Ÿä¸€çš„MCPé…ç½®åŒæ­¥ç®¡ç†å™¨"""
    
    def __init__(self, orchestrator):
        """
        åˆå§‹åŒ–åŒæ­¥ç®¡ç†å™¨
        
        Args:
            orchestrator: MCPOrchestratorå®ä¾‹
        """
        self.orchestrator = orchestrator
        # ç¡®ä¿ä½¿ç”¨ç»å¯¹è·¯å¾„
        import os
        self.mcp_json_path = os.path.abspath(orchestrator.mcp_config.json_path)
        self.file_observer = None
        self.sync_lock = asyncio.Lock()
        self.debounce_delay = 1.0  # é˜²æŠ–å»¶è¿Ÿï¼ˆç§’ï¼‰
        self.sync_task = None
        self.last_change_time = None
        self.is_running = False
        
        logger.info(f"UnifiedMCPSyncManager initialized for: {self.mcp_json_path}")
        
    async def start(self):
        """å¯åŠ¨åŒæ­¥ç®¡ç†å™¨"""
        if self.is_running:
            logger.warning("Sync manager is already running")
            return
            
        try:
            logger.info("Starting unified MCP sync manager...")
            
            # å¯åŠ¨æ–‡ä»¶ç›‘å¬
            await self._start_file_watcher()

            # ğŸ”§ æ‰§è¡Œå¯åŠ¨æ—¶åŒæ­¥ï¼ˆå§‹ç»ˆå¯ç”¨ï¼‰
            logger.info("Executing initial sync from mcp.json")
            await self.sync_global_agent_store_from_mcp_json()

            self.is_running = True
            logger.info("Unified MCP sync manager started successfully")
            
        except Exception as e:
            logger.error(f"Failed to start sync manager: {e}")
            await self.stop()
            raise
            
    async def stop(self):
        """åœæ­¢åŒæ­¥ç®¡ç†å™¨"""
        if not self.is_running:
            return
            
        logger.info("Stopping unified MCP sync manager...")
        
        # åœæ­¢æ–‡ä»¶ç›‘å¬
        if self.file_observer:
            self.file_observer.stop()
            self.file_observer.join()
            self.file_observer = None
            
        # å–æ¶ˆå¾…æ‰§è¡Œçš„åŒæ­¥ä»»åŠ¡
        if self.sync_task and not self.sync_task.done():
            self.sync_task.cancel()
            
        self.is_running = False
        logger.info("Unified MCP sync manager stopped")
        
    async def _start_file_watcher(self):
        """å¯åŠ¨mcp.jsonæ–‡ä»¶ç›‘å¬"""
        try:
            # ç¡®ä¿mcp.jsonæ–‡ä»¶å­˜åœ¨
            if not os.path.exists(self.mcp_json_path):
                logger.warning(f"MCP config file not found: {self.mcp_json_path}")
                # åˆ›å»ºç©ºé…ç½®æ–‡ä»¶
                os.makedirs(os.path.dirname(self.mcp_json_path), exist_ok=True)
                with open(self.mcp_json_path, 'w', encoding='utf-8') as f:
                    import json
                    json.dump({"mcpServers": {}}, f, indent=2)
                logger.info(f"Created empty MCP config file: {self.mcp_json_path}")
            
            # åˆ›å»ºæ–‡ä»¶ç›‘å¬å™¨
            self.file_observer = Observer()
            handler = MCPFileHandler(self)
            
            # ç›‘å¬mcp.jsonæ‰€åœ¨ç›®å½•
            watch_dir = os.path.dirname(self.mcp_json_path)
            self.file_observer.schedule(handler, watch_dir, recursive=False)
            self.file_observer.start()
            
            logger.info(f"File watcher started for directory: {watch_dir}")
            
        except Exception as e:
            logger.error(f"Failed to start file watcher: {e}")
            raise
            
    async def on_file_changed(self):
        """æ–‡ä»¶å˜åŒ–å›è°ƒï¼ˆå¸¦é˜²æŠ–ï¼‰"""
        try:
            self.last_change_time = time.time()
            
            # å–æ¶ˆä¹‹å‰çš„åŒæ­¥ä»»åŠ¡
            if self.sync_task and not self.sync_task.done():
                self.sync_task.cancel()
                
            # å¯åŠ¨é˜²æŠ–åŒæ­¥
            self.sync_task = asyncio.create_task(self._debounced_sync())
            
        except Exception as e:
            logger.error(f"Error handling file change: {e}")
            
    async def _debounced_sync(self):
        """é˜²æŠ–åŒæ­¥"""
        try:
            await asyncio.sleep(self.debounce_delay)
            
            # æ£€æŸ¥æ˜¯å¦æœ‰æ–°çš„å˜åŒ–
            if self.last_change_time and time.time() - self.last_change_time >= self.debounce_delay:
                logger.info("Triggering auto-sync due to mcp.json changes")
                await self.sync_main_client_from_mcp_json()
                
        except asyncio.CancelledError:
            logger.debug("Debounced sync cancelled")
        except Exception as e:
            logger.error(f"Error in debounced sync: {e}")
            
    async def sync_global_agent_store_from_mcp_json(self):
        """ä»mcp.jsonåŒæ­¥global_agent_storeï¼ˆæ ¸å¿ƒæ–¹æ³•ï¼‰"""
        async with self.sync_lock:
            try:
                logger.info("Starting global_agent_store sync from mcp.json")

                # è¯»å–æœ€æ–°é…ç½®
                config = self.orchestrator.mcp_config.load_config()
                services = config.get("mcpServers", {})

                logger.debug(f"Found {len(services)} services in mcp.json")

                # æ‰§è¡ŒåŒæ­¥
                results = await self._sync_global_agent_store_services(services)

                logger.info(f"Global agent store sync completed: {results}")
                return results

            except Exception as e:
                logger.error(f"Global agent store sync failed: {e}")
                raise
                
    async def _sync_global_agent_store_services(self, target_services: Dict[str, Any]) -> Dict[str, Any]:
        """åŒæ­¥global_agent_storeçš„æœåŠ¡"""
        try:
            global_agent_store_id = self.orchestrator.client_manager.global_agent_store_id

            # è·å–å½“å‰global_agent_storeçš„æœåŠ¡
            current_services = self._get_current_global_agent_store_services()
            
            # è®¡ç®—å·®å¼‚
            current_names = set(current_services.keys())
            target_names = set(target_services.keys())
            
            to_add = target_names - current_names
            to_remove = current_names - target_names
            to_update = target_names & current_names
            
            logger.debug(f"Sync plan: +{len(to_add)} -{len(to_remove)} ~{len(to_update)}")
            
            # æ‰§è¡ŒåŒæ­¥
            results = {
                "added": [],
                "removed": [],
                "updated": [],
                "failed": []
            }
            
            # 1. ç§»é™¤ä¸å†éœ€è¦çš„æœåŠ¡
            for service_name in to_remove:
                try:
                    success = await self._remove_service_from_global_agent_store(service_name)
                    if success:
                        results["removed"].append(service_name)
                        logger.debug(f"Removed service: {service_name}")
                    else:
                        results["failed"].append(f"remove:{service_name}")
                except Exception as e:
                    logger.error(f"Failed to remove service {service_name}: {e}")
                    results["failed"].append(f"remove:{service_name}:{e}")
            
            # 2. æ·»åŠ /æ›´æ–°æœåŠ¡ï¼ˆæ–°é€»è¾‘ï¼šæ“ä½œç¼“å­˜æ˜ å°„ï¼Œç„¶åå¼‚æ­¥æŒä¹…åŒ–ï¼‰
            services_to_register = {}
            for service_name in (to_add | to_update):
                try:
                    # ğŸ”§ æ–°é€»è¾‘ï¼šç›´æ¥æ“ä½œç¼“å­˜æ˜ å°„è€Œä¸æ˜¯ç›´æ¥æ“ä½œæ–‡ä»¶
                    success = await self._add_service_to_cache_mapping(
                        agent_id=global_agent_store_id,
                        service_name=service_name,
                        service_config=target_services[service_name]
                    )

                    if success:
                        services_to_register[service_name] = target_services[service_name]
                        if service_name in to_add:
                            results["added"].append(service_name)
                            logger.debug(f"Added service to cache: {service_name}")
                        else:
                            results["updated"].append(service_name)
                            logger.debug(f"Updated service in cache: {service_name}")
                    else:
                        action = "add" if service_name in to_add else "update"
                        results["failed"].append(f"{action}:{service_name}")

                except Exception as e:
                    action = "add" if service_name in to_add else "update"
                    logger.error(f"Failed to {action} service {service_name}: {e}")
                    results["failed"].append(f"{action}:{service_name}:{e}")

            # 3. æ‰¹é‡æ³¨å†Œåˆ°Registry
            if services_to_register:
                await self._batch_register_to_registry(global_agent_store_id, services_to_register)

            # 4. ğŸ”§ æ–°å¢ï¼šè§¦å‘ç¼“å­˜åˆ°æ–‡ä»¶çš„å¼‚æ­¥æŒä¹…åŒ–
            if services_to_register:
                await self._trigger_cache_persistence()
            
            return results

        except Exception as e:
            logger.error(f"Error syncing main client services: {e}")
            raise

    def _get_current_global_agent_store_services(self) -> Dict[str, Any]:
        """è·å–å½“å‰global_agent_storeçš„æœåŠ¡é…ç½®"""
        try:
            global_agent_store_id = self.orchestrator.client_manager.global_agent_store_id
            client_ids = self.orchestrator.client_manager.get_agent_clients(global_agent_store_id)

            current_services = {}
            for client_id in client_ids:
                client_config = self.orchestrator.client_manager.get_client_config(client_id)
                if client_config and "mcpServers" in client_config:
                    current_services.update(client_config["mcpServers"])

            return current_services

        except Exception as e:
            logger.error(f"Error getting current main client services: {e}")
            return {}

    async def _remove_service_from_global_agent_store(self, service_name: str) -> bool:
        """ä»global_agent_storeç§»é™¤æœåŠ¡"""
        try:
            global_agent_store_id = self.orchestrator.client_manager.global_agent_store_id

            # æŸ¥æ‰¾åŒ…å«è¯¥æœåŠ¡çš„client_ids
            matching_clients = self.orchestrator.client_manager.find_clients_with_service(
                global_agent_store_id, service_name
            )

            # ç§»é™¤åŒ…å«è¯¥æœåŠ¡çš„clients
            for client_id in matching_clients:
                self.orchestrator.client_manager._remove_client_and_mapping(global_agent_store_id, client_id)
                logger.debug(f"Removed client {client_id} containing service {service_name}")

            # ä»Registryç§»é™¤
            if hasattr(self.orchestrator.registry, 'remove_service'):
                self.orchestrator.registry.remove_service(global_agent_store_id, service_name)

            return len(matching_clients) > 0

        except Exception as e:
            logger.error(f"Error removing service {service_name} from main client: {e}")
            return False

    async def _batch_register_to_registry(self, agent_id: str, services_to_register: Dict[str, Any]):
        """æ‰¹é‡æ³¨å†ŒæœåŠ¡åˆ°Registry"""
        try:
            if not services_to_register:
                return

            logger.debug(f"Batch registering {len(services_to_register)} services to Registry")

            # è·å–å¯¹åº”çš„client_ids
            client_ids = self.orchestrator.client_manager.get_agent_clients(agent_id)

            for client_id in client_ids:
                client_config = self.orchestrator.client_manager.get_client_config(client_id)
                if not client_config:
                    continue

                # æ£€æŸ¥è¿™ä¸ªclientæ˜¯å¦åŒ…å«è¦æ³¨å†Œçš„æœåŠ¡
                client_services = client_config.get("mcpServers", {})
                services_in_client = set(client_services.keys()) & set(services_to_register.keys())

                if services_in_client:
                    try:
                        # ğŸ”§ é‡æ„ï¼šä½¿ç”¨ç»Ÿä¸€çš„add_serviceæ–¹æ³•è€Œä¸æ˜¯register_json_services
                        if hasattr(self.orchestrator, 'store') and self.orchestrator.store:
                            # ä½¿ç”¨ç»Ÿä¸€æ³¨å†Œæ¶æ„
                            await self.orchestrator.store.for_store().add_service_async(client_config, source="auto_startup")
                            logger.debug(f"Registered client {client_id} with services: {list(services_in_client)} via unified add_service")
                        else:
                            # å›é€€åˆ°åŸæœ‰æ–¹æ³•ï¼ˆå¸¦è­¦å‘Šï¼‰
                            logger.warning("Store reference not available, falling back to register_json_services")
                            await self.orchestrator.register_json_services(client_config, client_id=client_id)
                            logger.debug(f"Registered client {client_id} with services: {list(services_in_client)}")
                    except Exception as e:
                        logger.error(f"Failed to register client {client_id}: {e}")

        except Exception as e:
            logger.error(f"Error in batch register to registry: {e}")

    async def _add_service_to_cache_mapping(self, agent_id: str, service_name: str, service_config: Dict[str, Any]) -> bool:
        """
        å°†æœåŠ¡æ·»åŠ åˆ°ç¼“å­˜æ˜ å°„ï¼ˆRegistryä¸­çš„ä¸¤ä¸ªæ˜ å°„å­—æ®µï¼‰

        ç¼“å­˜æ˜ å°„æŒ‡çš„æ˜¯ï¼š
        - registry.agent_clients: Agent-Clientæ˜ å°„
        - registry.client_configs: Clienté…ç½®æ˜ å°„

        Args:
            agent_id: Agent ID
            service_name: æœåŠ¡åç§°
            service_config: æœåŠ¡é…ç½®

        Returns:
            æ˜¯å¦æˆåŠŸæ·»åŠ åˆ°ç¼“å­˜æ˜ å°„
        """
        try:
            # ç”Ÿæˆæˆ–è·å–client_id
            client_id = self.orchestrator.client_manager.generate_client_id()

            # è·å–Registryå®ä¾‹
            registry = getattr(self.orchestrator, 'registry', None)
            if not registry:
                logger.error("Registry not available")
                return False

            # æ›´æ–°ç¼“å­˜æ˜ å°„1ï¼šAgent-Clientæ˜ å°„
            if agent_id not in registry.agent_clients:
                registry.agent_clients[agent_id] = []
            if client_id not in registry.agent_clients[agent_id]:
                registry.agent_clients[agent_id].append(client_id)

            # æ›´æ–°ç¼“å­˜æ˜ å°„2ï¼šClienté…ç½®æ˜ å°„
            registry.client_configs[client_id] = {
                "mcpServers": {service_name: service_config}
            }

            logger.debug(f"âœ… ç¼“å­˜æ˜ å°„æ›´æ–°æˆåŠŸ: {service_name} -> {client_id}")
            logger.debug(f"   - agent_clients[{agent_id}] å·²æ›´æ–°")
            logger.debug(f"   - client_configs[{client_id}] å·²æ›´æ–°")
            return True

        except Exception as e:
            logger.error(f"Failed to add service to cache mapping: {e}")
            return False

    async def _trigger_cache_persistence(self):
        """
        è§¦å‘ç¼“å­˜æ˜ å°„åˆ°æ–‡ä»¶çš„åŒæ­¥æœºåˆ¶

        æ³¨æ„ï¼šè¿™é‡Œè°ƒç”¨çš„æ˜¯åŒæ­¥æœºåˆ¶ï¼ˆsync_to_client_managerï¼‰ï¼Œ
        ä¸æ˜¯å¼‚æ­¥æŒä¹…åŒ–ï¼ˆ_persist_to_files_asyncï¼‰
        """
        try:
            cache_manager = getattr(self.orchestrator, 'cache_manager', None)
            if cache_manager:
                # è°ƒç”¨ç¼“å­˜åŒæ­¥æœºåˆ¶ï¼šå°†ç¼“å­˜æ˜ å°„åŒæ­¥åˆ°æ–‡ä»¶
                cache_manager.sync_to_client_manager(self.orchestrator.client_manager)
                logger.debug("âœ… ç¼“å­˜æ˜ å°„åŒæ­¥åˆ°æ–‡ä»¶æˆåŠŸ")
            else:
                # å¤‡ç”¨æ–¹æ¡ˆ
                registry = getattr(self.orchestrator, 'registry', None)
                if registry:
                    registry.sync_to_client_manager(self.orchestrator.client_manager)
                    logger.debug("âœ… ç¼“å­˜æ˜ å°„åŒæ­¥åˆ°æ–‡ä»¶æˆåŠŸï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰")
                else:
                    logger.warning("æ— æ³•è§¦å‘ç¼“å­˜æ˜ å°„åŒæ­¥ï¼šcache_managerå’Œregistryéƒ½ä¸å¯ç”¨")

        except Exception as e:
            logger.error(f"Failed to trigger cache mapping sync: {e}")

    async def manual_sync(self) -> Dict[str, Any]:
        """æ‰‹åŠ¨è§¦å‘åŒæ­¥ï¼ˆç”¨äºAPIè°ƒç”¨ï¼‰"""
        logger.info("Manual sync triggered")
        return await self.sync_global_agent_store_from_mcp_json()

    def get_sync_status(self) -> Dict[str, Any]:
        """è·å–åŒæ­¥çŠ¶æ€ä¿¡æ¯"""
        return {
            "is_running": self.is_running,
            "mcp_json_path": self.mcp_json_path,
            "last_change_time": self.last_change_time,
            "sync_lock_locked": self.sync_lock.locked(),
            "file_observer_running": self.file_observer is not None and self.file_observer.is_alive() if self.file_observer else False
        }
