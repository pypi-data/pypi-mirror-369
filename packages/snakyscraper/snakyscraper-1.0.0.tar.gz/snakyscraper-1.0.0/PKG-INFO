Metadata-Version: 2.4
Name: snakyscraper
Version: 1.0.0
Summary: SnakyScraper is a lightweight and Pythonic web scraping toolkit built on top of BeautifulSoup and Requests. It provides an elegant interface for extracting structured HTML and metadata from websites with clean, direct outputs.
Home-page: https://github.com/riodevnet/snakyscraper
Author: Rio Dev
Author-email: my.riodev.net@gmail.com
License: MIT
Keywords: snakyscraper,scraping,scraper
Classifier: Development Status :: 3 - Alpha
Classifier: Intended Audience :: Developers
Classifier: Topic :: Software Development :: Build Tools
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.6
Classifier: Programming Language :: Python :: 3.7
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Programming Language :: Python :: 3.13
Classifier: Programming Language :: Python :: 3.14
Requires-Python: >=3.6
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: requests
Requires-Dist: beautifulsoup4
Requires-Dist: lxml
Dynamic: author
Dynamic: author-email
Dynamic: classifier
Dynamic: description
Dynamic: description-content-type
Dynamic: home-page
Dynamic: keywords
Dynamic: license
Dynamic: license-file
Dynamic: requires-dist
Dynamic: requires-python
Dynamic: summary


# üêç SnakyScraper

**SnakyScraper** is a lightweight and Pythonic web scraping toolkit built on top of BeautifulSoup and Requests. It provides an elegant interface for extracting structured HTML and metadata from websites with clean, direct outputs.

> Fast. Accurate. Snake-style scraping. üêçüéØ

---

## üöÄ Features

- ‚úÖ Extract metadata: title, description, keywords, author, and more
- ‚úÖ Built-in support for Open Graph, Twitter Card, canonical, and CSRF tags
- ‚úÖ Extract HTML structures: `h1`‚Äì`h6`, `p`, `ul`, `ol`, `img`, links
- ‚úÖ Powerful `filter()` method with class, ID, and tag-based selectors
- ‚úÖ `return_html` toggle to return clean text or raw HTML
- ‚úÖ Simple return values: string, list, or dictionary
- ‚úÖ Powered by BeautifulSoup4 and Requests

---

## üì¶ Installation

```bash
pip install snakyscraper
```

> Requires Python 3.7 or later

---

## üõ†Ô∏è Basic Usage

```python
from snakyscraper import SnakyScraper

scraper = SnakyScraper("https://example.com")

# Get the page title
print(scraper.title())  # "Welcome to Example.com"

# Get meta description
print(scraper.description())  # "This is the example meta description."

# Get all <h1> elements
print(scraper.h1())  # ["Welcome", "Latest News"]

# Extract Open Graph metadata
print(scraper.open_graph())  # {"og:title": "...", "og:description": "...", ...}

# Custom filter: find all div.card elements and extract child tags
print(scraper.filter(
    element="div",
    attributes={"class": "card"},
    multiple=True,
    extract=["h1", "p", ".title", "#desc"]
))
```

---

## üß™ Available Methods

### üîπ Page Metadata

```python
scraper.title()
scraper.description()
scraper.keywords()
scraper.keyword_string()
scraper.charset()
scraper.canonical()
scraper.content_type()
scraper.author()
scraper.csrf_token()
scraper.image()
```

### üîπ Open Graph & Twitter Card

```python
scraper.open_graph()
scraper.open_graph("og:title")

scraper.twitter_card()
scraper.twitter_card("twitter:title")
```

### üîπ Headings & Text

```python
scraper.h1()
scraper.h2()
scraper.h3()
scraper.h4()
scraper.h5()
scraper.h6()
scraper.p()
```

### üîπ Lists

```python
scraper.ul()
scraper.ol()
```

### üîπ Images

```python
scraper.images()
scraper.image_details()
```

### üîπ Links

```python
scraper.links()
scraper.link_details()
```

---

## üîç Custom DOM Filtering

Use `filter()` to target specific DOM elements and extract nested content.

#### ‚ñ∏ Single element

```python
scraper.filter(
    element="div",
    attributes={"id": "main"},
    multiple=False,
    extract=[".title", "#description", "p"]
)
```

#### ‚ñ∏ Multiple elements

```python
scraper.filter(
    element="div",
    attributes={"class": "card"},
    multiple=True,
    extract=["h1", ".subtitle", "#meta"]
)
```

> The `extract` argument accepts tag names, class selectors (e.g., `.title`), or ID selectors (e.g., `#meta`).  
> Output keys are automatically normalized:  
> `.title` ‚Üí `class__title`, `#meta` ‚Üí `id__meta`

#### ‚ñ∏ Clean Text Output

You can also disable raw HTML output:

```python
scraper.filter(
    element="p",
    attributes={"class": "dark-text"},
    multiple=True,
    return_html=False
)
```

---

## üì¶ Output Example

```python
scraper.title()
# "Welcome to Example.com"

scraper.h1()
# ["Main Heading", "Another Title"]

scraper.open_graph("og:title")
# "Example OG Title"
```

---

## ü§ù Contributing

Contributions are welcome!  
Found a bug or want to request a feature? Please open an [issue](https://github.com/riodevnet/snakyscraper/issues) or submit a pull request.

---

## üìÑ License

MIT License ¬© 2025 ‚Äî SnakyScraper

---

## üîó Related Projects

- [BeautifulSoup4](https://www.crummy.com/software/BeautifulSoup/)
- [Requests](https://docs.python-requests.org/)
- [lxml](https://lxml.de/)

---

## üí° Why SnakyScraper?

> Think of it as your Pythonic sniper ‚Äî targeting HTML content with precision and elegance.
