Metadata-Version: 2.4
Name: databricks-openai
Version: 0.6.0
Summary: Support for Databricks AI support with OpenAI
Author-email: Databricks <agent-feedback@databricks.com>
License: Apache-2.0
Requires-Python: >=3.10
Requires-Dist: databricks-ai-bridge>=0.7.0
Requires-Dist: databricks-connect<16.4,>=16.1.1
Requires-Dist: databricks-vectorsearch>=0.50
Requires-Dist: langchain>=0.3.0
Requires-Dist: mlflow>=2.20.1
Requires-Dist: openai>=1.99.9
Requires-Dist: pydantic>2.10.0
Requires-Dist: unitycatalog-openai[databricks]>=0.2.0
Provides-Extra: dev
Requires-Dist: databricks-sdk>=0.34.0; extra == 'dev'
Requires-Dist: pytest; extra == 'dev'
Requires-Dist: ruff==0.6.4; extra == 'dev'
Requires-Dist: typing-extensions; extra == 'dev'
Provides-Extra: integration
Requires-Dist: pytest-timeout>=2.3.1; extra == 'integration'
Description-Content-Type: text/markdown

#  Databricks OpenAI Integration

The `databricks-openai` package provides seamless integration of Databricks AI features into OpenAI applications.

## Installation

### From PyPI
```sh
pip install databricks-openai
```

### From Source
```sh
pip install git+https://git@github.com/databricks/databricks-ai-bridge.git#subdirectory=integrations/openai
```

## Key Features

- **Vector Search:** Store and query vector representations using `VectorSearchRetrieverTool`.

## Getting Started

### Use Vector Search on Databricks
```python
# Step 1: call model with VectorSearchRetrieverTool defined
dbvs_tool = VectorSearchRetrieverTool(index_name="catalog.schema.my_index_name")
messages = [
    {"role": "system", "content": "You are a helpful assistant."},
    {
        "role": "user",
        "content": "Using the Databricks documentation, answer what is Spark?"
    }
]
first_response = client.chat.completions.create(
    model="gpt-4o",
    messages=messages,
    tools=[dbvs_tool.tool]
)

# Step 2: Execute function code – parse the model's response and handle function calls.
tool_call = first_response.choices[0].message.tool_calls[0]
args = json.loads(tool_call.function.arguments)
result = dbvs_tool.execute(query=args["query"])  # For self-managed embeddings, optionally pass in openai_client=client

# Step 3: Supply model with results – so it can incorporate them into its final response.
messages.append(first_response.choices[0].message)
messages.append({
    "role": "tool",
    "tool_call_id": tool_call.id,
    "content": json.dumps(result)
})
second_response = client.chat.completions.create(
    model="gpt-4o",
    messages=messages,
    tools=tools
)
```

---

## Contribution Guide
We welcome contributions! Please see our [contribution guidelines](https://github.com/databricks/databricks-ai-bridge/tree/main/integrations/langchain) for details.

## License
This project is licensed under the [MIT License](LICENSE).

Thank you for using Databricks OpenAI!

