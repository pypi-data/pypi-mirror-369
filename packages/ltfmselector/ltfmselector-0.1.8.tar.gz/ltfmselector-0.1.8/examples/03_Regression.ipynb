{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ba5ccec-7dd6-4e6c-a26e-b30ef18b99df",
   "metadata": {},
   "source": [
    "## Example of using LTFMSelector for Regression\n",
    "As an example, we will experiment with the California Housing dataset. The target variable is the median house value for California districts, expressed in hundreds of thousands of dollars ($100,000).\n",
    "\n",
    "This dataset was derived from the 1990 U.S. census, using one row per census block group. A block group is the smallest geographical unit for which the U.S. Census Bureau publishes sample data (a block group typically has a population of 600 to 3,000 people).\n",
    "\n",
    "A household is a group of people residing within a home. Since the average number of rooms and bedrooms in this dataset are provided per household, these columns may take surprisingly large values for block groups with few households and many empty houses, such as vacation resorts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a466b28f-5ab0-484b-8824-2315a93393a6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'env'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mltfmselector\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LTFMSelector\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repo/ltfmselector/src/ltfmselector/__init__.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mltfmselector\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LTFMSelector\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repo/ltfmselector/src/ltfmselector/ltfmselector.py:10\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcollections\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m defaultdict\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01menv\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Environment\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ReplayMemory, DQN, Transition\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mitertools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m count\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'env'"
     ]
    }
   ],
   "source": [
    "from ltfmselector import LTFMSelector\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_california_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f813a4-f3b5-4cef-b6e0-3dcbf7f4d250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the California Housing Dataset\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "# Get data\n",
    "X = housing['data']\n",
    "\n",
    "# Get target\n",
    "y = housing['target']\n",
    "\n",
    "# Get feature names\n",
    "feature_names = housing['feature_names']\n",
    "\n",
    "# Get description\n",
    "dataset_description = housing['DESCR']\n",
    "print(dataset_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44da7d5b-906b-4de5-bf42-c7cab0f52b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data into pandas DataFrame\n",
    "housing_df = pd.DataFrame(\n",
    "    np.c_[X, y], columns = np.append(feature_names, ['target'])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ac1475-df9c-49ff-889b-06079cf9beab",
   "metadata": {},
   "source": [
    "The data will then be split for training and testing.\n",
    "\n",
    "Note: It is important that the training datasets (`X`) are passed as `pandas.DataFrame` and the label (`y`) as `pandas.Series`. Other forms will be accomodated for in later versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6195128c-4414-458c-9a53-78038eae9325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset for training and test\n",
    "X_df = housing_df.drop(['target'], axis=1)\n",
    "y_df = housing_df['target']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_df, y_df, test_size=0.2, random_state=5)\n",
    "\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "y_test  = y_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f6ac7b-9acb-4079-8a83-ee671b5f4e88",
   "metadata": {},
   "source": [
    "We will now train an agent using LTFMSelector to select features and a prediction models, tailored to each sample.\n",
    "\n",
    "When initializing LTFMSelector, one necessary hyperparameter is the number of episodes, over which an agent is trained. My personal recommendation is set roughly 2-3 times the number of training examples.\n",
    " - So for example here, we have 16512 training examples: Hence, ~32000 episodes\n",
    "\n",
    "Another hyperparameter that should be set is `ptype`, which should be set to `regression` for this example.\n",
    "\n",
    "If `pModels=None`, a default choice of:\n",
    " - Support Vector Machine\n",
    " - Random Forest\n",
    " - Ridge Regression (Linear least squares with L2 regularization)\n",
    "will be implemented, all using the scikit-learn library with default hyperparameters. Users can also pass a list of regression model objects, which must have `fit` and `predict` call functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1065057b-f85d-4202-a651-a959ef4fd3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training an agent using LTFMSelector to select features and an appropriate prediction model tailored to each sample\n",
    "AgentSelector = LTFMSelector(100, pType='regression') # If you got time, go for 20000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa45ff2-6a3c-4965-a1d5-18c05a2acb73",
   "metadata": {},
   "source": [
    "Train the agent by passing the training examples and label.\n",
    "\n",
    "The hyperparameter `agent_neuralnetwork` receives as an input a PyTorch neural network which will be used to learn the agent's policy. If `None`, a feed-forward (multilayer-perceptron) of with two hidden layers, each with 1024 units will be used.\n",
    "\n",
    "`lr` refers to the learning rate of the `AdamW` optimizer, used to update the policy network.\n",
    "\n",
    "The `fit` function returns a `dict<dict>` object, storing meta-information during the training process.\n",
    "\n",
    "Note: Just for demo purposes, training an agent over 1300 episodes may take some time but if you are simply interested in getting a feel for the interface then just set the number of episodes to 30 or less for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5592e6-bfef-4a6d-83cc-821f1ba6c16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now letting the agent train, this could take some time ...\n",
    "doc = AgentSelector.fit(X_train, y_train, agent_neuralnetwork=None, lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070e4333-db7a-4e72-8b14-f4de73da471d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check out the regression model performance in terms of the coefficient of determination\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"R2: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19de8a4-6609-40fe-8ba1-ae821264801f",
   "metadata": {},
   "source": [
    "For examples of how you can investigate the features and models selected per sample, simply refer to the other previous notebooks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
