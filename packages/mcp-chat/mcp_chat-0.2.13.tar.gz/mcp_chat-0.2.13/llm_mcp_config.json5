// The configuration file format is [JSON5](https://json5.org/),
// where comments and trailing commas are allowed.
// The file format is further extended to replace `${...}` notations
// with the values of corresponding environment variables.
// Keep all the credentials and private into the `.env` file
// and refer to them with `${...}` notation as needed.
{
    // "llm": {
    //     // https://docs.anthropic.com/en/docs/about-claude/pricing
    //     // https://console.anthropic.com/settings/billing
    //     "provider": "anthropic",
    //     "model": "claude-3-5-haiku-latest",
    //     // "model": "claude-sonnet-4-0",
    //     // "temperature": 0.0,
    //     // "max_tokens": 10000,
    // },

    // "llm": {
    //     // https://platform.openai.com/docs/pricing
    //     // https://platform.openai.com/settings/organization/billing/overview
    //     "provider": "openai",
    //     "model": "gpt-4.1-nano",
    //     // "model": "gpt-5-mini",
    //     // "temperature": 0.0,  //  'temperature' is not supported with "o4-mini"
    //     // "max_completion_tokens": 10000,  //  Use 'max_completion_tokens' instead of 'max_tokens'
    // },

    "llm": {
        // https://ai.google.dev/gemini-api/docs/pricing
        // https://console.cloud.google.com/billing
        "provider": "google_genai",
        "model": "gemini-2.5-flash",
        // "model": "gemini-2.5-pro",
        // "temperature": 0.0,
        // "max_tokens": 10000,
    },

    // "llm": {
    //     // hhttps://console.x.ai/
    //     "provider": "xai",
    //     "model": "grok-3-mini",
    //     // "model": "grok-4",
    // },

    // "llm": {
    //     // https://cloud.cerebras.ai
    //     "provider": "cerebras",
    //     "model": "gpt-oss-120b",
    // },

    // "llm": {
    //     // ttps://console.groq.com/keys
    //     "provider": "groq",
    //     "model": "openai/gpt-oss-20b",
    //     // "model": "openai/gpt-oss-120b",
    // },

    "example_queries": [
        "Read the news headlines on bbc.com",
        "Read and briefly summarize the LICENSE file",
        "Are there any weather alerts in California?",
        // "What's the news from Tokyo today?",
        // "Open the webpage at bbc.com",
        // "Tell me about my Notion account",
    ],

    "mcp_servers": {
        // https://github.com/modelcontextprotocol/servers/tree/main/src/filesystem
        "filesystem": {
            "command": "npx",
            "args": [
                "-y",
                "@modelcontextprotocol/server-filesystem",
                "."
            ]
        },

        // https://github.com/modelcontextprotocol/servers/tree/main/src/fetch
        "fetch": {
            "command": "uvx",
            "args": [
                "mcp-server-fetch"
            ]
        },

        // https://github.com/modelcontextprotocol/quickstart-resources/tree/main/weather-server-python
        "us-weather": {  // US weather only
            "command": "npx",
            "args": [
                "-y",
                "@h1deya/mcp-server-weather"
            ]
        },

        // // Auto-detection: tries Streamable HTTP first, falls back to SSE
        // "auto-detect-server": {
        //     "url": "http://${SERVER_HOST}:${SERVER_PORT}/..."
        // },

        // // WebSocket
        // "ws-server-name": {
        //     "url": "ws://${WS_SERVER_HOST}:${WS_SERVER_PORT}/..."
        // },

        // // Test SSE connection with the auto fallback
        // // See the comments at the top of src/index.ts
        // us-weather: {
        //     "url": "http://localhost:${SSE_SERVER_PORT}/sse"
        // },

        // // Example of authentication via Authorization header
        // // https://github.com/github/github-mcp-server?tab=readme-ov-file#remote-github-mcp-server
        // "github": {
        //   // To avoid auto protocol fallback, specify the protocol explicitly when using authentication
        //   "type": "http",  // or `transport: "http",`
        //   "url": "https://api.githubcopilot.com/mcp/",
        //   "headers": {
        //     "Authorization": "Bearer ${GITHUB_PERSONAL_ACCESS_TOKEN}"
        //   }
        // },
        // // NOTE: When accessing the GitHub MCP server, [GitHub PAT (Personal Access Token)](https://github.com/settings/personal-access-tokens)
        // // alone is not enough; your GitHub account must have an active Copilot subscription or be assigned a Copilot license through your organization.

        // // https://github.com/microsoft/playwright-mcp
        // "playwright": {
        //     "command": "npx",
        //     "args": [ "-y", "@playwright/mcp@latest" ]
        // },

        // // https://github.com/modelcontextprotocol/servers/tree/main/src/brave-search
        // "brave-search": {
        //     "command": "npx",
        //     "args": [ "-y", "@modelcontextprotocol/server-brave-search"],
        //     "env": { "BRAVE_API_KEY": "${BRAVE_API_KEY}" }
        // },

        // notion: {
        //   "command": "npx",
        //   "args": ["-y", "@notionhq/notion-mcp-server"],
        //   "env": {
        //     // Although the following implies that this MCP server is designed for
        //     // OpenAI LLMs, it works fine with others models.
        //     // Tested Claude and Gemini
        //     "OPENAPI_MCP_HEADERS": '{"Authorization": "Bearer ${NOTION_INTEGRATION_SECRET}", "Notion-Version": "2022-06-28"}'
        //   },
        // },
    }
}
