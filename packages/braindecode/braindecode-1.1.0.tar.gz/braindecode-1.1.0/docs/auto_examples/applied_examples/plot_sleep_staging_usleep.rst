
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/applied_examples/plot_sleep_staging_usleep.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_examples_applied_examples_plot_sleep_staging_usleep.py>`
        to download the full example code.

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_applied_examples_plot_sleep_staging_usleep.py:

.. _sleep-staging-usleep:

Sleep staging on the Sleep Physionet dataset using U-Sleep network
==================================================================

.. note::
    Please take a look at the simpler sleep staging example
    :ref:`sleep-staging-physionet-chambon2018`
    before going through this example. The current example uses a more complex
    architecture and a sequence-to-sequence (seq2seq) approach.

This tutorial shows how to train and test a sleep staging neural network with
Braindecode. We adapt the U-Sleep approach of [1]_ to learn on sequences of EEG
windows using the openly accessible Sleep Physionet dataset [2]_ [3]_.

.. warning::
    The example is written to have a very short execution time.
    This number of epochs is here too small and very few recordings are used.
    To obtain competitive results you need to use more data and more epochs.

.. GENERATED FROM PYTHON SOURCE LINES 22-28

.. code-block:: Python

    # Authors: Theo Gnassounou <theo.gnassounou@inria.fr>
    #          Omar Chehab <l-emir-omar.chehab@inria.fr>
    #
    # License: BSD (3-clause)









.. GENERATED FROM PYTHON SOURCE LINES 29-41

Loading and preprocessing the dataset
-------------------------------------

Loading
~~~~~~~

First, we load the data using the
:class:`braindecode.datasets.sleep_physionet.SleepPhysionet` class. We load
two recordings from two different individuals: we will use the first one to
train our network and the second one to evaluate performance (as in the `MNE
sleep staging example <mne-clinical-60-sleep_>`_).


.. GENERATED FROM PYTHON SOURCE LINES 41-50

.. code-block:: Python


    from braindecode.datasets import SleepPhysionet

    subject_ids = [0, 1]
    crop = (0, 30 * 400)  # we only keep 400 windows of 30s to speed example
    dataset = SleepPhysionet(
        subject_ids=subject_ids, recording_ids=[2], crop_wake_mins=30, crop=crop
    )





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Extracting EDF parameters from /Users/baristim/mne_data/physionet-sleep-data/SC4002E0-PSG.edf...
    EDF file detected
    Setting channel info structure...
    Creating raw.info structure...
    Extracting EDF parameters from /Users/baristim/mne_data/physionet-sleep-data/SC4012E0-PSG.edf...
    EDF file detected
    Setting channel info structure...
    Creating raw.info structure...




.. GENERATED FROM PYTHON SOURCE LINES 51-58

Preprocessing
~~~~~~~~~~~~~

Next, we preprocess the raw data. We scale each channel recording-wise to
have zero median and unit interquartile range. We don't upsample to 128 Hz as
done in [1]_ so that we keep the example as light as possible. No filtering
is described in [1]_.

.. GENERATED FROM PYTHON SOURCE LINES 58-68

.. code-block:: Python


    from sklearn.preprocessing import robust_scale

    from braindecode.preprocessing import Preprocessor, preprocess

    preprocessors = [Preprocessor(robust_scale, channel_wise=True)]

    # Transform the data
    preprocess(dataset, preprocessors)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Reading 0 ... 1200000  =      0.000 ... 12000.000 secs...
    Reading 0 ... 1200000  =      0.000 ... 12000.000 secs...

    <braindecode.datasets.sleep_physionet.SleepPhysionet object at 0x35b6227b0>



.. GENERATED FROM PYTHON SOURCE LINES 69-73

Extract windows
~~~~~~~~~~~~~~~

We extract 30-s windows to be used in the classification task.

.. GENERATED FROM PYTHON SOURCE LINES 73-99

.. code-block:: Python


    from braindecode.preprocessing import create_windows_from_events

    mapping = {  # We merge stages 3 and 4 following AASM standards.
        "Sleep stage W": 0,
        "Sleep stage 1": 1,
        "Sleep stage 2": 2,
        "Sleep stage 3": 3,
        "Sleep stage 4": 3,
        "Sleep stage R": 4,
    }

    window_size_s = 30
    sfreq = 100
    window_size_samples = window_size_s * sfreq

    windows_dataset = create_windows_from_events(
        dataset,
        trial_start_offset_samples=0,
        trial_stop_offset_samples=0,
        window_size_samples=window_size_samples,
        window_stride_samples=window_size_samples,
        preload=True,
        mapping=mapping,
    )





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Used Annotations descriptions: ['Sleep stage 1', 'Sleep stage 2', 'Sleep stage 3', 'Sleep stage 4', 'Sleep stage R', 'Sleep stage W']
    Used Annotations descriptions: ['Sleep stage 1', 'Sleep stage 2', 'Sleep stage 3', 'Sleep stage 4', 'Sleep stage R', 'Sleep stage W']




.. GENERATED FROM PYTHON SOURCE LINES 100-105

Split dataset into train and valid
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

We split the dataset into training and validation set taking
every other subject as train or valid.

.. GENERATED FROM PYTHON SOURCE LINES 105-110

.. code-block:: Python


    split_ids = dict(train=subject_ids[::2], valid=subject_ids[1::2])
    splits = windows_dataset.split(split_ids)
    train_set, valid_set = splits["train"], splits["valid"]








.. GENERATED FROM PYTHON SOURCE LINES 111-120

Create sequence samplers
------------------------

Following the sequence-to-sequence approach of [1]_, we need to provide our
neural network with sequences of windows. We can achieve this by defining
Sampler objects that return sequences of windows.
Non-overlapping sequences of 35 windows are used in [1]_, however to limit
the memory requirements for this example we use shorter sequences of 3
windows.

.. GENERATED FROM PYTHON SOURCE LINES 120-135

.. code-block:: Python


    from braindecode.samplers import SequenceSampler

    n_windows = 3  # Sequences of 3 consecutive windows; originally 35 in paper
    n_windows_stride = 3  # Non-overlapping sequences

    train_sampler = SequenceSampler(
        train_set.get_metadata(), n_windows, n_windows_stride, randomize=True
    )
    valid_sampler = SequenceSampler(valid_set.get_metadata(), n_windows, n_windows_stride)

    # Print number of examples per class
    print(len(train_sampler))
    print(len(valid_sampler))





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    133
    133




.. GENERATED FROM PYTHON SOURCE LINES 136-140

Finally, since some sleep stages appear a lot more often than others (e.g.
most of the night is spent in the N2 stage), the classes are imbalanced. To
avoid overfitting to the more frequent classes, we compute weights that we
will provide to the loss function when training.

.. GENERATED FROM PYTHON SOURCE LINES 140-147

.. code-block:: Python


    import numpy as np
    from sklearn.utils import compute_class_weight

    y_train = [train_set[idx][1][1] for idx in train_sampler]
    class_weights = compute_class_weight("balanced", classes=np.unique(y_train), y=y_train)








.. GENERATED FROM PYTHON SOURCE LINES 148-154

Create model
------------

We can now create the deep learning model. In this tutorial, we use the
U-Sleep architecture introduced in [1]_, which is fully convolutional
neural network.

.. GENERATED FROM PYTHON SOURCE LINES 154-188

.. code-block:: Python


    import torch

    from braindecode.models import USleep
    from braindecode.util import set_random_seeds

    cuda = torch.cuda.is_available()  # check if GPU is available
    device = "cuda" if torch.cuda.is_available() else "cpu"
    if cuda:
        torch.backends.cudnn.benchmark = True
    # Set random seed to be able to roughly reproduce results
    # Note that with cudnn benchmark set to True, GPU indeterminism
    # may still make results substantially different between runs.
    # To obtain more consistent results at the cost of increased computation time,
    # you can set `cudnn_benchmark=False` in `set_random_seeds`
    # or remove `torch.backends.cudnn.benchmark = True`
    set_random_seeds(seed=31, cuda=cuda)

    n_classes = 5
    classes = list(range(n_classes))
    # Extract number of channels and time steps from dataset
    in_chans, input_size_samples = train_set[0][0].shape
    model = USleep(
        n_chans=in_chans,
        sfreq=sfreq,
        depth=12,
        with_skip_connection=True,
        n_outputs=n_classes,
        n_times=input_size_samples,
    )

    # Send model to GPU
    if cuda:
        model.cuda()







.. GENERATED FROM PYTHON SOURCE LINES 189-204

Training
--------

We can now train our network. :class:`braindecode.classifier.EEGClassifier` is a
braindecode object that is responsible for managing the training of neural
networks. It inherits from :class:`skorch.classifier.NeuralNetClassifier`, so the
training logic is the same as in
`<skorch_>`_.

.. note::
   We use different hyperparameters from [1]_, as these hyperparameters were
   optimized on different datasets and with a different number of recordings.
   Generally speaking, it is recommended to perform hyperparameter
   optimization if reusing this code on a different dataset or with more
   recordings.

.. GENERATED FROM PYTHON SOURCE LINES 204-258

.. code-block:: Python


    from skorch.callbacks import EpochScoring
    from skorch.helper import predefined_split

    from braindecode import EEGClassifier

    lr = 1e-3
    batch_size = 32
    n_epochs = 3  # we use few epochs for speed and but more than one for plotting

    from sklearn.metrics import balanced_accuracy_score


    def balanced_accuracy_multi(model, X, y):
        y_pred = model.predict(X)
        return balanced_accuracy_score(y.flatten(), y_pred.flatten())


    train_bal_acc = EpochScoring(
        scoring=balanced_accuracy_multi,
        on_train=True,
        name="train_bal_acc",
        lower_is_better=False,
    )
    valid_bal_acc = EpochScoring(
        scoring=balanced_accuracy_multi,
        on_train=False,
        name="valid_bal_acc",
        lower_is_better=False,
    )
    callbacks = [("train_bal_acc", train_bal_acc), ("valid_bal_acc", valid_bal_acc)]

    clf = EEGClassifier(
        model,
        criterion=torch.nn.CrossEntropyLoss,
        criterion__weight=torch.Tensor(class_weights).to(device),
        optimizer=torch.optim.Adam,
        iterator_train__shuffle=False,
        iterator_train__sampler=train_sampler,
        iterator_valid__sampler=valid_sampler,
        train_split=predefined_split(valid_set),  # using valid_set for validation
        optimizer__lr=lr,
        batch_size=batch_size,
        callbacks=callbacks,
        device=device,
        classes=classes,
    )
    # Deactivate the default valid_acc callback:
    clf.set_params(callbacks__valid_acc=None)

    # Model training for a specified number of epochs. `y` is None as it is already
    # supplied in the dataset.
    clf.fit(train_set, y=None, epochs=n_epochs)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    /Users/baristim/miniforge3/envs/braindecode-official/lib/python3.12/site-packages/torch/nn/modules/conv.py:370: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/Convolution.cpp:1037.)
      return F.conv1d(
      epoch    train_bal_acc    train_loss    valid_bal_acc    valid_loss     dur
    -------  ---------------  ------------  ---------------  ------------  ------
          1           0.2040        1.6129           0.1707        1.5807  7.0672
          2           0.2224        1.5430           0.1594        1.5866  7.4234
          3           0.3464        1.4928           0.1853        1.6026  7.3874


.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <style>#sk-container-id-2 {
      /* Definition of color scheme common for light and dark mode */
      --sklearn-color-text: black;
      --sklearn-color-line: gray;
      /* Definition of color scheme for unfitted estimators */
      --sklearn-color-unfitted-level-0: #fff5e6;
      --sklearn-color-unfitted-level-1: #f6e4d2;
      --sklearn-color-unfitted-level-2: #ffe0b3;
      --sklearn-color-unfitted-level-3: chocolate;
      /* Definition of color scheme for fitted estimators */
      --sklearn-color-fitted-level-0: #f0f8ff;
      --sklearn-color-fitted-level-1: #d4ebff;
      --sklearn-color-fitted-level-2: #b3dbfd;
      --sklearn-color-fitted-level-3: cornflowerblue;

      /* Specific color for light theme */
      --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
      --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));
      --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
      --sklearn-color-icon: #696969;

      @media (prefers-color-scheme: dark) {
        /* Redefinition of color scheme for dark theme */
        --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
        --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));
        --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
        --sklearn-color-icon: #878787;
      }
    }

    #sk-container-id-2 {
      color: var(--sklearn-color-text);
    }

    #sk-container-id-2 pre {
      padding: 0;
    }

    #sk-container-id-2 input.sk-hidden--visually {
      border: 0;
      clip: rect(1px 1px 1px 1px);
      clip: rect(1px, 1px, 1px, 1px);
      height: 1px;
      margin: -1px;
      overflow: hidden;
      padding: 0;
      position: absolute;
      width: 1px;
    }

    #sk-container-id-2 div.sk-dashed-wrapped {
      border: 1px dashed var(--sklearn-color-line);
      margin: 0 0.4em 0.5em 0.4em;
      box-sizing: border-box;
      padding-bottom: 0.4em;
      background-color: var(--sklearn-color-background);
    }

    #sk-container-id-2 div.sk-container {
      /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
         but bootstrap.min.css set `[hidden] { display: none !important; }`
         so we also need the `!important` here to be able to override the
         default hidden behavior on the sphinx rendered scikit-learn.org.
         See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
      display: inline-block !important;
      position: relative;
    }

    #sk-container-id-2 div.sk-text-repr-fallback {
      display: none;
    }

    div.sk-parallel-item,
    div.sk-serial,
    div.sk-item {
      /* draw centered vertical line to link estimators */
      background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
      background-size: 2px 100%;
      background-repeat: no-repeat;
      background-position: center center;
    }

    /* Parallel-specific style estimator block */

    #sk-container-id-2 div.sk-parallel-item::after {
      content: "";
      width: 100%;
      border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
      flex-grow: 1;
    }

    #sk-container-id-2 div.sk-parallel {
      display: flex;
      align-items: stretch;
      justify-content: center;
      background-color: var(--sklearn-color-background);
      position: relative;
    }

    #sk-container-id-2 div.sk-parallel-item {
      display: flex;
      flex-direction: column;
    }

    #sk-container-id-2 div.sk-parallel-item:first-child::after {
      align-self: flex-end;
      width: 50%;
    }

    #sk-container-id-2 div.sk-parallel-item:last-child::after {
      align-self: flex-start;
      width: 50%;
    }

    #sk-container-id-2 div.sk-parallel-item:only-child::after {
      width: 0;
    }

    /* Serial-specific style estimator block */

    #sk-container-id-2 div.sk-serial {
      display: flex;
      flex-direction: column;
      align-items: center;
      background-color: var(--sklearn-color-background);
      padding-right: 1em;
      padding-left: 1em;
    }


    /* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
    clickable and can be expanded/collapsed.
    - Pipeline and ColumnTransformer use this feature and define the default style
    - Estimators will overwrite some part of the style using the `sk-estimator` class
    */

    /* Pipeline and ColumnTransformer style (default) */

    #sk-container-id-2 div.sk-toggleable {
      /* Default theme specific background. It is overwritten whether we have a
      specific estimator or a Pipeline/ColumnTransformer */
      background-color: var(--sklearn-color-background);
    }

    /* Toggleable label */
    #sk-container-id-2 label.sk-toggleable__label {
      cursor: pointer;
      display: block;
      width: 100%;
      margin-bottom: 0;
      padding: 0.5em;
      box-sizing: border-box;
      text-align: center;
    }

    #sk-container-id-2 label.sk-toggleable__label-arrow:before {
      /* Arrow on the left of the label */
      content: "▸";
      float: left;
      margin-right: 0.25em;
      color: var(--sklearn-color-icon);
    }

    #sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {
      color: var(--sklearn-color-text);
    }

    /* Toggleable content - dropdown */

    #sk-container-id-2 div.sk-toggleable__content {
      max-height: 0;
      max-width: 0;
      overflow: hidden;
      text-align: left;
      /* unfitted */
      background-color: var(--sklearn-color-unfitted-level-0);
    }

    #sk-container-id-2 div.sk-toggleable__content.fitted {
      /* fitted */
      background-color: var(--sklearn-color-fitted-level-0);
    }

    #sk-container-id-2 div.sk-toggleable__content pre {
      margin: 0.2em;
      border-radius: 0.25em;
      color: var(--sklearn-color-text);
      /* unfitted */
      background-color: var(--sklearn-color-unfitted-level-0);
    }

    #sk-container-id-2 div.sk-toggleable__content.fitted pre {
      /* unfitted */
      background-color: var(--sklearn-color-fitted-level-0);
    }

    #sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {
      /* Expand drop-down */
      max-height: 200px;
      max-width: 100%;
      overflow: auto;
    }

    #sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
      content: "▾";
    }

    /* Pipeline/ColumnTransformer-specific style */

    #sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
      color: var(--sklearn-color-text);
      background-color: var(--sklearn-color-unfitted-level-2);
    }

    #sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
      background-color: var(--sklearn-color-fitted-level-2);
    }

    /* Estimator-specific style */

    /* Colorize estimator box */
    #sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
      /* unfitted */
      background-color: var(--sklearn-color-unfitted-level-2);
    }

    #sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
      /* fitted */
      background-color: var(--sklearn-color-fitted-level-2);
    }

    #sk-container-id-2 div.sk-label label.sk-toggleable__label,
    #sk-container-id-2 div.sk-label label {
      /* The background is the default theme color */
      color: var(--sklearn-color-text-on-default-background);
    }

    /* On hover, darken the color of the background */
    #sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {
      color: var(--sklearn-color-text);
      background-color: var(--sklearn-color-unfitted-level-2);
    }

    /* Label box, darken color on hover, fitted */
    #sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
      color: var(--sklearn-color-text);
      background-color: var(--sklearn-color-fitted-level-2);
    }

    /* Estimator label */

    #sk-container-id-2 div.sk-label label {
      font-family: monospace;
      font-weight: bold;
      display: inline-block;
      line-height: 1.2em;
    }

    #sk-container-id-2 div.sk-label-container {
      text-align: center;
    }

    /* Estimator-specific */
    #sk-container-id-2 div.sk-estimator {
      font-family: monospace;
      border: 1px dotted var(--sklearn-color-border-box);
      border-radius: 0.25em;
      box-sizing: border-box;
      margin-bottom: 0.5em;
      /* unfitted */
      background-color: var(--sklearn-color-unfitted-level-0);
    }

    #sk-container-id-2 div.sk-estimator.fitted {
      /* fitted */
      background-color: var(--sklearn-color-fitted-level-0);
    }

    /* on hover */
    #sk-container-id-2 div.sk-estimator:hover {
      /* unfitted */
      background-color: var(--sklearn-color-unfitted-level-2);
    }

    #sk-container-id-2 div.sk-estimator.fitted:hover {
      /* fitted */
      background-color: var(--sklearn-color-fitted-level-2);
    }

    /* Specification for estimator info (e.g. "i" and "?") */

    /* Common style for "i" and "?" */

    .sk-estimator-doc-link,
    a:link.sk-estimator-doc-link,
    a:visited.sk-estimator-doc-link {
      float: right;
      font-size: smaller;
      line-height: 1em;
      font-family: monospace;
      background-color: var(--sklearn-color-background);
      border-radius: 1em;
      height: 1em;
      width: 1em;
      text-decoration: none !important;
      margin-left: 1ex;
      /* unfitted */
      border: var(--sklearn-color-unfitted-level-1) 1pt solid;
      color: var(--sklearn-color-unfitted-level-1);
    }

    .sk-estimator-doc-link.fitted,
    a:link.sk-estimator-doc-link.fitted,
    a:visited.sk-estimator-doc-link.fitted {
      /* fitted */
      border: var(--sklearn-color-fitted-level-1) 1pt solid;
      color: var(--sklearn-color-fitted-level-1);
    }

    /* On hover */
    div.sk-estimator:hover .sk-estimator-doc-link:hover,
    .sk-estimator-doc-link:hover,
    div.sk-label-container:hover .sk-estimator-doc-link:hover,
    .sk-estimator-doc-link:hover {
      /* unfitted */
      background-color: var(--sklearn-color-unfitted-level-3);
      color: var(--sklearn-color-background);
      text-decoration: none;
    }

    div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
    .sk-estimator-doc-link.fitted:hover,
    div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
    .sk-estimator-doc-link.fitted:hover {
      /* fitted */
      background-color: var(--sklearn-color-fitted-level-3);
      color: var(--sklearn-color-background);
      text-decoration: none;
    }

    /* Span, style for the box shown on hovering the info icon */
    .sk-estimator-doc-link span {
      display: none;
      z-index: 9999;
      position: relative;
      font-weight: normal;
      right: .2ex;
      padding: .5ex;
      margin: .5ex;
      width: min-content;
      min-width: 20ex;
      max-width: 50ex;
      color: var(--sklearn-color-text);
      box-shadow: 2pt 2pt 4pt #999;
      /* unfitted */
      background: var(--sklearn-color-unfitted-level-0);
      border: .5pt solid var(--sklearn-color-unfitted-level-3);
    }

    .sk-estimator-doc-link.fitted span {
      /* fitted */
      background: var(--sklearn-color-fitted-level-0);
      border: var(--sklearn-color-fitted-level-3);
    }

    .sk-estimator-doc-link:hover span {
      display: block;
    }

    /* "?"-specific style due to the `<a>` HTML tag */

    #sk-container-id-2 a.estimator_doc_link {
      float: right;
      font-size: 1rem;
      line-height: 1em;
      font-family: monospace;
      background-color: var(--sklearn-color-background);
      border-radius: 1rem;
      height: 1rem;
      width: 1rem;
      text-decoration: none;
      /* unfitted */
      color: var(--sklearn-color-unfitted-level-1);
      border: var(--sklearn-color-unfitted-level-1) 1pt solid;
    }

    #sk-container-id-2 a.estimator_doc_link.fitted {
      /* fitted */
      border: var(--sklearn-color-fitted-level-1) 1pt solid;
      color: var(--sklearn-color-fitted-level-1);
    }

    /* On hover */
    #sk-container-id-2 a.estimator_doc_link:hover {
      /* unfitted */
      background-color: var(--sklearn-color-unfitted-level-3);
      color: var(--sklearn-color-background);
      text-decoration: none;
    }

    #sk-container-id-2 a.estimator_doc_link.fitted:hover {
      /* fitted */
      background-color: var(--sklearn-color-fitted-level-3);
    }
    </style><div id="sk-container-id-2" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>&lt;class &#x27;braindecode.classifier.EEGClassifier&#x27;&gt;[initialized](
      module_=======================================================================================================================================================
      Layer (type (var_name):depth-idx)                  Input Shape               Output Shape              Param #                   Kernel Shape
      ======================================================================================================================================================
      USleep (USleep)                                    [1, 2, 3000]              [1, 5]                    --                        --
      ├─ModuleList (encoder_blocks): 1-1                 --                        --                        --                        --
      │    └─_EncoderBlock (0): 2-1                      [1, 2, 3000]              [1, 6, 1500]              --                        7
      │    │    └─Sequential (block_prepool): 3-1        [1, 2, 3000]              [1, 6, 3000]              102                       --
      │    │    └─MaxPool1d (maxpool): 3-2               [1, 6, 3000]              [1, 6, 1500]              --                        2
      │    └─_EncoderBlock (1): 2-2                      [1, 6, 1500]              [1, 9, 750]               --                        7
      │    │    └─Sequential (block_prepool): 3-3        [1, 6, 1500]              [1, 9, 1500]              405                       --
      │    │    └─MaxPool1d (maxpool): 3-4               [1, 9, 1500]              [1, 9, 750]               --                        2
      │    └─_EncoderBlock (2): 2-3                      [1, 9, 750]               [1, 11, 375]              --                        7
      │    │    └─Sequential (block_prepool): 3-5        [1, 9, 750]               [1, 11, 750]              726                       --
      │    │    └─MaxPool1d (maxpool): 3-6               [1, 11, 750]              [1, 11, 375]              --                        2
      │    └─_EncoderBlock (3): 2-4                      [1, 11, 375]              [1, 15, 188]              --                        7
      │    │    └─Sequential (block_prepool): 3-7        [1, 11, 375]              [1, 15, 375]              1,200                     --
      │    │    └─ConstantPad1d (pad): 3-8               [1, 15, 375]              [1, 15, 377]              --                        --
      │    │    └─MaxPool1d (maxpool): 3-9               [1, 15, 377]              [1, 15, 188]              --                        2
      │    └─_EncoderBlock (4): 2-5                      [1, 15, 188]              [1, 20, 94]               --                        7
      │    │    └─Sequential (block_prepool): 3-10       [1, 15, 188]              [1, 20, 188]              2,160                     --
      │    │    └─MaxPool1d (maxpool): 3-11              [1, 20, 188]              [1, 20, 94]               --                        2
      │    └─_EncoderBlock (5): 2-6                      [1, 20, 94]               [1, 28, 47]               --                        7
      │    │    └─Sequential (block_prepool): 3-12       [1, 20, 94]               [1, 28, 94]               4,004                     --
      │    │    └─MaxPool1d (maxpool): 3-13              [1, 28, 94]               [1, 28, 47]               --                        2
      │    └─_EncoderBlock (6): 2-7                      [1, 28, 47]               [1, 40, 24]               --                        7
      │    │    └─Sequential (block_prepool): 3-14       [1, 28, 47]               [1, 40, 47]               7,960                     --
      │    │    └─ConstantPad1d (pad): 3-15              [1, 40, 47]               [1, 40, 49]               --                        --
      │    │    └─MaxPool1d (maxpool): 3-16              [1, 40, 49]               [1, 40, 24]               --                        2
      │    └─_EncoderBlock (7): 2-8                      [1, 40, 24]               [1, 55, 12]               --                        7
      │    │    └─Sequential (block_prepool): 3-17       [1, 40, 24]               [1, 55, 24]               15,565                    --
      │    │    └─MaxPool1d (maxpool): 3-18              [1, 55, 24]               [1, 55, 12]               --                        2
      │    └─_EncoderBlock (8): 2-9                      [1, 55, 12]               [1, 77, 6]                --                        7
      │    │    └─Sequential (block_prepool): 3-19       [1, 55, 12]               [1, 77, 12]               29,876                    --
      │    │    └─MaxPool1d (maxpool): 3-20              [1, 77, 12]               [1, 77, 6]                --                        2
      │    └─_EncoderBlock (9): 2-10                     [1, 77, 6]                [1, 108, 3]               --                        7
      │    │    └─Sequential (block_prepool): 3-21       [1, 77, 6]                [1, 108, 6]               58,536                    --
      │    │    └─MaxPool1d (maxpool): 3-22              [1, 108, 6]               [1, 108, 3]               --                        2
      │    └─_EncoderBlock (10): 2-11                    [1, 108, 3]               [1, 152, 2]               --                        7
      │    │    └─Sequential (block_prepool): 3-23       [1, 108, 3]               [1, 152, 3]               115,368                   --
      │    │    └─ConstantPad1d (pad): 3-24              [1, 152, 3]               [1, 152, 5]               --                        --
      │    │    └─MaxPool1d (maxpool): 3-25              [1, 152, 5]               [1, 152, 2]               --                        2
      │    └─_EncoderBlock (11): 2-12                    [1, 152, 2]               [1, 214, 1]               --                        7
      │    │    └─Sequential (block_prepool): 3-26       [1, 152, 2]               [1, 214, 2]               228,338                   --
      │    │    └─MaxPool1d (maxpool): 3-27              [1, 214, 2]               [1, 214, 1]               --                        2
      ├─Sequential (bottom): 1-2                         [1, 214, 1]               [1, 302, 1]               --                        --
      │    └─Conv1d (0): 2-13                            [1, 214, 1]               [1, 302, 1]               452,698                   [7]
      │    └─ELU (1): 2-14                               [1, 302, 1]               [1, 302, 1]               --                        --
      │    └─BatchNorm1d (2): 2-15                       [1, 302, 1]               [1, 302, 1]               604                       --
      ├─ModuleList (decoder_blocks): 1-3                 --                        --                        --                        --
      │    └─_DecoderBlock (0): 2-16                     [1, 302, 1]               [1, 214, 2]               --                        7
      │    │    └─Sequential (block_preskip): 3-28       [1, 302, 1]               [1, 214, 2]               129,898                   --
      │    │    └─Sequential (block_postskip): 3-29      [1, 428, 2]               [1, 214, 2]               641,786                   --
      │    └─_DecoderBlock (1): 2-17                     [1, 214, 2]               [1, 152, 3]               --                        7
      │    │    └─Sequential (block_preskip): 3-30       [1, 214, 2]               [1, 152, 4]               65,512                    --
      │    │    └─Sequential (block_postskip): 3-31      [1, 304, 3]               [1, 152, 3]               323,912                   --
      │    └─_DecoderBlock (2): 2-18                     [1, 152, 3]               [1, 108, 6]               --                        7
      │    │    └─Sequential (block_preskip): 3-32       [1, 152, 3]               [1, 108, 6]               33,156                    --
      │    │    └─Sequential (block_postskip): 3-33      [1, 216, 6]               [1, 108, 6]               163,620                   --
      │    └─_DecoderBlock (3): 2-19                     [1, 108, 6]               [1, 77, 12]               --                        7
      │    │    └─Sequential (block_preskip): 3-34       [1, 108, 6]               [1, 77, 12]               16,863                    --
      │    │    └─Sequential (block_postskip): 3-35      [1, 154, 12]              [1, 77, 12]               83,237                    --
      │    └─_DecoderBlock (4): 2-20                     [1, 77, 12]               [1, 55, 24]               --                        7
      │    │    └─Sequential (block_preskip): 3-36       [1, 77, 12]               [1, 55, 24]               8,635                     --
      │    │    └─Sequential (block_postskip): 3-37      [1, 110, 24]              [1, 55, 24]               42,515                    --
      │    └─_DecoderBlock (5): 2-21                     [1, 55, 24]               [1, 40, 47]               --                        7
      │    │    └─Sequential (block_preskip): 3-38       [1, 55, 24]               [1, 40, 48]               4,520                     --
      │    │    └─Sequential (block_postskip): 3-39      [1, 80, 47]               [1, 40, 47]               22,520                    --
      │    └─_DecoderBlock (6): 2-22                     [1, 40, 47]               [1, 28, 94]               --                        7
      │    │    └─Sequential (block_preskip): 3-40       [1, 40, 47]               [1, 28, 94]               2,324                     --
      │    │    └─Sequential (block_postskip): 3-41      [1, 56, 94]               [1, 28, 94]               11,060                    --
      │    └─_DecoderBlock (7): 2-23                     [1, 28, 94]               [1, 20, 188]              --                        7
      │    │    └─Sequential (block_preskip): 3-42       [1, 28, 94]               [1, 20, 188]              1,180                     --
      │    │    └─Sequential (block_postskip): 3-43      [1, 40, 188]              [1, 20, 188]              5,660                     --
      │    └─_DecoderBlock (8): 2-24                     [1, 20, 188]              [1, 15, 375]              --                        7
      │    │    └─Sequential (block_preskip): 3-44       [1, 20, 188]              [1, 15, 376]              645                       --
      │    │    └─Sequential (block_postskip): 3-45      [1, 30, 375]              [1, 15, 375]              3,195                     --
      │    └─_DecoderBlock (9): 2-25                     [1, 15, 375]              [1, 11, 750]              --                        7
      │    │    └─Sequential (block_preskip): 3-46       [1, 15, 375]              [1, 11, 750]              363                       --
      │    │    └─Sequential (block_postskip): 3-47      [1, 22, 750]              [1, 11, 750]              1,727                     --
      │    └─_DecoderBlock (10): 2-26                    [1, 11, 750]              [1, 9, 1500]              --                        7
      │    │    └─Sequential (block_preskip): 3-48       [1, 11, 750]              [1, 9, 1500]              225                       --
      │    │    └─Sequential (block_postskip): 3-49      [1, 18, 1500]             [1, 9, 1500]              1,161                     --
      │    └─_DecoderBlock (11): 2-27                    [1, 9, 1500]              [1, 6, 3000]              --                        7
      │    │    └─Sequential (block_preskip): 3-50       [1, 9, 1500]              [1, 6, 3000]              126                       --
      │    │    └─Sequential (block_postskip): 3-51      [1, 12, 3000]             [1, 6, 3000]              522                       --
      ├─Sequential (clf): 1-4                            [1, 6, 3000]              [1, 6, 1]                 --                        --
      │    └─Conv1d (0): 2-28                            [1, 6, 3000]              [1, 6, 3000]              42                        [1]
      │    └─Tanh (1): 2-29                              [1, 6, 3000]              [1, 6, 3000]              --                        --
      │    └─AvgPool1d (2): 2-30                         [1, 6, 3000]              [1, 6, 1]                 --                        [3000]
      ├─Sequential (final_layer): 1-5                    [1, 6, 1]                 [1, 5, 1]                 --                        --
      │    └─Conv1d (0): 2-31                            [1, 6, 1]                 [1, 5, 1]                 35                        [1]
      │    └─ELU (1): 2-32                               [1, 5, 1]                 [1, 5, 1]                 --                        --
      │    └─Conv1d (2): 2-33                            [1, 5, 1]                 [1, 5, 1]                 30                        [1]
      │    └─Identity (3): 2-34                          [1, 5, 1]                 [1, 5, 1]                 --                        --
      ======================================================================================================================================================
      Total params: 2,482,011
      Trainable params: 2,482,011
      Non-trainable params: 0
      Total mult-adds (Units.MEGABYTES): 22.43
      ======================================================================================================================================================
      Input size (MB): 0.02
      Forward/backward pass size (MB): 2.91
      Params size (MB): 9.93
      Estimated Total Size (MB): 12.86
      ======================================================================================================================================================,
    )</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-2" type="checkbox" checked><label for="sk-estimator-id-2" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;EEGClassifier<span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span></label><div class="sk-toggleable__content fitted"><pre>&lt;class &#x27;braindecode.classifier.EEGClassifier&#x27;&gt;[initialized](
      module_=======================================================================================================================================================
      Layer (type (var_name):depth-idx)                  Input Shape               Output Shape              Param #                   Kernel Shape
      ======================================================================================================================================================
      USleep (USleep)                                    [1, 2, 3000]              [1, 5]                    --                        --
      ├─ModuleList (encoder_blocks): 1-1                 --                        --                        --                        --
      │    └─_EncoderBlock (0): 2-1                      [1, 2, 3000]              [1, 6, 1500]              --                        7
      │    │    └─Sequential (block_prepool): 3-1        [1, 2, 3000]              [1, 6, 3000]              102                       --
      │    │    └─MaxPool1d (maxpool): 3-2               [1, 6, 3000]              [1, 6, 1500]              --                        2
      │    └─_EncoderBlock (1): 2-2                      [1, 6, 1500]              [1, 9, 750]               --                        7
      │    │    └─Sequential (block_prepool): 3-3        [1, 6, 1500]              [1, 9, 1500]              405                       --
      │    │    └─MaxPool1d (maxpool): 3-4               [1, 9, 1500]              [1, 9, 750]               --                        2
      │    └─_EncoderBlock (2): 2-3                      [1, 9, 750]               [1, 11, 375]              --                        7
      │    │    └─Sequential (block_prepool): 3-5        [1, 9, 750]               [1, 11, 750]              726                       --
      │    │    └─MaxPool1d (maxpool): 3-6               [1, 11, 750]              [1, 11, 375]              --                        2
      │    └─_EncoderBlock (3): 2-4                      [1, 11, 375]              [1, 15, 188]              --                        7
      │    │    └─Sequential (block_prepool): 3-7        [1, 11, 375]              [1, 15, 375]              1,200                     --
      │    │    └─ConstantPad1d (pad): 3-8               [1, 15, 375]              [1, 15, 377]              --                        --
      │    │    └─MaxPool1d (maxpool): 3-9               [1, 15, 377]              [1, 15, 188]              --                        2
      │    └─_EncoderBlock (4): 2-5                      [1, 15, 188]              [1, 20, 94]               --                        7
      │    │    └─Sequential (block_prepool): 3-10       [1, 15, 188]              [1, 20, 188]              2,160                     --
      │    │    └─MaxPool1d (maxpool): 3-11              [1, 20, 188]              [1, 20, 94]               --                        2
      │    └─_EncoderBlock (5): 2-6                      [1, 20, 94]               [1, 28, 47]               --                        7
      │    │    └─Sequential (block_prepool): 3-12       [1, 20, 94]               [1, 28, 94]               4,004                     --
      │    │    └─MaxPool1d (maxpool): 3-13              [1, 28, 94]               [1, 28, 47]               --                        2
      │    └─_EncoderBlock (6): 2-7                      [1, 28, 47]               [1, 40, 24]               --                        7
      │    │    └─Sequential (block_prepool): 3-14       [1, 28, 47]               [1, 40, 47]               7,960                     --
      │    │    └─ConstantPad1d (pad): 3-15              [1, 40, 47]               [1, 40, 49]               --                        --
      │    │    └─MaxPool1d (maxpool): 3-16              [1, 40, 49]               [1, 40, 24]               --                        2
      │    └─_EncoderBlock (7): 2-8                      [1, 40, 24]               [1, 55, 12]               --                        7
      │    │    └─Sequential (block_prepool): 3-17       [1, 40, 24]               [1, 55, 24]               15,565                    --
      │    │    └─MaxPool1d (maxpool): 3-18              [1, 55, 24]               [1, 55, 12]               --                        2
      │    └─_EncoderBlock (8): 2-9                      [1, 55, 12]               [1, 77, 6]                --                        7
      │    │    └─Sequential (block_prepool): 3-19       [1, 55, 12]               [1, 77, 12]               29,876                    --
      │    │    └─MaxPool1d (maxpool): 3-20              [1, 77, 12]               [1, 77, 6]                --                        2
      │    └─_EncoderBlock (9): 2-10                     [1, 77, 6]                [1, 108, 3]               --                        7
      │    │    └─Sequential (block_prepool): 3-21       [1, 77, 6]                [1, 108, 6]               58,536                    --
      │    │    └─MaxPool1d (maxpool): 3-22              [1, 108, 6]               [1, 108, 3]               --                        2
      │    └─_EncoderBlock (10): 2-11                    [1, 108, 3]               [1, 152, 2]               --                        7
      │    │    └─Sequential (block_prepool): 3-23       [1, 108, 3]               [1, 152, 3]               115,368                   --
      │    │    └─ConstantPad1d (pad): 3-24              [1, 152, 3]               [1, 152, 5]               --                        --
      │    │    └─MaxPool1d (maxpool): 3-25              [1, 152, 5]               [1, 152, 2]               --                        2
      │    └─_EncoderBlock (11): 2-12                    [1, 152, 2]               [1, 214, 1]               --                        7
      │    │    └─Sequential (block_prepool): 3-26       [1, 152, 2]               [1, 214, 2]               228,338                   --
      │    │    └─MaxPool1d (maxpool): 3-27              [1, 214, 2]               [1, 214, 1]               --                        2
      ├─Sequential (bottom): 1-2                         [1, 214, 1]               [1, 302, 1]               --                        --
      │    └─Conv1d (0): 2-13                            [1, 214, 1]               [1, 302, 1]               452,698                   [7]
      │    └─ELU (1): 2-14                               [1, 302, 1]               [1, 302, 1]               --                        --
      │    └─BatchNorm1d (2): 2-15                       [1, 302, 1]               [1, 302, 1]               604                       --
      ├─ModuleList (decoder_blocks): 1-3                 --                        --                        --                        --
      │    └─_DecoderBlock (0): 2-16                     [1, 302, 1]               [1, 214, 2]               --                        7
      │    │    └─Sequential (block_preskip): 3-28       [1, 302, 1]               [1, 214, 2]               129,898                   --
      │    │    └─Sequential (block_postskip): 3-29      [1, 428, 2]               [1, 214, 2]               641,786                   --
      │    └─_DecoderBlock (1): 2-17                     [1, 214, 2]               [1, 152, 3]               --                        7
      │    │    └─Sequential (block_preskip): 3-30       [1, 214, 2]               [1, 152, 4]               65,512                    --
      │    │    └─Sequential (block_postskip): 3-31      [1, 304, 3]               [1, 152, 3]               323,912                   --
      │    └─_DecoderBlock (2): 2-18                     [1, 152, 3]               [1, 108, 6]               --                        7
      │    │    └─Sequential (block_preskip): 3-32       [1, 152, 3]               [1, 108, 6]               33,156                    --
      │    │    └─Sequential (block_postskip): 3-33      [1, 216, 6]               [1, 108, 6]               163,620                   --
      │    └─_DecoderBlock (3): 2-19                     [1, 108, 6]               [1, 77, 12]               --                        7
      │    │    └─Sequential (block_preskip): 3-34       [1, 108, 6]               [1, 77, 12]               16,863                    --
      │    │    └─Sequential (block_postskip): 3-35      [1, 154, 12]              [1, 77, 12]               83,237                    --
      │    └─_DecoderBlock (4): 2-20                     [1, 77, 12]               [1, 55, 24]               --                        7
      │    │    └─Sequential (block_preskip): 3-36       [1, 77, 12]               [1, 55, 24]               8,635                     --
      │    │    └─Sequential (block_postskip): 3-37      [1, 110, 24]              [1, 55, 24]               42,515                    --
      │    └─_DecoderBlock (5): 2-21                     [1, 55, 24]               [1, 40, 47]               --                        7
      │    │    └─Sequential (block_preskip): 3-38       [1, 55, 24]               [1, 40, 48]               4,520                     --
      │    │    └─Sequential (block_postskip): 3-39      [1, 80, 47]               [1, 40, 47]               22,520                    --
      │    └─_DecoderBlock (6): 2-22                     [1, 40, 47]               [1, 28, 94]               --                        7
      │    │    └─Sequential (block_preskip): 3-40       [1, 40, 47]               [1, 28, 94]               2,324                     --
      │    │    └─Sequential (block_postskip): 3-41      [1, 56, 94]               [1, 28, 94]               11,060                    --
      │    └─_DecoderBlock (7): 2-23                     [1, 28, 94]               [1, 20, 188]              --                        7
      │    │    └─Sequential (block_preskip): 3-42       [1, 28, 94]               [1, 20, 188]              1,180                     --
      │    │    └─Sequential (block_postskip): 3-43      [1, 40, 188]              [1, 20, 188]              5,660                     --
      │    └─_DecoderBlock (8): 2-24                     [1, 20, 188]              [1, 15, 375]              --                        7
      │    │    └─Sequential (block_preskip): 3-44       [1, 20, 188]              [1, 15, 376]              645                       --
      │    │    └─Sequential (block_postskip): 3-45      [1, 30, 375]              [1, 15, 375]              3,195                     --
      │    └─_DecoderBlock (9): 2-25                     [1, 15, 375]              [1, 11, 750]              --                        7
      │    │    └─Sequential (block_preskip): 3-46       [1, 15, 375]              [1, 11, 750]              363                       --
      │    │    └─Sequential (block_postskip): 3-47      [1, 22, 750]              [1, 11, 750]              1,727                     --
      │    └─_DecoderBlock (10): 2-26                    [1, 11, 750]              [1, 9, 1500]              --                        7
      │    │    └─Sequential (block_preskip): 3-48       [1, 11, 750]              [1, 9, 1500]              225                       --
      │    │    └─Sequential (block_postskip): 3-49      [1, 18, 1500]             [1, 9, 1500]              1,161                     --
      │    └─_DecoderBlock (11): 2-27                    [1, 9, 1500]              [1, 6, 3000]              --                        7
      │    │    └─Sequential (block_preskip): 3-50       [1, 9, 1500]              [1, 6, 3000]              126                       --
      │    │    └─Sequential (block_postskip): 3-51      [1, 12, 3000]             [1, 6, 3000]              522                       --
      ├─Sequential (clf): 1-4                            [1, 6, 3000]              [1, 6, 1]                 --                        --
      │    └─Conv1d (0): 2-28                            [1, 6, 3000]              [1, 6, 3000]              42                        [1]
      │    └─Tanh (1): 2-29                              [1, 6, 3000]              [1, 6, 3000]              --                        --
      │    └─AvgPool1d (2): 2-30                         [1, 6, 3000]              [1, 6, 1]                 --                        [3000]
      ├─Sequential (final_layer): 1-5                    [1, 6, 1]                 [1, 5, 1]                 --                        --
      │    └─Conv1d (0): 2-31                            [1, 6, 1]                 [1, 5, 1]                 35                        [1]
      │    └─ELU (1): 2-32                               [1, 5, 1]                 [1, 5, 1]                 --                        --
      │    └─Conv1d (2): 2-33                            [1, 5, 1]                 [1, 5, 1]                 30                        [1]
      │    └─Identity (3): 2-34                          [1, 5, 1]                 [1, 5, 1]                 --                        --
      ======================================================================================================================================================
      Total params: 2,482,011
      Trainable params: 2,482,011
      Non-trainable params: 0
      Total mult-adds (Units.MEGABYTES): 22.43
      ======================================================================================================================================================
      Input size (MB): 0.02
      Forward/backward pass size (MB): 2.91
      Params size (MB): 9.93
      Estimated Total Size (MB): 12.86
      ======================================================================================================================================================,
    )</pre></div> </div></div></div></div>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 259-265

Plot results
------------

We use the history stored by Skorch during training to plot the performance of
the model throughout training. Specifically, we plot the loss and the balanced
balanced accuracy for the training and validation sets.

.. GENERATED FROM PYTHON SOURCE LINES 265-282

.. code-block:: Python


    import matplotlib.pyplot as plt
    import pandas as pd

    # Extract loss and balanced accuracy values for plotting from history object
    df = pd.DataFrame(clf.history.to_list())
    df.index.name = "Epoch"
    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(8, 7), sharex=True)
    df[["train_loss", "valid_loss"]].plot(color=["r", "b"], ax=ax1)
    df[["train_bal_acc", "valid_bal_acc"]].plot(color=["r", "b"], ax=ax2)
    ax1.set_ylabel("Loss")
    ax2.set_ylabel("Balanced accuracy")
    ax1.legend(["Train", "Valid"])
    ax2.legend(["Train", "Valid"])
    fig.tight_layout()
    plt.show()




.. image-sg:: /auto_examples/applied_examples/images/sphx_glr_plot_sleep_staging_usleep_001.png
   :alt: plot sleep staging usleep
   :srcset: /auto_examples/applied_examples/images/sphx_glr_plot_sleep_staging_usleep_001.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 283-284

Finally, we also display the confusion matrix and classification report:

.. GENERATED FROM PYTHON SOURCE LINES 284-299

.. code-block:: Python

    from sklearn.metrics import classification_report, confusion_matrix

    from braindecode.visualization import plot_confusion_matrix

    y_true = np.array([valid_set[i][1] for i in valid_sampler])
    y_pred = clf.predict(valid_set)

    confusion_mat = confusion_matrix(y_true.flatten(), y_pred.flatten())

    plot_confusion_matrix(
        confusion_mat=confusion_mat, class_names=["Wake", "N1", "N2", "N3", "REM"]
    )

    print(classification_report(y_true.flatten(), y_pred.flatten()))




.. image-sg:: /auto_examples/applied_examples/images/sphx_glr_plot_sleep_staging_usleep_002.png
   :alt: plot sleep staging usleep
   :srcset: /auto_examples/applied_examples/images/sphx_glr_plot_sleep_staging_usleep_002.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

                  precision    recall  f1-score   support

               0       0.12      0.31      0.17        64
               1       0.03      0.05      0.04        22
               2       0.52      0.34      0.41       197
               3       0.26      0.20      0.23        84
               4       0.25      0.03      0.06        32

        accuracy                           0.26       399
       macro avg       0.24      0.19      0.18       399
    weighted avg       0.35      0.26      0.28       399





.. GENERATED FROM PYTHON SOURCE LINES 300-304

Finally, we can also visualize the hypnogram of the recording we used for
validation, with the predicted sleep stages overlaid on top of the true
sleep stages. We can see that the model cannot correctly identify the
different sleep stages with this amount of training.

.. GENERATED FROM PYTHON SOURCE LINES 304-313

.. code-block:: Python


    import matplotlib.pyplot as plt

    fig, ax = plt.subplots(figsize=(15, 5))
    ax.plot(y_true.flatten(), color="b", label="Expert annotations")
    ax.plot(y_pred.flatten(), color="r", label="Predict annotations", alpha=0.5)
    ax.set_xlabel("Time (epochs)")
    ax.set_ylabel("Sleep stage")




.. image-sg:: /auto_examples/applied_examples/images/sphx_glr_plot_sleep_staging_usleep_003.png
   :alt: plot sleep staging usleep
   :srcset: /auto_examples/applied_examples/images/sphx_glr_plot_sleep_staging_usleep_003.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    Text(150.22222222222223, 0.5, 'Sleep stage')



.. GENERATED FROM PYTHON SOURCE LINES 314-319

Our model was able to learn, as shown by the decreasing training and
validation loss values, despite the low amount of data that was available
(only two recordings in this example). To further improve performance, more
recordings should be included in the training set, the model should be
trained for more epochs and hyperparameters should be optimized.

.. GENERATED FROM PYTHON SOURCE LINES 321-339

References
----------

.. [1] Perslev M, Darkner S, Kempfner L, Nikolic M, Jennum PJ, Igel C.
       U-Sleep: resilient high-frequency sleep staging. npj Digit. Med. 4, 72 (2021).
       https://github.com/perslev/U-Time/blob/master/utime/models/usleep.py

.. [2] B Kemp, AH Zwinderman, B Tuk, HAC Kamphuisen, JJL Oberyé. Analysis of
       a sleep-dependent neuronal feedback loop: the slow-wave
       microcontinuity of the EEG. IEEE-BME 47(9):1185-1194 (2000).

.. [3] Goldberger AL, Amaral LAN, Glass L, Hausdorff JM, Ivanov PCh,
       Mark RG, Mietus JE, Moody GB, Peng C-K, Stanley HE. (2000)
       PhysioBank, PhysioToolkit, and PhysioNet: Components of a New
       Research Resource for Complex Physiologic Signals.
       Circulation 101(23):e215-e220

.. include:: /links.inc


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 51.196 seconds)

**Estimated memory usage:**  955 MB


.. _sphx_glr_download_auto_examples_applied_examples_plot_sleep_staging_usleep.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: plot_sleep_staging_usleep.ipynb <plot_sleep_staging_usleep.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: plot_sleep_staging_usleep.py <plot_sleep_staging_usleep.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: plot_sleep_staging_usleep.zip <plot_sleep_staging_usleep.zip>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
